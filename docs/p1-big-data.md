# Partie 1 - Introduction au Big Data
![Big Data](img/p1/big-data.jpeg)

## Les "Big Data", Pourquoi?
L'√™tre humain, √† travers l'humanit√©, a toujours cherch√© trois choses : Savoir (qu'est-ce qui s'est pass√©?), Comprendre (pourquoi cela s'est-il pass√©?) et Pr√©dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam√© l'omniscience en ayant recours √† des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal.

Cela dit, ces moyens ne sont gu√®res satisfaisants √† l'esprit m√©ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle √† tout √©v√®nement, et une justification convainquante √† tout comportement. Le scientifique se base sur des faits. Il veut arriver √† faire de la magie gr√¢ce √† la technologie.

Pour arriver √† ces fins, le scientifique a besoin de donn√©es. L'int√©r√™t de collecter des donn√©es et de les exploiter a longtemps √©t√© n√©glig√©, et a √©t√© limit√© au peu de donn√©es, jug√©es "utiles", qui semblaient suffisantes pour atteindre un objectif imm√©diat. Cependant, adopter le chemin √©vident et peu risqu√© n'aurait jamais permis de r√©aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen..

Le terme Big Data est apparu peu de temps apr√®s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une √®re o√π l'ajout des donn√©es √©tait exclusivement r√©serv√© √† une √©lite experte, o√π le volume des donn√©es disponible √©tait petit mais o√π les donn√©es √©taient pr√©cieuses et pertinentes, vers une √®re o√π tout un chacun √©tait capable d'introduire des connaissances, v√©ridiques ou pas, qui seraient sauvegard√©es dans une m√©moire collective jusqu'√† la fin des temps. Ce changement de paradigme a entrain√© le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn√©es, mais √©galement d'en extraire de la valeur.

Ces infrastructures auront la capacit√© de g√©rer toute la cha√Æne logistique des donn√©es, de la collecte vers l'affichage. Cela semble √©vident, me direz-vous, car les syst√®mes classiques sont capables de faire cela. Qui stocke mieux les donn√©es qu'une bonne vieille base de donn√©es relationnelle? Le probl√®me est que les donn√©es dites "Big Data" sont caract√©ris√©es par des propri√©t√©s telles que, les syst√®mes classiques de stockage et de traitement auraient du mal √† les exploiter √† leur juste valeur.

## Caract√©ristiques des Donn√©es Massives
Le terme "donn√©es massives", ou "Big Data", ne donne √† mon avis pas enti√®rement justice aux donn√©es de notre domaine. En effet, il repr√©sente une seule caract√©ristique parmis plusieurs, qui est le Volume, qui, m√™me si elle semble √™tre la plus importante, est loin d'√™tre la plus critique.

En effet, les donn√©es massives sont caract√©ris√©es par les fameux *V. Il en existe plusieurs (10 jusqu'√† ce jour si je ne m'abuse, mais [certains](https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html) en citent m√™me 42!!!), mais pourraient √† mon avis √™tre r√©sum√©s en trois caract√©ristiques primordiales, autours de la combinaison desquelles tournent toutes les d√©cisions prises dans ce domaine.

**Volume**
C'est √©videmment le V le plus manifeste, qui caract√©rise le fait que les donn√©es ont un volume √©norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'√†  $2^{80}$ octets!). Mais ceci n'est pas tout. Un volume √©norme, s'il reste constant, est g√©rable : il suffit de trouver une machine suffisamment puissante pour le g√©rer. Le probl√®me avec la propri√©t√© du volume, c'est qu'il augmente de fa√ßon continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann√©e, atteste que _"Over the last two years alone 90 percent of the data in the world was generated."_ Il est donc primordial de trouver un moyen de g√©rer ce volume toujours croissant des donn√©es.

**V√©locit√©**
Cette propri√©t√© est, √† mon avis, la plus probl√©matique des trois, car, coupl√©e avec le volume, elle rend les syst√®me actuels obsol√®tes. En effet, la v√©locit√© est, litt√©ralement, "La vitesse avec laquelle quelque chose se d√©place dans une direction particuli√®re". Dans notre cas, la v√©locit√© des donn√©es est la responsable directe du volume croissant des donn√©es dans le syst√®me. Elle est provoqu√©e par une arriv√©e des donn√©es dans le syst√®me sous la forme d'un flux constant qui demande √† √™tre stock√© et trait√© imm√©diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr√©sentation r√©cente et fid√®le de l'√©tat des donn√©es. D'ailleurs, cette propri√©t√© a engendr√© une autre pr√©occupation des analystes des donn√©es, qui est de fournir une introspection en temps r√©el sur les donn√©es, les qualifiant ainsi de "Fast Data".

**Vari√©t√©**
Ce qui distingue vraiment les donn√©es massives des donn√©es g√©r√©es classiquement dans des bases de donn√©es op√©rationnelles, c'est le support des donn√©es semi- et non structur√©es. En effet, les donn√©es non structur√©es sont des donn√©es qu'on stocke dans un format qui n'est pas d√©fini √† la cr√©ation, telles que les donn√©es textuelles, images ou sons. Les donn√©es semi-structur√©es sont des donn√©es qui contiennent une structure, mais que cette structure n'est pas rigide, et on ne d√©finit pas de contraintes d'√©criture √† l'insertion de la donn√©e, contrairement aux donn√©es structur√©es (se trouvant typiquement dans des bases de donn√©es relationnelles) qui, si elles ne respectent pas la structure d√©finie, sont consid√©r√©es fausses et ne sont pas autoris√©es √† √™tre enregistr√©es. On estime que seules 15% des donn√©es dans une entreprise sont des donn√©es structur√©es, contre 85% qui ne le sont pas! Dans une optique centr√©e sur les donn√©es, dont le but est de gagner le maximum de vision √† partir des donn√©es, perdre autant de sources d'information est un vrai probl√®me. Il est donc important que les syst√®mes Big Data sachent interpr√©ter ces donn√©es et en extraire le maximum de valeur.

Toutes les d√©cisions, choix et propri√©t√©s prises au niveau des architectures et infrastructures Big Data sont r√©gies par ces trois caract√©ristiques, ce qui va compl√®tement changer la vision "relationnelle" que tout informaticien qui se respecte a acquis tout au long de ses ann√©es d'√©tude et de travail.

Cela dit, ce ne sont pas les seules propri√©t√©s. D'autres V ont vu le jour, mais sans jamais avoir autant d'impact sur l'infrastructre, plut√¥t dans la fa√ßon de d√©finir les processus, la gouvernance et les approches m√©tier √† adopter. Nous citons par exemple :

  - _V√©racit√©_ : c'est la confiance que nous devons avoir en nos donn√©es. Cette propri√©t√© est inversement proportionnelle au volume et √† la vari√©t√© : plus nos donn√©es sont fiables, moins elles sont diversifi√©es et volumineuses!
  - _Valeur_ : c'est la capacit√© d'extraire de la valeur m√©tier √† partir des donn√©es.
  - _Variabilit√©_ : une extension de la vari√©t√©, qui indique √† quel point nos donn√©es peuvent avoir des dimensions diff√©rentes √† partir des sources de donn√©es disparates.
  - _Visualisation_ : c'est la capacit√© de nos donn√©es √† √™tre repr√©sent√©es par les outils de visualisation classiques.
  - etc.

## Principes de base du Domaine des Big Data
Il est important, avant d'entamer n'importe quel travail sur les syst√®mes Big Data, de consid√©rer certains principes, qui sont parfois en enti√®re contradiction avec les principes classiques de d√©veloppement d'application. Ce n'est pas si √©tonnant : le domaine des Big Data n'est pas cens√© prendre la place des domaines relationnel et d√©cisionnel, mais plut√¥t les enrichir et agr√©menter.

### _MOTTO 1 :_ Stocker d'abord, r√©fl√©chir ensuite
√Ä cause de la v√©locit√©, il est important de consid√©rer qu'il nous sera parfois difficile, voire impossible, de nettoyer les donn√©es ou de faire un traitement quelconque dessus, avant de les stocker. Cela risque dans bien des cas de nous faire perdre des donn√©es, le cauchemar de tout scientifique des donn√©es!

Nous devons donc envisager la possibilit√© de d√©finir des syst√®mes de stockage qui contiennent des donn√©es non nettoy√©es, en vrac (appel√©es _raw data_), pour ensuite lancer des traitements dessus.. l'horreur pour un gestionnaire de bases des donn√©es! üò±

Bien entendu, ces "bases" ne sont pas con√ßues pour √™tre directement exploit√©es par des applications externes, mais plut√¥t pour conserver le plus longtemps possibles les donn√©es brutes, sans perte, qui pourraient eventuellement √™tre r√©utilis√©es pour d'autres fins.

### _MOTTO 2 :_ Absolument TOUTES les donn√©es sont importantes!
D'o√π l'int√©r√™t du _MOTTO 1_. Il nous est parfois difficile, au tout d√©but de la conception des syst√®mes Big Data, de cerner toutes les possibilit√©s offertes par ces syst√®mes et par les donn√©es que nous avons √† notre disposition. Nous sommes donc en g√©n√©ral tent√©s de supprimer les donn√©es dont nous n'avons pas besoin une fois extraite l'information imm√©diatement utile. Cela dit, gr√¢ce √† l'accessibilit√© des syst√®mes de stockage magn√©tiques et leur prix de plus en plus bas, nous consid√©rons qu'il est largement plus b√©n√©fique de stocker des donn√©es qu'on n'utilisera peut-√™tre jamais, plut√¥t que de gagner de la place et perdre un potentiel pouvoir concurrentiel.

### _MOTTO 3 :_ Ce sont les donn√©es qui pilotent le traitement
Dans un syst√®me op√©rationnel classique, ainsi que dans la plupart des syst√®mes d√©cisionnels, ce sont les besoins m√©tier qui pr√©valoient : le responsable m√©tier commence par d√©finir les besoins (ou les KPIs : _Key Performance Indicators_ dans le cas d'un syst√®me d√©cisionnel), puis le responsable technique con√ßoit les structures de donn√©es pour r√©pondre √† ces besoins.

Par essence, un syst√®me Big Data fonctionne diff√©remment : les donn√©es sont collect√©es tout d'abord √† partir de toutes les sources possibles; des traitements de fouille et d'exploration de ces donn√©es sont lanc√©s ensuite, pour extraire de la valeur √† partir de ces donn√©es. L'objectif est toujours le m√™me : chercher l'effet WOW!

D'o√π l'int√©r√™t de ce MOTTO : d√©finir le traitement √† r√©aliser d√©pend des donn√©es que nous avons r√©ussi √† collecter, et par le contraire. Cela implique donc l'utilisation d'autres types de syst√®mes de traitement et d'algorithmes d'analyse.

### _MOTTO 4 :_ Co-localisation des donn√©es et du traitement
Un syst√®me classique √† plusieurs couches, tel que le syst√®me trois tiers par exemple, se base sur le principe de s√©paration des donn√©es et du traitement. On trouve en g√©n√©ral des donn√©es sur un serveur de bases de donn√©es s√©par√©, et les traitement complexes sur un serveur d'application qui se charge de l'aggr√©gation et de l'affichage de ces donn√©es. Ceci est agr√©ment√© d'un langage de requ√™tage d√©claratif (typiquement SQL) pour r√©aliser des op√©rations de filtrage, parfois assez lourdes et complexes, au niveau de la base de donn√©es.

Cela dit, dans un contexte Big Data, le volume des donn√©es peut s'av√©rer assez cons√©quent, trop m√™me pour envisager de le d√©placer √† chaque fois vers un autre syst√®me pour en extraire une vraie valeur. De plus, compter sur un langage comme SQL pour diminuer le volume ou faire de simples agr√©gations au niveau de la base de donn√©es pourra la rendre indisponible pendant un moment, ce qui va √† l'encontre du principe de v√©locit√©, qui exige une disponibilit√© √† toute √©preuve du syst√®me de stockage.

C'est pour cette raison que, pour r√©aliser les traitements voulus en un temps raisonnable et sans avoir √† les d√©placer sur le r√©seau, il est question dans les syst√®mes Big Data de d√©placer le traitement vers les donn√©es, au lieu de d√©placeer les donn√©es vers le traitement.

### _MOTTO 5 :_ La redondance, c'est bien

### _MOTTO 6 :_ Vive le Polyglottisme!

## Infrastructure Big Data : Besoins

## Th√©or√®me CAP

## Technologies et Paradigmes
### Technologies d'Ingestion de Donn√©es

### Technologies de Stockage de Donn√©es

### Technologies de Traitement de Donn√©es
