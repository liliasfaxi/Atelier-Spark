# Partie 1 - Introduction au Big Data
![Big Data](img/p1/big-data.jpeg)

## Les "Big Data", Pourquoi?
L'√™tre humain, √† travers l'humanit√©, a toujours cherch√© trois choses : Savoir (qu'est-ce qui s'est pass√©?), Comprendre (pourquoi cela s'est-il pass√©?) et Pr√©dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam√© l'omniscience en ayant recours √† des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal.

Cela dit, ces moyens ne sont gu√®res satisfaisants √† l'esprit m√©ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle √† tout √©v√®nement, et une justification convainquante √† tout comportement. Le scientifique se base sur des faits. Il veut arriver √† faire de la magie gr√¢ce √† la technologie.

Pour arriver √† ces fins, le scientifique a besoin de donn√©es. L'int√©r√™t de collecter des donn√©es et de les exploiter a longtemps √©t√© n√©glig√©, et a √©t√© limit√© au peu de donn√©es, jug√©es "utiles", qui semblaient suffisantes pour atteindre un objectif imm√©diat. Cependant, adopter le chemin √©vident et peu risqu√© n'aurait jamais permis de r√©aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen..

Le terme Big Data est apparu peu de temps apr√®s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une √®re o√π l'ajout des donn√©es √©tait exclusivement r√©serv√© √† une √©lite experte, o√π le volume des donn√©es disponible √©tait petit mais o√π les donn√©es √©taient pr√©cieuses et pertinentes, vers une √®re o√π tout un chacun √©tait capable d'introduire des connaissances, v√©ridiques ou pas, qui seraient sauvegard√©es dans une m√©moire collective jusqu'√† la fin des temps. Ce changement de paradigme a entrain√© le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn√©es, mais √©galement d'en extraire de la valeur.

Ces infrastructures auront la capacit√© de g√©rer toute la cha√Æne logistique des donn√©es, de la collecte vers l'affichage. Cela semble √©vident, me direz-vous, car les syst√®mes classiques sont capables de faire cela. Qui stocke mieux les donn√©es qu'une bonne vieille base de donn√©es relationnelle? Le probl√®me est que les donn√©es dites "Big Data" sont caract√©ris√©es par des propri√©t√©s telles que, les syst√®mes classiques de stockage et de traitement auraient du mal √† les exploiter √† leur juste valeur.

## Caract√©ristiques des Donn√©es Massives
Le terme "donn√©es massives", ou "Big Data", ne donne √† mon avis pas enti√®rement justice aux donn√©es de notre domaine. En effet, il repr√©sente une seule caract√©ristique parmis plusieurs, qui est le Volume, qui, m√™me si elle semble √™tre la plus importante, est loin d'√™tre la plus critique.

En effet, les donn√©es massives sont caract√©ris√©es par les fameux *V. Il en existe plusieurs (10 jusqu'√† ce jour si je ne m'abuse, mais [certains](https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html) en citent m√™me 42!!!), mais pourraient √† mon avis √™tre r√©sum√©s en trois caract√©ristiques primordiales, autours de la combinaison desquelles tournent toutes les d√©cisions prises dans ce domaine.

  - **Volume**
  C'est √©videmment le V le plus manifeste, qui caract√©rise le fait que les donn√©es ont un volume √©norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'√†  $2^{80}$ octets!). Mais ceci n'est pas tout. Un volume √©norme, s'il reste constant, est g√©rable : il suffit de trouver une machine suffisamment puissante pour le g√©rer. Le probl√®me avec la propri√©t√© du volume, c'est qu'il augmente de fa√ßon continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann√©e, atteste que _"Over the last two years alone 90 percent of the data in the world was generated."_ Il est donc primordial de trouver un moyen de g√©rer ce volume toujours croissant des donn√©es.

  - **V√©locit√©**
  Cette propri√©t√© est, √† mon avis, la plus probl√©matique des trois, car, coupl√©e avec le volume, elle rend les syst√®me actuels obsol√®tes. En effet, la v√©locit√© est, litt√©ralement, "La vitesse avec laquelle quelque chose se d√©place dans une direction particuli√®re". Dans notre cas, la v√©locit√© des donn√©es est la responsable directe du volume croissant des donn√©es dans le syst√®me. Elle est provoqu√©e par une arriv√©e des donn√©es dans le syst√®me sous la forme d'un flux constant qui demande √† √™tre stock√© et trait√© imm√©diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr√©sentation r√©cente et fid√®le de l'√©tat des donn√©es. D'ailleurs, cette propri√©t√© a engendr√© une autre pr√©occupation des analystes des donn√©es, qui est de fournir une introspection en temps r√©el sur les donn√©es, les qualifiant ainsi de "Fast Data".

  - **Vari√©t√©**
  Ce qui distingue vraiment les donn√©es massives des donn√©es g√©r√©es classiquement dans des bases de donn√©es op√©rationnelles, c'est le support des donn√©es semi- et non structur√©es. En effet, les donn√©es non structur√©es sont des donn√©es qu'on stocke dans un format qui n'est pas d√©fini √† la cr√©ation, telles que les donn√©es textuelles, images ou sons. Les donn√©es semi-structur√©es sont des donn√©es qui contiennent une structure, mais que cette structure n'est pas rigide, et on ne d√©finit pas de contraintes d'√©criture √† l'insertion de la donn√©e, contrairement aux donn√©es structur√©es (se trouvant typiquement dans des bases de donn√©es relationnelles) qui, si elles ne respectent pas la structure d√©finie, sont consid√©r√©es fausses et ne sont pas autoris√©es √† √™tre enregistr√©es. On estime que seules 15% des donn√©es dans une entreprise sont des donn√©es structur√©es, contre 85% qui ne le sont pas! Dans une optique centr√©e sur les donn√©es, dont le but est de gagner le maximum de vision √† partir des donn√©es, perdre autant de sources d'information est un vrai probl√®me. Il est donc important que les syst√®mes Big Data sachent interpr√©ter ces donn√©es et en extraire le maximum de valeur.

Toutes les d√©cisions, choix et propri√©t√©s prises au niveau des architectures et infrastructures Big Data sont r√©gies par ces trois caract√©ristiques, ce qui va compl√®tement changer la vision "relationnelle" que tout informaticien qui se respecte a acquis tout au long de ses ann√©es d'√©tude et de travail.

Cela dit, ce ne sont pas les seules propri√©t√©s. D'autres V ont vu le jour, mais sans jamais avoir autant d'impact sur l'infrastructre, plut√¥t dans la fa√ßon de d√©finir les processus, la gouvernance et les approches m√©tier √† adopter. Nous citons par exemple :

  - _V√©racit√©_ : c'est la confiance que nous devons avoir en nos donn√©es. Cette propri√©t√© est inversement proportionnelle au volume et √† la vari√©t√© : plus nos donn√©es sont fiables, moins elles sont diversifi√©es et volumineuses!
  - _Valeur_ : c'est la capacit√© d'extraire de la valeur m√©tier √† partir des donn√©es.
  - _Variabilit√©_ : une extension de la vari√©t√©, qui indique √† quel point nos donn√©es peuvent avoir des dimensions diff√©rentes √† partir des sources de donn√©es disparates.
  - _Visualisation_ : c'est la capacit√© de nos donn√©es √† √™tre repr√©sent√©es par les outils de visualisation classiques.
  - etc.

## Infrastructure Big Data : Besoins
Les caract√©ristiques des donn√©es Big Data cit√©es ci-dessus, entra√Ænent des besoins particuliers en termes d'infrastructure et d'architecture.

**Volume**
La caract√©ristique de volume, qui implique que la taille des donn√©es augmente de fa√ßon r√©guli√®re, fait qu'on ne peut plus se contenter d'un syst√®me centralis√© classique. Car dans un syst√®me centralis√© (donc bas√© sur une seule machine), augmenter les ressources de stockage au besoin implique ce que nous appelons une **scalabilit√© verticale** ou un _scale up_, qui veut dire une augmentation des capacit√©s du serveur de stockage en rajoutant des processeurs, de la RAM ou des disques.

Cependant, cette solution, bien qu'elle soit intuitive, rapide et ne requiert pas de changement architecturaux cons√©quents, implique en g√©n√©ral un temps d'arr√™t pendant l'installation, ainsi qu'une d√©pense assez cons√©quente pour faire l'acquisition d'un serveur puissant. De plus, une machine unique atteindra rapidement une limite mat√©rielle, car il vous est impossible d'augmenter ses ressources ind√©finiment.

En contrepartie, il est possible de penser que, face √† un volume toujours en augmentation de donn√©es, il serait plus judicieux de rajouter des machines au besoin, cr√©ant ainsi un cluster de machines interconnect√©es -syst√®me r√©parti-, dont la taille et la capacit√© sont virtuellement illimit√©es. Nous sommes donc face √† un autre type de scalabilit√© : la  **scalabilit√© horizontale** ou le _scale out_

Donc Volume => <span class="highlight">Scalabilit√© Horizontale</span>

**V√©locit√©**
La v√©locit√© est une propri√©t√© qui, coupl√©e au volume, rend la gestion de l'infrastructure un vrai cauchemar. En effet, g√©rer des donn√©es en continuelle arriv√©e implique qu'il y'a un risque √©norme de perte de donn√©es, si elles ne sont pas manipul√©es √† temps. C'est pour cette raison qu'un syst√®me Big Data se doit d'√™tre continuellement disponible : toute requ√™te de lecture ou d'√©criture doit √™tre trait√©e en un temps raisonnable, et le syst√®me doit √™tre continuellement alerte pour saisir toutes les donn√©es, sans risquer de les perdre.

Ainsi V√©locit√© => <span class="highlight">Disponibilit√©</span>

**Vari√©t√©**
La vari√©t√© de donn√©es implique non seulement que nous sommes en pr√©sence de donn√©es structur√©es, semi-structur√©es et non structur√©es, mais √©galement que ces donn√©es peuvent parvenir de sources diff√©rentes, avec des formats diff√©rents, et que m√™me √† partir d'une m√™me source, ce format peut changer d'un moment √† un autre. Dans les syst√®mes classiques, tout ce qui est variable doit passer par une couche d'homog√©n√©isation qui transformera chaque entr√©e ou enregistrement dans la forme souhait√©e, en remplissant par des valeurs NULL les donn√©es manquantes. Rajouter cette couche d'homog√©n√©isation aura un double impact n√©gatif sur notre syst√®me : (1) √† cause de la v√©locit√©, cette op√©ration risquera de ralentir la collecte et saisie des donn√©es entrantes, et (2) on pourra subir une perte de donn√©es suite √† ces transformations.

C'est pour ces raisons qu'un syst√®me Big Data se doit de supporter des types de donn√©es changeants, sans pour autant requ√©rir √† des subterfuges qui alourdissent ou contournent le syst√®me de stockage.

D'o√π Vari√©t√© => <span class="highlight">Flexibilit√©</span>

## Th√©or√®me CAP
Les besoins de scalabilit√©, disponibilit√© et flexibilit√©, obligatoires pour avoir un syst√®me Big Data en bonne et due forme, se trouvent confront√©s √† une contrainte de taille... et qu'en est-il de la coh√©rence (commun√©ment appel√©e aussi consistence, par anglicisme)?
La coh√©rence repr√©sente en effet un _must_ pour les syst√®mes relationnels classiques, et une base sur laquelle sont prises toutes les d√©cisions conceptuelles et techniques. Elle repr√©sente le fait que les donn√©es stables doivent respecter toutes les contraintes d'int√©grit√© d√©finies √† la cr√©ation de la base de donn√©e. Par exemple, si un champ est d√©cr√©t√© "Non Null", il doit le rester quelque soit la situation, et √† aucun moment une requ√™te ne doit surprendre ce champs avec une valeur nulle, m√™me si c'est juste une valeur interm√©diaire. La coh√©rence est un principe tr√®s rigide dans les bases de donn√©es relationnelles, et repr√©sente le crit√®re de base pour la gestion des transactions : le **C** de **ACID**.

Cela dit, dans les syst√®mes Big Data, nous nous trouvons confront√©s √† un probl√®me de taille : nous devons √™tre en pr√©sence d'une infrastructure r√©partie et hautement disponible. Or, il existe un th√©or√®me appel√© **CAP** pour _Consistency / Availability / Partition tolerance_, qui stipule que ces trois propri√©t√©s (notamment la coh√©rence, la disponibilit√© et la tol√©rance au partitionnement), ne peut jamais avoir lieu en m√™me temps. Seules deux d'entre elles peuvent √™tre respect√©es √† la fois.

Essayons d'expliquer pourquoi.

Un syst√®me r√©parti est dit coh√©rent si tous ses noeuds voient les m√™mes donn√©es en m√™me temps. C'est √† dire que, si nous r√©alisons une op√©ration de lecture sur un syst√®me consistant, il devrait toujours retourner la valeur la plus r√©cente qui ait √©t√© √©crite, quel que soit l'endroit √† partir duquel la lecture est effectu√©e. Ainsi, si une donn√©e est modifi√©e sur un noeud particulier, pour conserver la coh√©rence demand√©e, aucune op√©ration de lecture ne doit √™tre permise avant d'avoir mis √† jour toutes les r√©pliques (copies) de cette donn√©es. Or, les diff√©rents noeuds d'un cluster sont en g√©n√©ral distants, parfois m√™me g√©ographiquement, il est donc n√©cessaire d'attendre que la propagation de la modification se fasse sur le r√©seau, pour effectuer n'importe quelle op√©ration, m√™me une lecture. Ceci va rendre nos donn√©es indisponibles √† la lecture pendant tout le temps que durera l'op√©ration de synchronisation, qui est un temps incertain puisque... r√©seau. Assurer donc une coh√©rence forte dans un syst√®me distribu√© est en contradiction avec le besoin de disponibilit√© du syst√®me et donn√©es. D'ailleurs, c'est ce que font les bases de donn√©es relationnelles r√©parties, qui conservent les propri√©t√©s ACID tout en distribuant les donn√©es, mais qui souffrent d'un manque notoire de performance.

Les syst√®mes Big Data, subissant les contraintes des V pr√©c√©demment cit√©s, doivent donc faire un choix. Or ce choix est loin d'√™tre facile : qui voudra acheter un syst√®me qui pr√¥ne haut et fort qu'il est incoh√©rent ? L'id√©e serait donc de partir sur le principe de **coh√©rence √©ventuelle** ou parfois de **coh√©rence ajustable**. Ainsi, un syst√®me Big Data est un syst√®me principalement disponible, fondamentalement r√©parti, et qui assure une coh√©rence √©ventuelle au bout d'un temps g√©n√©ralement n√©gligeable, avec la possibilit√© de configurer les niveau de coh√©rence parfois m√™me dynamiquement.

Les experts les appellent donc les syst√®mes **BASE** (admirez le jeux de mot.. ACID, BASE üòé):

  - **B**asically **A**vailable
  - **S**oft-state
  - **E**ventual consistency

La propri√©t√© de _Soft State_ ou d'√©tat "mou" veut dire que l'√©tat du syst√®me peut changer dans le temps, m√™me sans qu'il y ait une nouvelle entr√©e, √† cause du principe de coh√©rence √©ventuelle expliqu√© pr√©c√©demment.

Maintenant que vous √™tes plus familiaris√©s avec les caract√©ristiques d'un syst√®me Big Data, listons quelques principes, appel√©s ici _MOTTOS_, qui vont r√©gir nos futures d√©cisions dans ce domaine.

## Principes de base du Domaine des Big Data
Il est important, avant d'entamer n'importe quel travail sur les syst√®mes Big Data, de consid√©rer certains principes, qui sont parfois en enti√®re contradiction avec les principes classiques de d√©veloppement d'application. Ce n'est pas si √©tonnant : le domaine des Big Data n'est pas cens√© prendre la place des domaines relationnel et d√©cisionnel, mais plut√¥t les enrichir et agr√©menter.

**_MOTTO 1 :_ Stocker d'abord, r√©fl√©chir ensuite**
√Ä cause de la v√©locit√©, il est important de consid√©rer qu'il nous sera parfois difficile, voire impossible, de nettoyer les donn√©es ou de faire un traitement quelconque dessus, avant de les stocker. Cela risque dans bien des cas de nous faire perdre des donn√©es, le cauchemar de tout scientifique des donn√©es!

Nous devons donc envisager la possibilit√© de d√©finir des syst√®mes de stockage qui contiennent des donn√©es non nettoy√©es, en vrac (appel√©es _raw data_), pour ensuite lancer des traitements dessus.. l'horreur pour un gestionnaire de bases des donn√©es! üò±

Bien entendu, ces "bases" ne sont pas con√ßues pour √™tre directement exploit√©es par des applications externes, mais plut√¥t pour conserver le plus longtemps possibles les donn√©es brutes, sans perte, qui pourraient eventuellement √™tre r√©utilis√©es pour d'autres fins.

**_MOTTO 2 :_ Absolument TOUTES les donn√©es sont importantes!**
D'o√π l'int√©r√™t du _MOTTO 1_. Il nous est parfois difficile, au tout d√©but de la conception des syst√®mes Big Data, de cerner toutes les possibilit√©s offertes par ces syst√®mes et par les donn√©es que nous avons √† notre disposition. Nous sommes donc en g√©n√©ral tent√©s de supprimer les donn√©es dont nous n'avons pas besoin une fois extraite l'information imm√©diatement utile. Cela dit, gr√¢ce √† l'accessibilit√© des syst√®mes de stockage magn√©tiques et leur prix de plus en plus bas, nous consid√©rons qu'il est largement plus b√©n√©fique de stocker des donn√©es qu'on n'utilisera peut-√™tre jamais, plut√¥t que de gagner de la place et perdre un potentiel pouvoir concurrentiel.

**_MOTTO 3 :_ Ce sont les donn√©es qui pilotent le traitement**
Dans un syst√®me op√©rationnel classique, ainsi que dans la plupart des syst√®mes d√©cisionnels, ce sont les besoins m√©tier qui pr√©valoient : le responsable m√©tier commence par d√©finir les besoins (ou les KPIs : _Key Performance Indicators_ dans le cas d'un syst√®me d√©cisionnel), puis le responsable technique con√ßoit les structures de donn√©es pour r√©pondre √† ces besoins.

Par essence, un syst√®me Big Data fonctionne diff√©remment : les donn√©es sont collect√©es tout d'abord √† partir de toutes les sources possibles; des traitements de fouille et d'exploration de ces donn√©es sont lanc√©s ensuite, pour extraire de la valeur √† partir de ces donn√©es. L'objectif est toujours le m√™me : chercher l'effet WOW!

D'o√π l'int√©r√™t de ce MOTTO : d√©finir le traitement √† r√©aliser d√©pend des donn√©es que nous avons r√©ussi √† collecter, et par le contraire. Cela implique donc l'utilisation d'autres types de syst√®mes de traitement et d'algorithmes d'analyse.

**_MOTTO 4 :_ Co-localisation des donn√©es et du traitement**
Un syst√®me classique √† plusieurs couches, tel que le syst√®me trois tiers par exemple, se base sur le principe de s√©paration des donn√©es et du traitement. On trouve en g√©n√©ral des donn√©es sur un serveur de bases de donn√©es s√©par√©, et les traitement complexes sur un serveur d'application qui se charge de l'aggr√©gation et de l'affichage de ces donn√©es. Ceci est agr√©ment√© d'un langage de requ√™tage d√©claratif (typiquement SQL) pour r√©aliser des op√©rations de filtrage, parfois assez lourdes et complexes, au niveau de la base de donn√©es.

Cela dit, dans un contexte Big Data, le volume des donn√©es peut s'av√©rer assez cons√©quent, trop m√™me pour envisager de le d√©placer √† chaque fois vers un autre syst√®me pour en extraire une vraie valeur. De plus, compter sur un langage comme SQL pour diminuer le volume ou faire de simples agr√©gations au niveau de la base de donn√©es pourra la rendre indisponible pendant un moment, ce qui va √† l'encontre du principe de v√©locit√©, qui exige une disponibilit√© √† toute √©preuve du syst√®me de stockage.

C'est pour cette raison que, pour r√©aliser les traitements voulus en un temps raisonnable et sans avoir √† trimballer les donn√©es sur le r√©seau, il est question dans les syst√®mes Big Data de d√©placer le traitement vers les donn√©es massives, au lieu de d√©placer les donn√©es vers le traitement.

**_MOTTO 5 :_ La redondance, c'est bien**
Dans les bases de donn√©es relationnelles, le plus grand ennemi √† combattre dans la conception de la structure de donn√©es et la redondance, et ce pour deux raisons. La premi√®re, √©vidente, est le gain d'espace : notre espace de stockage est pr√©cieux, et nous devons √©viter de le gaspiller sans raison pr√©cise. La deuxi√®me est un besoin de coh√©rence : si nous dupliquons une m√™me information √† plusieurs endroits dans la base, nous devrons par la suite faire attention, parfois par des m√©canismes compliqu√©s et co√ªteux, √† ce que cette information soit mise √† jour instantan√©ment sur la totalit√© de ses copies.

Ce besoin d'√©viter la redondance a cr√©√© la n√©cessit√© d'utiliser plusieurs techniques, telles que les jointures et clefs √©trang√®res, et entra√Æne parfois la cr√©ation d'un tr√®s grand nombre de tables. Ceci rajoute une complexit√© pour le requ√™tage, et une lourdeur d'ex√©cution des t√¢ches sur la base.

Un syst√®me Big Data qui, non seulement est caract√©ris√© par un gros volume de donn√©es, mais √©galement une grande v√©locit√©, et qui doit donc √™tre imm√©diatement disponible, ne peut pas se permettre de gaspiller ses ressources en requ√™tes inutiles. On tol√®re donc √† un certain point les risques dus √† la redondance, pour gagner en disponibilit√©, primordiale dans ce type de syst√®mes.

D'autre part, un syst√®me Big Data est un syst√®me r√©parti par excellence, et dans un syst√®me r√©parti, il est primordial d'assurer une bonne tol√©rance aux fautes en cr√©ant des r√©pliques des donn√©es, diss√©min√©es partout sur le cluster. Ces r√©pliques assurent qu'aucune machine n'est compl√®tement indispensable, et diminue le risque d'indisponibilit√© des donn√©es.

**_MOTTO 6 :_ Vive le Polyglottisme!**
√ätre polyglotte, c'est √™tre capable de parler plusieurs langues. Et les syst√®mes Big Data encouragent le polyglottisme. En effet, ce sont des syst√®mes complexes qui impliquent en g√©n√©ral plusieurs traitements et plusieurs types de donn√©es diff√©rentes (donn√©es brutes, donn√©es nettoy√©es, donn√©es trait√©es), ce qui fait qu'il existe deux principes importants √† encourager :

  - _Polyglot Programming_ : Une application peut comporter plusieurs langages et paradigmes de programmation, chacun assurant un besoin particulier, de fa√ßon √† profiter des avantages de chacun √† sa juste valeur.
  - _Polyglot Persistence_ : Dans une m√™me application, il est possible d'utiliser plusieurs syst√®mes de stockage diff√©rents (relationnels, nosql, syst√®mes de fichiers, etc.).

Gr√¢ce √† ces deux principes, on pourra cr√©er des applications complexes mais compl√®tes, qui permettent d'assurer tous les besoins en terme de stockage et de traitement.



## Technologies et Paradigmes
### Technologies d'Ingestion de Donn√©es

### Technologies de Stockage de Donn√©es

### Technologies de Traitement de Donn√©es
