{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Atelier Apache Spark Ce(tte) \u0153uvre est mise \u00e0 disposition selon les termes de la Licence Creative Commons Attribution - Pas d\u2019Utilisation Commerciale - Partage dans les M\u00eames Conditions 4.0 International . Overview L'objectif de ce cours est d'initier les apprenants aux concepts de base de Apache Spark, et de faire le tours des composants qui le constituent et des cas d'utilisation. Ce cours est renforc\u00e9 par des travaux pratiques.","title":"Atelier Apache Spark"},{"location":"#atelier-apache-spark","text":"Ce(tte) \u0153uvre est mise \u00e0 disposition selon les termes de la Licence Creative Commons Attribution - Pas d\u2019Utilisation Commerciale - Partage dans les M\u00eames Conditions 4.0 International .","title":"Atelier Apache Spark"},{"location":"#overview","text":"L'objectif de ce cours est d'initier les apprenants aux concepts de base de Apache Spark, et de faire le tours des composants qui le constituent et des cas d'utilisation. Ce cours est renforc\u00e9 par des travaux pratiques.","title":"Overview"},{"location":"p1-big-data/","text":"Partie 1 - Introduction au Big Data Les \"Big Data\", Pourquoi? L'\u00eatre humain, \u00e0 travers l'humanit\u00e9, a toujours cherch\u00e9 trois choses: Savoir (qu'est-ce qui s'est pass\u00e9?), Comprendre (pourquoi cela s'est-il pass\u00e9?) et Pr\u00e9dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam\u00e9 l'omniscience en ayant recours \u00e0 des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal. Cela dit, ces moyens ne sont gu\u00e8res satisfaisants \u00e0 l'esprit m\u00e9ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle \u00e0 tout \u00e9v\u00e8nement, et une justification convainquante \u00e0 tout comportement. Le scientifique se base sur des faits. Il veut arriver \u00e0 faire de la magie gr\u00e2ce \u00e0 la technologie. Pour arriver \u00e0 ces fins, le scientifique a besoin de donn\u00e9es. L'int\u00e9r\u00eat de collecter des donn\u00e9es et de les exploiter a longtemps \u00e9t\u00e9 n\u00e9glig\u00e9, et a \u00e9t\u00e9 limit\u00e9 au peu de donn\u00e9es, jug\u00e9es \"utiles\", qui semblaient suffisantes pour atteindre un objectif imm\u00e9diat. Cependant, adopter le chemin \u00e9vident et peu risqu\u00e9 n'aurait jamais permis de r\u00e9aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen.. Le terme Big Data est apparu peu de temps apr\u00e8s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une \u00e8re o\u00f9 l'ajout des donn\u00e9es \u00e9tait exclusivement r\u00e9serv\u00e9 \u00e0 une \u00e9lite experte, o\u00f9 le volume des donn\u00e9es disponible \u00e9tait petit mais o\u00f9 les donn\u00e9es \u00e9taient pr\u00e9cieuses et pertinentes, vers une \u00e8re o\u00f9 tout un chacun \u00e9tait capable d'introduire des connaissances, v\u00e9ridiques ou pas, qui seraient sauvegard\u00e9es dans une m\u00e9moire collective jusqu'\u00e0 la fin des temps. Ce changement de paradigme a entrain\u00e9 le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn\u00e9es, mais \u00e9galement d'en extraire de la valeur. Ces infrastructures auront la capacit\u00e9 de g\u00e9rer toute la cha\u00eene logistique des donn\u00e9es, de la collecte vers l'affichage. Cela semble \u00e9vident, me direz-vous, car les syst\u00e8mes classiques sont capables de faire cela. Qui stocke mieux les donn\u00e9es qu'une bonne vieille base de donn\u00e9es relationnelle? Le probl\u00e8me est que les donn\u00e9es dites \"Big Data\" sont caract\u00e9ris\u00e9es par des propri\u00e9t\u00e9s telles que, les syst\u00e8mes classiques de stockage et de traitement auraient du mal \u00e0 les exploiter \u00e0 leur juste valeur. Caract\u00e9ristiques des Donn\u00e9es Massives Le terme \"donn\u00e9es massives\", ou \"Big Data\", ne donne \u00e0 mon avis pas enti\u00e8rement justice aux donn\u00e9es de notre domaine. En effet, il repr\u00e9sente une seule caract\u00e9ristique parmis plusieurs, qui est le Volume, qui, m\u00eame si elle semble \u00eatre la plus importante, est loin d'\u00eatre la plus critique. En effet, les donn\u00e9es massives sont caract\u00e9ris\u00e9es par les fameux *V. Il en existe plusieurs (11 jusqu'\u00e0 ce jour si je ne m'abuse), mais pourraient \u00e0 mon avis \u00eatre r\u00e9sum\u00e9s en trois caract\u00e9ristiques primordiales, autours de la combinaison desquelles tournent toutes les d\u00e9cisions prises dans ce domaine. Volume : C'est \u00e9videmment le V le plus manifeste, qui caract\u00e9rise le fait que les donn\u00e9es ont un volume \u00e9norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'\u00e0 2^{80} 2^{80} octets!). Mais ceci n'est pas tout. Un volume \u00e9norme, s'il reste constant, est g\u00e9rable: il suffit de trouver une machine suffisamment puissante pour le g\u00e9rer. Le probl\u00e8me avec la propri\u00e9t\u00e9 du volume, c'est qu'il augmente de fa\u00e7on continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann\u00e9e, atteste que \"Over the last two years alone 90 percent of the data in the world was generated.\" Il est donc primordial de trouver un moyen de g\u00e9rer ce volume toujours croissant des donn\u00e9es. V\u00e9locit\u00e9 : Cette propri\u00e9t\u00e9 est, \u00e0 mon avis, la plus probl\u00e9matique des trois, car, coupl\u00e9e avec le volume, elle rend les syst\u00e8me actuels obsol\u00e8tes. En effet, la v\u00e9locit\u00e9 est, litt\u00e9ralement, \"La vitesse avec laquelle quelque chose se d\u00e9place dans une direction particuli\u00e8re\". Dans notre cas, la v\u00e9locit\u00e9 des donn\u00e9es est la responsable directe du volume croissant des donn\u00e9es dans le syst\u00e8me. Elle est provoqu\u00e9e par une arriv\u00e9e des donn\u00e9es dans le syst\u00e8me sous la forme d'un flux constant qui demande \u00e0 \u00eatre stock\u00e9 et trait\u00e9 imm\u00e9diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr\u00e9sentation r\u00e9cente et fid\u00e8le de l'\u00e9tat des donn\u00e9es. D'ailleurs, cette propri\u00e9t\u00e9 a engendr\u00e9 une autre pr\u00e9occupation des analystes des donn\u00e9es, qui est de fournir une introspection en temps r\u00e9el sur les donn\u00e9es, les qualifiant ainsi de \"Fast Data\". Vari\u00e9t\u00e9 : Principes de base du Domaine des Big Data Stocker d'abord, r\u00e9fl\u00e9chir ensuite Absolument TOUTES les donn\u00e9es sont importantes! Ce sont les donn\u00e9es qui pilotent le traitement La redondance, c'est bien Sois Polyglotte! Infrastructure Big Data: Besoins Th\u00e9or\u00e8me CAP Technologies et Paradigmes Technologies d'Ingestion de Donn\u00e9es Technologies de Stockage de Donn\u00e9es Technologies de Traitement de Donn\u00e9es","title":"Partie 1 - Introduction au Big Data"},{"location":"p1-big-data/#partie-1-introduction-au-big-data","text":"","title":"Partie 1 - Introduction au Big Data"},{"location":"p1-big-data/#les-big-data-pourquoi","text":"L'\u00eatre humain, \u00e0 travers l'humanit\u00e9, a toujours cherch\u00e9 trois choses: Savoir (qu'est-ce qui s'est pass\u00e9?), Comprendre (pourquoi cela s'est-il pass\u00e9?) et Pr\u00e9dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam\u00e9 l'omniscience en ayant recours \u00e0 des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal. Cela dit, ces moyens ne sont gu\u00e8res satisfaisants \u00e0 l'esprit m\u00e9ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle \u00e0 tout \u00e9v\u00e8nement, et une justification convainquante \u00e0 tout comportement. Le scientifique se base sur des faits. Il veut arriver \u00e0 faire de la magie gr\u00e2ce \u00e0 la technologie. Pour arriver \u00e0 ces fins, le scientifique a besoin de donn\u00e9es. L'int\u00e9r\u00eat de collecter des donn\u00e9es et de les exploiter a longtemps \u00e9t\u00e9 n\u00e9glig\u00e9, et a \u00e9t\u00e9 limit\u00e9 au peu de donn\u00e9es, jug\u00e9es \"utiles\", qui semblaient suffisantes pour atteindre un objectif imm\u00e9diat. Cependant, adopter le chemin \u00e9vident et peu risqu\u00e9 n'aurait jamais permis de r\u00e9aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen.. Le terme Big Data est apparu peu de temps apr\u00e8s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une \u00e8re o\u00f9 l'ajout des donn\u00e9es \u00e9tait exclusivement r\u00e9serv\u00e9 \u00e0 une \u00e9lite experte, o\u00f9 le volume des donn\u00e9es disponible \u00e9tait petit mais o\u00f9 les donn\u00e9es \u00e9taient pr\u00e9cieuses et pertinentes, vers une \u00e8re o\u00f9 tout un chacun \u00e9tait capable d'introduire des connaissances, v\u00e9ridiques ou pas, qui seraient sauvegard\u00e9es dans une m\u00e9moire collective jusqu'\u00e0 la fin des temps. Ce changement de paradigme a entrain\u00e9 le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn\u00e9es, mais \u00e9galement d'en extraire de la valeur. Ces infrastructures auront la capacit\u00e9 de g\u00e9rer toute la cha\u00eene logistique des donn\u00e9es, de la collecte vers l'affichage. Cela semble \u00e9vident, me direz-vous, car les syst\u00e8mes classiques sont capables de faire cela. Qui stocke mieux les donn\u00e9es qu'une bonne vieille base de donn\u00e9es relationnelle? Le probl\u00e8me est que les donn\u00e9es dites \"Big Data\" sont caract\u00e9ris\u00e9es par des propri\u00e9t\u00e9s telles que, les syst\u00e8mes classiques de stockage et de traitement auraient du mal \u00e0 les exploiter \u00e0 leur juste valeur.","title":"Les \"Big Data\", Pourquoi?"},{"location":"p1-big-data/#caracteristiques-des-donnees-massives","text":"Le terme \"donn\u00e9es massives\", ou \"Big Data\", ne donne \u00e0 mon avis pas enti\u00e8rement justice aux donn\u00e9es de notre domaine. En effet, il repr\u00e9sente une seule caract\u00e9ristique parmis plusieurs, qui est le Volume, qui, m\u00eame si elle semble \u00eatre la plus importante, est loin d'\u00eatre la plus critique. En effet, les donn\u00e9es massives sont caract\u00e9ris\u00e9es par les fameux *V. Il en existe plusieurs (11 jusqu'\u00e0 ce jour si je ne m'abuse), mais pourraient \u00e0 mon avis \u00eatre r\u00e9sum\u00e9s en trois caract\u00e9ristiques primordiales, autours de la combinaison desquelles tournent toutes les d\u00e9cisions prises dans ce domaine. Volume : C'est \u00e9videmment le V le plus manifeste, qui caract\u00e9rise le fait que les donn\u00e9es ont un volume \u00e9norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'\u00e0 2^{80} 2^{80} octets!). Mais ceci n'est pas tout. Un volume \u00e9norme, s'il reste constant, est g\u00e9rable: il suffit de trouver une machine suffisamment puissante pour le g\u00e9rer. Le probl\u00e8me avec la propri\u00e9t\u00e9 du volume, c'est qu'il augmente de fa\u00e7on continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann\u00e9e, atteste que \"Over the last two years alone 90 percent of the data in the world was generated.\" Il est donc primordial de trouver un moyen de g\u00e9rer ce volume toujours croissant des donn\u00e9es. V\u00e9locit\u00e9 : Cette propri\u00e9t\u00e9 est, \u00e0 mon avis, la plus probl\u00e9matique des trois, car, coupl\u00e9e avec le volume, elle rend les syst\u00e8me actuels obsol\u00e8tes. En effet, la v\u00e9locit\u00e9 est, litt\u00e9ralement, \"La vitesse avec laquelle quelque chose se d\u00e9place dans une direction particuli\u00e8re\". Dans notre cas, la v\u00e9locit\u00e9 des donn\u00e9es est la responsable directe du volume croissant des donn\u00e9es dans le syst\u00e8me. Elle est provoqu\u00e9e par une arriv\u00e9e des donn\u00e9es dans le syst\u00e8me sous la forme d'un flux constant qui demande \u00e0 \u00eatre stock\u00e9 et trait\u00e9 imm\u00e9diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr\u00e9sentation r\u00e9cente et fid\u00e8le de l'\u00e9tat des donn\u00e9es. D'ailleurs, cette propri\u00e9t\u00e9 a engendr\u00e9 une autre pr\u00e9occupation des analystes des donn\u00e9es, qui est de fournir une introspection en temps r\u00e9el sur les donn\u00e9es, les qualifiant ainsi de \"Fast Data\". Vari\u00e9t\u00e9 :","title":"Caract\u00e9ristiques des Donn\u00e9es Massives"},{"location":"p1-big-data/#principes-de-base-du-domaine-des-big-data","text":"","title":"Principes de base du Domaine des Big Data"},{"location":"p1-big-data/#stocker-dabord-reflechir-ensuite","text":"","title":"Stocker d'abord, r\u00e9fl\u00e9chir ensuite"},{"location":"p1-big-data/#absolument-toutes-les-donnees-sont-importantes","text":"","title":"Absolument TOUTES les donn\u00e9es sont importantes!"},{"location":"p1-big-data/#ce-sont-les-donnees-qui-pilotent-le-traitement","text":"","title":"Ce sont les donn\u00e9es qui pilotent le traitement"},{"location":"p1-big-data/#la-redondance-cest-bien","text":"","title":"La redondance, c'est bien"},{"location":"p1-big-data/#sois-polyglotte","text":"","title":"Sois Polyglotte!"},{"location":"p1-big-data/#infrastructure-big-data-besoins","text":"","title":"Infrastructure Big Data: Besoins"},{"location":"p1-big-data/#theoreme-cap","text":"","title":"Th\u00e9or\u00e8me CAP"},{"location":"p1-big-data/#technologies-et-paradigmes","text":"","title":"Technologies et Paradigmes"},{"location":"p1-big-data/#technologies-dingestion-de-donnees","text":"","title":"Technologies d'Ingestion de Donn\u00e9es"},{"location":"p1-big-data/#technologies-de-stockage-de-donnees","text":"","title":"Technologies de Stockage de Donn\u00e9es"},{"location":"p1-big-data/#technologies-de-traitement-de-donnees","text":"","title":"Technologies de Traitement de Donn\u00e9es"},{"location":"tips/","text":"italique input gras 50070 image ou lien Apache Hadoop code git clone https : //github.com/liliasfaxi/hadoop-cluster-docker inline code hadoop fs - mkdir - p / user / root Attention blablabla Erreur blablabla tables |Instruction|Fonctionnalit\u00e9| |---------|-------------------------------------------------------------| | hadoop fs \u2013 ls | Afficher le contenu du re\u0301pertoire racine | | hadoop fs \u2013 put file . txt | Upload un fichier dans hadoop (a\u0300 partir du re\u0301pertoire courant linux) | | hadoop fs \u2013 get file . txt | Download un fichier a\u0300 partir de hadoop sur votre disque local | | hadoop fs \u2013 tail file . txt | Lire les dernie\u0300res lignes du fichier | | hadoop fs \u2013 cat file . txt | Affiche tout le contenu du fichier | | hadoop fs \u2013 mv file . txt newfile . txt | Renommer le fichier | | hadoop fs \u2013 rm newfile . txt | Supprimer le fichier | | hadoop fs \u2013 mkdir myinput | Cre\u0301er un re\u0301pertoire | | hadoop fs \u2013 cat file . txt \\ | less | Lire le fichier page par page|","title":"Tips"}]}