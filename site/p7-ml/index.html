<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Lilia Sfaxi">
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p7-ml/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>P7 - Spark MLLib - Atelier Apache Spark</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Atelier Apache Spark</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Atelier Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p1-big-data/" class="nav-link">P1 - Introduction au Big Data</a>
                            </li>
                            <li class="navitem">
                                <a href="../p2-spark/" class="nav-link">P2 - Introduction à Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p3-install/" class="nav-link">P3 - Installation de Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p4-batch/" class="nav-link">P4 - RDD et Batch Processing avec Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p5-sql/" class="nav-link">P5 - Spark SQL</a>
                            </li>
                            <li class="navitem">
                                <a href="../p6-stream/" class="nav-link">P6 - Spark Streaming</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">P7 - Spark MLLib</a>
                            </li>
                            <li class="navitem">
                                <a href="../p8-graphx/" class="nav-link">P8 - Spark GraphX</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../p6-stream/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../p8-graphx/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p7-ml.md" class="nav-link">Edit on liliasfaxi/Atelier-Spark</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#partie-7-spark-mllib" class="nav-link">Partie 7 - Spark MLLib</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#presentation-de-spark-mllib" class="nav-link">Présentation de Spark MLLib</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#chargement-des-donnees" class="nav-link">Chargement des données</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#ml-pipelines" class="nav-link">ML Pipelines</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#references" class="nav-link">Références</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="partie-7-spark-mllib">Partie 7 - Spark MLLib</h1>
<p><center><img src="../img/p7/ml.jpg" width="600pt"></center></p>
<h2 id="presentation-de-spark-mllib">Présentation de Spark MLLib</h2>
<p>Spark MLLib[^spark-official] est la librairie d'apprentissage automatique (Machine Learning) de Spark. Son but est de rendre son utilisation facile et scalable. À un haut niveau d'abstraction, elle fournit des outils tel que:</p>
<ul>
<li>Des algorithmes de machine learning classiques tel que la classification, régression, clustering et filtrage collaboratif.</li>
<li>L'extraction de caractéristiques (<em>Features</em>), transformation, réduction de dimensions et sélection</li>
<li>Les pipelines pour construire, évaluer et régler les pipelines ML.</li>
<li>La persistence, pour sauvegarder et charger des algorithmes, modèles et pipelines.</li>
<li>Des utilitaires tel que l'algèbre linéaire, statistiques, manipulation des données, etc.</li>
</ul>
<p>A partir de la version 2.0 de Spark, la structure principale utilisée pour l'API MLlib est DataFrame, en opposition aux RDD, car son utilisation est plus intuitive et uniforme, et qu'elle facilite les transformations.</p>
<h2 id="chargement-des-donnees">Chargement des données</h2>
<p>Nous allons montrer dans cette partie comment utiliser des sources de données pour charger des données avec MLLib. En plus des sources de données classiques tel que Parquet, CSV, JSON et JDBC, des sources spécifiques pour l'apprentissage numérique sont fournies, tel que la source de données pour les images (<em>image data source</em>).</p>
<p>Cette source de données est utilisée pour chager des images à partir d'un répertoire. Elle transforme les images compressées (jpeg, png, etc.) en représentation brute via la librairie Java <strong>ImageIO</strong>. Le DataFrame chargé admet une seule colonne de type <em>StructType</em>, appelé <strong>image</strong>, contenant les données de l'image stockées dans un schéma, comme suit:</p>
<p><center></p>
<table>
<thead>
<tr>
<th>Nom</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>origin</code></td>
<td>StringType</td>
<td>représente le chemin du fichier image</td>
</tr>
<tr>
<td><code>height</code></td>
<td>IntegerType</td>
<td>La hauteur de l'image</td>
</tr>
<tr>
<td><code>width</code></td>
<td>IntegerType</td>
<td>La largeur de l'image</td>
</tr>
<tr>
<td><code>nChannels</code></td>
<td>IntegerType</td>
<td>Le nombre de canaux de l'image</td>
</tr>
<tr>
<td><code>mode</code></td>
<td>IntegerType</td>
<td>Le type compatible OpenCV</td>
</tr>
<tr>
<td><code>data</code></td>
<td>BinaryType</td>
<td>Les octets de l'image dans un ordre compatible à OpenCV</td>
</tr>
</tbody>
</table>
<p></center></p>
<p>Pour charger des fichiers images , une API en SparkSQL est fournie:</p>
<p><code>scala
  val df = spark.read.format("image").option("dropInvalid", true).load("&lt;chemin_du_répertoire_contenant_les_images&gt;")</code>
Un DataFrame sera alors créé, dont la structure est présentée dans le tableau précédent, contenant les informations relatives aux images contenues dans le répertoire donné.</p>
<h2 id="ml-pipelines">ML Pipelines</h2>
<p>Les pipelines ML fournissent un ensemble uniforme d'APIs au dessus des DataFrames, permettant de créer et accorder (<em>tune</em>) des pipelines pratiques de machine learning.</p>
<h3 id="definition-des-pipelines">Définition des Pipelines</h3>
<p>En machine learning, il est commun d'exécuter une séquence d'algorithmes pour traiter et apprendre à partir de données. Par exemple, un flux de traitement d'un document texte peut inclure les étapes suivantes:</p>
<ul>
<li>Diviser chaque document en mots</li>
<li>Convertir chaque mot en vecteur de caractéristiques numériques</li>
<li>Créer un modèle prédictif en utiliser les vecteurs et les labels</li>
</ul>
<p>MLLib permet de créer de tels flux (ou pipelines), en définissant une séquence de <code>PipelineStage</code>s, composés de <code>Transformer</code>s et de <code>Estimator</code>s, qui doivent être exécutés dans un certain ordre.</p>
<ul>
<li><code>Transformer</code>: Algorithme qui peut transformer un DataFrame en un autre DataFrame. Par exemple, un modèle ML est un <code>Transformer</code> qui transforme un DataFrame avec des caractéristiques (ou <em>features</em>), en un DataFrame avec des prédictions.</li>
<li><code>Estimator</code>: Algorithme qui peut être appliqué sur un DataFrame pour produire un <code>Transformer</code>. Par exemple, un algorithme d'apprentissage est un <code>Estimator</code> qui s'entraîne sur un DataFrame pour produire un modèle.</li>
</ul>
<h3 id="fonctionnement-des-pipelines">Fonctionnement des Pipelines</h3>
<p>Un pipeline est un ensemble d'étapes, où chaque étape est soit un <code>Transformer</code> soit un <code>Estimator</code>. Ces étapes sont exécutés dans l'ordre, et le DataFrame en entrée est transformé au fur et à mesure de son passage à travers ces étapes. Pour les étapes exécutant un <code>Transformer</code>, la méthode <em>transform()</em> est appelée sur le DataFrame, alors que pour les étapes exécutant un <code>Estimator</code>, c'est la fonction <em>fit()</em> qui est appelée, résultant en la création d'un <code>Transformer</code>, qui à son tour, devient une partie de la Pipeline.</p>
<h3 id="exemple-de-pipeline">Exemple de Pipeline</h3>
<p>Pour illustrer le fonctionnement des Pipelines, l'exemple suivant est présenté:</p>
<p><img alt="Exemple de Pipeline" src="../img/p7/pipeline.png" /></p>
<p>Cette pipeline montre l'application d'un modèle de régression linéaire pour la prédiction de la valeur d'un label à partir d'un texte. La méthode <code>Pipeline.fit()</code> est initialement appelée sur le DataFrame originel (<em>Raw Text</em>),  qui contient des documents textes bruts et des labels. La méthode <code>Tokenizer.transform()</code> divise les documents texte en mots, en  rajoutant une nouvelle colonne contenant ces mots à la DataFrame. La méthode <code>HashingTF.transform()</code> convertit les mots en vecteurs de features. Ensuite, puisque <code>LogisticRegression</code> est un <code>Estimator</code>, la pipeline appelle <code>LogisticRegression.fit()</code> pour créer le <code>Transformer</code>: <code>LogisticRegressionModel</code>, qui est à son tour utilisé pour produire un nouveau DataFrame contenant les prédictions.</p>
<p>L'exemple présenté ci-dessus est réalisé grâce au code suivant (ce code est écrit dans le langage Python):</p>
<p>```python
  from pyspark.ml import Pipeline
  from pyspark.ml.classification import LogisticRegression
  from pyspark.ml.feature import HashingTF, Tokenizer
  from pyspark.sql import SQLContext
  from pyspark import SparkContext</p>
<p>sc = SparkContext(appName="Linear Regression Pipeline")
  spark = SQLContext(sc)</p>
<p># Préparer des documents de training à partir d'une liste de tuples (id, text, label). On remarque ici qu'un label =1 si la texte en question contient le mot spark
  training = spark.createDataFrame([
    (0, "a b c d e spark", 1.0),
    (1, "b d", 0.0),
    (2, "spark f g h", 1.0),
    (3, "hadoop mapreduce", 0.0)
  ], ["id", "text", "label"])</p>
<p># Configurer une pipeline, qui consiste en trois étapes: tokenizer, hashingTF, and lr.
  tokenizer = Tokenizer(inputCol="text", outputCol="words")
  hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol="features")
  lr = LogisticRegression(maxIter=10, regParam=0.001)
  pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</p>
<p># Adapter la pipeline aux documents de training.
  model = pipeline.fit(training)</p>
<p># Preparer les documents de test,qui ne sont pas labellisés, donc composés de tuples (id, text).
  test = spark.createDataFrame([
    (4, "spark i j k"),
    (5, "l m n"),
    (6, "spark hadoop spark"),
    (7, "apache hadoop")
  ], ["id", "text"])</p>
<p># Réaliser des prédictions sur les documents de test et afficher les colonnes significatives.
  prediction = model.transform(test)
  selected = prediction.select("id", "text", "probability", "prediction")
  for row in selected.collect():
    rid, text, prob, prediction = row
    print("(%d, %s) --&gt; prob=%s, prediction=%f" % (rid, text, str(prob), prediction))
  ```
Pour exécuter ce code sur notre cluster, nous allons suivre les étapes suivantes:</p>
<ul>
<li>Lancer le cluster spark:
  <code>Bash
    docker start spark-master spark-slave1 spark-slave2</code></li>
<li>Vous connecter sur la machine master:
  <code>Bash
    docker exec -it spark-master bash</code></li>
<li>Il faudra d'abord mettre en place l'environnement de votre cluster pour pouvoir exécuter le code en Python (dépassez ces étapes si vous avez déjà utilisé <code>pyspark</code>). PySpark est la bibliothèque Python de Spark. Il faut suivre les étapes suivantes pour l'utiliser:<ul>
<li>Insérer la variable d'environnement suivante dans le fichier ~/.bashrc: <code>export PYSPARK_PYTHON=python3</code>. Pyspark utilisera ainsi la version 3 de python.</li>
<li>Charger cette variable en tapant <code>source ~/.bashrc</code></li>
<li>Installer le gestionnaire de packages <code>pip3</code>: <code>apt install python3-pip</code></li>
</ul>
</li>
<li>Certains packages sont manquants pour faire marcher votre code. Il faut installer les packages suivants:
      <code>bash
        pip3 install numpy spark</code></li>
<li>Créer un fichier <code>pipeline.py</code> dans lequel vous allez copier le code présenté ci-dessus</li>
<li>Pour lancer votre application, exécuter:
  <code>bash
    spark-submit pipeline.py</code></li>
</ul>
<p>Le résultat de la prédiction s'affichera sur votre console, comme suit:</p>
<p><img alt="Pipeline - Prédiction" src="../img/p7/prediction.png" /></p>
<p>On remarque, d'après le résultat précédent, que notre pipeline a réussi sa prédiction, en affectant à chacune des phrases contenant le mot <em>spark</em> une valeur de label égale à 1, ce qui était l'objectif de notre modèle.</p>
<h2 id="references">Références</h2>
<p>[^spark-official]:
  Spark Documentation, <em>Spark MLLib Guide</em>, <a href="https://spark.apache.org/docs/latest/ml-guide.html">https://spark.apache.org/docs/latest/ml-guide.html</a>, consulté le 04/2020</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2019 - 2020 Lilia Sfaxi</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
