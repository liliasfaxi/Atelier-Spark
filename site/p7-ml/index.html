



<!doctype html>
<html lang="fr" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Cours et Travaux Pratiques pour se familiariser avec Apache Spark">
      
      
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p7-ml/">
      
      
        <meta name="author" content="Lilia Sfaxi">
      
      
        <meta name="lang:clipboard.copy" content="Copier dans le presse-papier">
      
        <meta name="lang:clipboard.copied" content="Copié dans le presse-papier">
      
        <meta name="lang:search.language" content="fr">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="Aucun document trouvé">
      
        <meta name="lang:search.result.one" content="1 document trouvé">
      
        <meta name="lang:search.result.other" content="# documents trouvés">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>P7 - Spark MLLib - Atelier Apache Spark</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#546e7a">
      
    
    
      <script src="../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="blue-grey" data-md-color-accent="amber">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#partie-7-spark-mllib" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://liliasfaxi.github.io/Atelier-Spark/" title="Atelier Apache Spark" class="md-header-nav__button md-logo">
          
            <img src="../img/logo.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Atelier Apache Spark
            </span>
            <span class="md-header-nav__topic">
              
                P7 - Spark MLLib
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Rechercher" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Taper pour démarrer la recherche
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/liliasfaxi/Atelier-Spark/" title="Aller au dépôt" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    liliasfaxi/Atelier-Spark
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://liliasfaxi.github.io/Atelier-Spark/" title="Atelier Apache Spark" class="md-nav__button md-logo">
      
        <img src="../img/logo.png" width="48" height="48">
      
    </a>
    Atelier Apache Spark
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/liliasfaxi/Atelier-Spark/" title="Aller au dépôt" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    liliasfaxi/Atelier-Spark
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Atelier Apache Spark" class="md-nav__link">
      Atelier Apache Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p1-big-data/" title="P1 - Introduction au Big Data" class="md-nav__link">
      P1 - Introduction au Big Data
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p2-spark/" title="P2 - Introduction à Apache Spark" class="md-nav__link">
      P2 - Introduction à Apache Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p3-install/" title="P3 - Installation de Spark" class="md-nav__link">
      P3 - Installation de Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p4-batch/" title="P4 - RDD et Batch Processing avec Spark" class="md-nav__link">
      P4 - RDD et Batch Processing avec Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p5-sql/" title="P5 - Spark SQL" class="md-nav__link">
      P5 - Spark SQL
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p6-stream/" title="P6 - Spark Streaming" class="md-nav__link">
      P6 - Spark Streaming
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        P7 - Spark MLLib
      </label>
    
    <a href="./" title="P7 - Spark MLLib" class="md-nav__link md-nav__link--active">
      P7 - Spark MLLib
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table des matières</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#presentation-de-spark-mllib" class="md-nav__link">
    Présentation de Spark MLLib
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chargement-des-donnees" class="md-nav__link">
    Chargement des données
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ml-pipelines" class="md-nav__link">
    ML Pipelines
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#definition-des-pipelines" class="md-nav__link">
    Définition des Pipelines
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fonctionnement-des-pipelines" class="md-nav__link">
    Fonctionnement des Pipelines
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exemple-de-pipeline" class="md-nav__link">
    Exemple de Pipeline
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    Références
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table des matières</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#presentation-de-spark-mllib" class="md-nav__link">
    Présentation de Spark MLLib
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chargement-des-donnees" class="md-nav__link">
    Chargement des données
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ml-pipelines" class="md-nav__link">
    ML Pipelines
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#definition-des-pipelines" class="md-nav__link">
    Définition des Pipelines
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fonctionnement-des-pipelines" class="md-nav__link">
    Fonctionnement des Pipelines
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exemple-de-pipeline" class="md-nav__link">
    Exemple de Pipeline
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    Références
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p7-ml.md" title="Editer cette page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="partie-7-spark-mllib">Partie 7 - Spark MLLib</h1>
<p><center><img src="../img/p7/ml.jpg" width="600pt"></center></p>
<h2 id="presentation-de-spark-mllib">Présentation de Spark MLLib</h2>
<p>Spark MLLib<sup id="fnref:spark-official"><a class="footnote-ref" href="#fn:spark-official">1</a></sup> est la librairie d'apprentissage automatique (Machine Learning) de Spark. Son but est de rendre son utilisation facile et scalable. À un haut niveau d'abstraction, elle fournit des outils tel que:</p>
<ul>
<li>Des algorithmes de machine learning classiques tel que la classification, régression, clustering et filtrage collaboratif.</li>
<li>L'extraction de caractéristiques (<em>Features</em>), transformation, réduction de dimensions et sélection</li>
<li>Les pipelines pour construire, évaluer et régler les pipelines ML.</li>
<li>La persistence, pour sauvegarder et charger des algorithmes, modèles et pipelines.</li>
<li>Des utilitaires tel que l'algèbre linéaire, statistiques, manipulation des données, etc.</li>
</ul>
<p>A partir de la version 2.0 de Spark, la structure principale utilisée pour l'API MLlib est DataFrame, en opposition aux RDD, car son utilisation est plus intuitive et uniforme, et qu'elle facilite les transformations.</p>
<h2 id="chargement-des-donnees">Chargement des données</h2>
<p>Nous allons montrer dans cette partie comment utiliser des sources de données pour charger des données avec MLLib. En plus des sources de données classiques tel que Parquet, CSV, JSON et JDBC, des sources spécifiques pour l'apprentissage numérique sont fournies, tel que la source de données pour les images (<em>image data source</em>).</p>
<p>Cette source de données est utilisée pour chager des images à partir d'un répertoire. Elle transforme les images compressées (jpeg, png, etc.) en représentation brute via la librairie Java <strong>ImageIO</strong>. Le DataFrame chargé admet une seule colonne de type <em>StructType</em>, appelé <strong>image</strong>, contenant les données de l'image stockées dans un schéma, comme suit:</p>
<p><center></p>
<table>
<thead>
<tr>
<th>Nom</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code class="codehilite"><span class="n">origin</span></code></td>
<td>StringType</td>
<td>représente le chemin du fichier image</td>
</tr>
<tr>
<td><code class="codehilite"><span class="n">height</span></code></td>
<td>IntegerType</td>
<td>La hauteur de l'image</td>
</tr>
<tr>
<td><code class="codehilite"><span class="n">width</span></code></td>
<td>IntegerType</td>
<td>La largeur de l'image</td>
</tr>
<tr>
<td><code class="codehilite"><span class="n">nChannels</span></code></td>
<td>IntegerType</td>
<td>Le nombre de canaux de l'image</td>
</tr>
<tr>
<td><code class="codehilite"><span class="n">mode</span></code></td>
<td>IntegerType</td>
<td>Le type compatible OpenCV</td>
</tr>
<tr>
<td><code class="codehilite"><span class="n">data</span></code></td>
<td>BinaryType</td>
<td>Les octets de l'image dans un ordre compatible à OpenCV</td>
</tr>
</tbody>
</table>
<p></center></p>
<p>Pour charger des fichiers images , une API en SparkSQL est fournie:</p>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;image&quot;</span><span class="o">).</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;dropInvalid&quot;</span><span class="o">,</span> <span class="kc">true</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;&lt;chemin_du_répertoire_contenant_les_images&gt;&quot;</span><span class="o">)</span>
</pre></div>
</td></tr></table><br />
Un DataFrame sera alors créé, dont la structure est présentée dans le tableau précédent, contenant les informations relatives aux images contenues dans le répertoire donné.</p>
<h2 id="ml-pipelines">ML Pipelines</h2>
<p>Les pipelines ML fournissent un ensemble uniforme d'APIs au dessus des DataFrames, permettant de créer et accorder (<em>tune</em>) des pipelines pratiques de machine learning.</p>
<h3 id="definition-des-pipelines">Définition des Pipelines</h3>
<p>En machine learning, il est commun d'exécuter une séquence d'algorithmes pour traiter et apprendre à partir de données. Par exemple, un flux de traitement d'un document texte peut inclure les étapes suivantes:</p>
<ul>
<li>Diviser chaque document en mots</li>
<li>Convertir chaque mot en vecteur de caractéristiques numériques</li>
<li>Créer un modèle prédictif en utiliser les vecteurs et les labels</li>
</ul>
<p>MLLib permet de créer de tels flux (ou pipelines), en définissant une séquence de <code class="codehilite"><span class="n">PipelineStage</span></code>s, composés de <code class="codehilite"><span class="n">Transformer</span></code>s et de <code class="codehilite"><span class="n">Estimator</span></code>s, qui doivent être exécutés dans un certain ordre.</p>
<ul>
<li><code class="codehilite"><span class="n">Transformer</span></code>: Algorithme qui peut transformer un DataFrame en un autre DataFrame. Par exemple, un modèle ML est un <code class="codehilite"><span class="n">Transformer</span></code> qui transforme un DataFrame avec des caractéristiques (ou <em>features</em>), en un DataFrame avec des prédictions.</li>
<li><code class="codehilite"><span class="n">Estimator</span></code>: Algorithme qui peut être appliqué sur un DataFrame pour produire un <code class="codehilite"><span class="n">Transformer</span></code>. Par exemple, un algorithme d'apprentissage est un <code class="codehilite"><span class="n">Estimator</span></code> qui s'entraîne sur un DataFrame pour produire un modèle.</li>
</ul>
<h3 id="fonctionnement-des-pipelines">Fonctionnement des Pipelines</h3>
<p>Un pipeline est un ensemble d'étapes, où chaque étape est soit un <code class="codehilite"><span class="n">Transformer</span></code> soit un <code class="codehilite"><span class="n">Estimator</span></code>. Ces étapes sont exécutés dans l'ordre, et le DataFrame en entrée est transformé au fur et à mesure de son passage à travers ces étapes. Pour les étapes exécutant un <code class="codehilite"><span class="n">Transformer</span></code>, la méthode <em>transform()</em> est appelée sur le DataFrame, alors que pour les étapes exécutant un <code class="codehilite"><span class="n">Estimator</span></code>, c'est la fonction <em>fit()</em> qui est appelée, résultant en la création d'un <code class="codehilite"><span class="n">Transformer</span></code>, qui à son tour, devient une partie de la Pipeline.</p>
<h3 id="exemple-de-pipeline">Exemple de Pipeline</h3>
<p>Pour illustrer le fonctionnement des Pipelines, l'exemple suivant est présenté:</p>
<p><img alt="Exemple de Pipeline" src="../img/p7/pipeline.png" /></p>
<p>Cette pipeline montre l'application d'un modèle de régression linéaire pour la prédiction de la valeur d'un label à partir d'un texte. La méthode <code class="codehilite"><span class="n">Pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span></code> est initialement appelée sur le DataFrame originel (<em>Raw Text</em>),  qui contient des documents textes bruts et des labels. La méthode <code class="codehilite"><span class="n">Tokenizer</span><span class="p">.</span><span class="n">transform</span><span class="p">()</span></code> divise les documents texte en mots, en  rajoutant une nouvelle colonne contenant ces mots à la DataFrame. La méthode <code class="codehilite"><span class="n">HashingTF</span><span class="p">.</span><span class="n">transform</span><span class="p">()</span></code> convertit les mots en vecteurs de features. Ensuite, puisque <code class="codehilite"><span class="n">LogisticRegression</span></code> est un <code class="codehilite"><span class="n">Estimator</span></code>, la pipeline appelle <code class="codehilite"><span class="n">LogisticRegression</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span></code> pour créer le <code class="codehilite"><span class="n">Transformer</span></code>: <code class="codehilite"><span class="n">LogisticRegressionModel</span></code>, qui est à son tour utilisé pour produire un nouveau DataFrame contenant les prédictions.</p>
<p>L'exemple présenté ci-dessus est réalisé grâce au code suivant (ce code est écrit dans le langage Python):</p>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SQLContext</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>

<span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">appName</span><span class="o">=</span><span class="s">&quot;Linear Regression Pipeline&quot;</span><span class="p">)</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SQLContext</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>

<span class="c"># Préparer des documents de training à partir d&#39;une liste de tuples (id, text, label). On remarque ici qu&#39;un label =1 si la texte en question contient le mot spark</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s">&quot;a b c d e spark&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s">&quot;b d&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s">&quot;spark f g h&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s">&quot;hadoop mapreduce&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s">&quot;id&quot;</span><span class="p">,</span> <span class="s">&quot;text&quot;</span><span class="p">,</span> <span class="s">&quot;label&quot;</span><span class="p">])</span>

<span class="c"># Configurer une pipeline, qui consiste en trois étapes: tokenizer, hashingTF, and lr.</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s">&quot;words&quot;</span><span class="p">)</span>
<span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">(),</span> <span class="n">outputCol</span><span class="o">=</span><span class="s">&quot;features&quot;</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">hashingTF</span><span class="p">,</span> <span class="n">lr</span><span class="p">])</span>

<span class="c"># Adapter la pipeline aux documents de training.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>

<span class="c"># Preparer les documents de test,qui ne sont pas labellisés, donc composés de tuples (id, text).</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s">&quot;spark i j k&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s">&quot;l m n&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s">&quot;spark hadoop spark&quot;</span><span class="p">),</span>
  <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s">&quot;apache hadoop&quot;</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s">&quot;id&quot;</span><span class="p">,</span> <span class="s">&quot;text&quot;</span><span class="p">])</span>

<span class="c"># Réaliser des prédictions sur les documents de test et afficher les colonnes significatives.</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">selected</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;id&quot;</span><span class="p">,</span> <span class="s">&quot;text&quot;</span><span class="p">,</span> <span class="s">&quot;probability&quot;</span><span class="p">,</span> <span class="s">&quot;prediction&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">selected</span><span class="o">.</span><span class="n">collect</span><span class="p">():</span>
  <span class="n">rid</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="n">row</span>
  <span class="k">print</span><span class="p">(</span><span class="s">&quot;(</span><span class="si">%d</span><span class="s">, </span><span class="si">%s</span><span class="s">) --&gt; prob=</span><span class="si">%s</span><span class="s">, prediction=</span><span class="si">%f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">rid</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">prob</span><span class="p">),</span> <span class="n">prediction</span><span class="p">))</span>
</pre></div>
</td></tr></table><br />
Pour exécuter ce code sur notre cluster, nous allons suivre les étapes suivantes:</p>
<ul>
<li>Lancer le cluster spark:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">start</span> <span class="n">spark</span><span class="o">-</span><span class="n">master</span> <span class="n">spark</span><span class="o">-</span><span class="n">slave1</span> <span class="n">spark</span><span class="o">-</span><span class="n">slave2</span>
</pre></div>
</td></tr></table></li>
<li>Vous connecter sur la machine master:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="n">spark</span><span class="o">-</span><span class="n">master</span> <span class="n">bash</span>
</pre></div>
</td></tr></table></li>
<li>Il faudra d'abord mettre en place l'environnement de votre cluster pour pouvoir exécuter le code en Python (dépassez ces étapes si vous avez déjà utilisé <code class="codehilite"><span class="n">pyspark</span></code>). PySpark est la bibliothèque Python de Spark. Il faut suivre les étapes suivantes pour l'utiliser:<ul>
<li>Insérer la variable d'environnement suivante dans le fichier ~/.bashrc: <code class="codehilite"><span class="n">export</span> <span class="n">PYSPARK_PYTHON</span><span class="o">=</span><span class="n">python3</span></code>. Pyspark utilisera ainsi la version 3 de python.</li>
<li>Charger cette variable en tapant <code class="codehilite"><span class="n">source</span> <span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span></code></li>
<li>Installer le gestionnaire de packages <code class="codehilite"><span class="n">pip3</span></code>: <code class="codehilite"><span class="n">apt</span> <span class="n">install</span> <span class="n">python3</span><span class="o">-</span><span class="n">pip</span></code></li>
</ul>
</li>
<li>Certains packages sont manquants pour faire marcher votre code. Il faut installer les packages suivants:<br />
      <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  pip3 install numpy spark
</pre></div>
</td></tr></table></li>
<li>Créer un fichier <code class="codehilite"><span class="n">pipeline</span><span class="p">.</span><span class="n">py</span></code> dans lequel vous allez copier le code présenté ci-dessous</li>
<li>Pour lancer votre application, exécuter:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  spark-submit pipeline.py
</pre></div>
</td></tr></table></li>
</ul>
<p>Le résultat de la prédiction s'affichera sur votre console, comme suit:</p>
<p><img alt="Pipeline - Prédiction" src="../img/p7/prediction.png" /></p>
<p>On remarque, d'après le résultat précédent, que notre pipeline a réussi sa prédiction, en affectant à chacune des phrases contenant le mot <em>spark</em> une valeur de label égale à 1, ce qui était l'objectif de notre modèle.</p>
<h2 id="references">Références</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:spark-official">
<p>Spark Documentation, <em>Spark MLLib Guide</em>, <a href="https://spark.apache.org/docs/latest/ml-guide.html">https://spark.apache.org/docs/latest/ml-guide.html</a>, consulté le 04/2020&#160;<a class="footnote-backref" href="#fnref:spark-official" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../p6-stream/" title="P6 - Spark Streaming" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Précédent
                </span>
                P6 - Spark Streaming
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 - 2020 Lilia Sfaxi
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="http://liliasfaxi.wix.com/liliasfaxi" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/liliasfaxi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/lillitou" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://www.linkedin.com/in/liliasfaxi/" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.808e90bb.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
                <script src="../assets/javascripts/lunr/lunr.fr.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      
    
  </body>
</html>