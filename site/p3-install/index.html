



<!doctype html>
<html lang="fr" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Cours et Travaux Pratiques pour se familiariser avec Apache Spark">
      
      
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p3-install/">
      
      
        <meta name="author" content="Lilia Sfaxi">
      
      
        <meta name="lang:clipboard.copy" content="Copier dans le presse-papier">
      
        <meta name="lang:clipboard.copied" content="Copié dans le presse-papier">
      
        <meta name="lang:search.language" content="fr">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="Aucun document trouvé">
      
        <meta name="lang:search.result.one" content="1 document trouvé">
      
        <meta name="lang:search.result.other" content="# documents trouvés">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>P3 - Installation de Spark - Atelier Apache Spark</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.1b62728e.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#546e7a">
      
    
    
      <script src="../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="blue-grey" data-md-color-accent="amber">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#partie-3-installation-de-spark" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://liliasfaxi.github.io/Atelier-Spark/" title="Atelier Apache Spark" class="md-header-nav__button md-logo">
          
            <img src="../img/logo.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Atelier Apache Spark
            </span>
            <span class="md-header-nav__topic">
              
                P3 - Installation de Spark
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Rechercher" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Taper pour démarrer la recherche
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/liliasfaxi/Atelier-Spark/" title="Aller au dépôt" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    liliasfaxi/Atelier-Spark
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://liliasfaxi.github.io/Atelier-Spark/" title="Atelier Apache Spark" class="md-nav__button md-logo">
      
        <img src="../img/logo.png" width="48" height="48">
      
    </a>
    Atelier Apache Spark
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/liliasfaxi/Atelier-Spark/" title="Aller au dépôt" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    liliasfaxi/Atelier-Spark
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Atelier Apache Spark" class="md-nav__link">
      Atelier Apache Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p1-big-data/" title="P1 - Introduction au Big Data" class="md-nav__link">
      P1 - Introduction au Big Data
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p2-spark/" title="P2 - Introduction à Apache Spark" class="md-nav__link">
      P2 - Introduction à Apache Spark
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        P3 - Installation de Spark
      </label>
    
    <a href="./" title="P3 - Installation de Spark" class="md-nav__link md-nav__link--active">
      P3 - Installation de Spark
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table des matières</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation-de-spark-sur-un-seul-noeud" class="md-nav__link">
    Installation de Spark sur un seul Noeud
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#etape-1-telecharger-limage-de-base" class="md-nav__link">
    Étape 1 - Télécharger l'image de base
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-2-installer-java" class="md-nav__link">
    Étape 2 - Installer Java
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-3-installer-scala" class="md-nav__link">
    Étape 3 - Installer Scala
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-4-telecharger-spark" class="md-nav__link">
    Étape 4 - Télécharger Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-5-mise-en-place-de-lenvironnement-spark" class="md-nav__link">
    Étape 5 - Mise en place de l'environnement Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-6-demarrer-un-serveur-master-en-standalone" class="md-nav__link">
    Étape 6 - Démarrer un serveur master en standalone
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-7-demarrer-un-processus-worker" class="md-nav__link">
    Étape 7 - Démarrer un processus Worker
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation-de-spark-sur-un-cluster" class="md-nav__link">
    Installation de Spark sur un cluster
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#etape-1-installer-ssh" class="md-nav__link">
    Étape 1 - Installer SSH
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-2-configurer-spark" class="md-nav__link">
    Étape 2 - Configurer Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-3-creer-une-image-a-partir-du-contenaire" class="md-nav__link">
    Étape 3 - Créer une image à partir du contenaire
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-4-creer-le-cluster" class="md-nav__link">
    Étape 4 - Créer le Cluster
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-5-demarrer-les-services-spark" class="md-nav__link">
    Étape 5 - Démarrer les services Spark
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p4-batch/" title="P4 - RDD et Batch Processing avec Spark" class="md-nav__link">
      P4 - RDD et Batch Processing avec Spark
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p5-sql/" title="P5 - Spark SQL" class="md-nav__link">
      P5 - Spark SQL
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../p6-stream/" title="P6 - Spark Streaming" class="md-nav__link">
      P6 - Spark Streaming
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table des matières</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation-de-spark-sur-un-seul-noeud" class="md-nav__link">
    Installation de Spark sur un seul Noeud
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#etape-1-telecharger-limage-de-base" class="md-nav__link">
    Étape 1 - Télécharger l'image de base
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-2-installer-java" class="md-nav__link">
    Étape 2 - Installer Java
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-3-installer-scala" class="md-nav__link">
    Étape 3 - Installer Scala
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-4-telecharger-spark" class="md-nav__link">
    Étape 4 - Télécharger Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-5-mise-en-place-de-lenvironnement-spark" class="md-nav__link">
    Étape 5 - Mise en place de l'environnement Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-6-demarrer-un-serveur-master-en-standalone" class="md-nav__link">
    Étape 6 - Démarrer un serveur master en standalone
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-7-demarrer-un-processus-worker" class="md-nav__link">
    Étape 7 - Démarrer un processus Worker
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation-de-spark-sur-un-cluster" class="md-nav__link">
    Installation de Spark sur un cluster
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#etape-1-installer-ssh" class="md-nav__link">
    Étape 1 - Installer SSH
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-2-configurer-spark" class="md-nav__link">
    Étape 2 - Configurer Spark
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-3-creer-une-image-a-partir-du-contenaire" class="md-nav__link">
    Étape 3 - Créer une image à partir du contenaire
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-4-creer-le-cluster" class="md-nav__link">
    Étape 4 - Créer le Cluster
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#etape-5-demarrer-les-services-spark" class="md-nav__link">
    Étape 5 - Démarrer les services Spark
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p3-install.md" title="Editer cette page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="partie-3-installation-de-spark">Partie 3 - Installation de Spark</h1>
<p><center><img src="../img/p2/spark.jpeg" width="400pt"></center></p>
<h2 id="installation-de-spark-sur-un-seul-noeud">Installation de Spark sur un seul Noeud</h2>
<p>Pour installer Spark, nous allons utiliser des contenaires <a href="https://www.docker.com/">Docker</a>. Docker nous permettra de mettre en place un environnement complet, entièrement portable, sans rien installer sur la machine hôte, pour utiliser Spark de façon uniforme grâce aux lignes de commande.</p>
<p>Nous allons suivre les étapes suivantes pour installer l'environnement Spark sur une machine ubuntu.</p>
<h3 id="etape-1-telecharger-limage-de-base">Étape 1 - Télécharger l'image de base</h3>
<p>Avant de suivre les étapes suivantes, il faut commencer par installer Docker. Suivre les étapes se trouvant dans le lien suivant, suivant votre système d'exploitation:<br />
<a href="https://docs.docker.com/install/">https://docs.docker.com/install/</a></p>
<p>Nous avons choisi Ubuntu comme environnement cible pour notre contenaire Docker. Nous commençons donc par télécharger l'image Ubuntu à partir de Docker Hub, avec la commande suivante:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">pull</span> <span class="n">ubuntu</span>
</pre></div>
</td></tr></table>

<p>Nous allons ensuite créer un contenaire à partir de l'image téléchargée.</p>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">run</span> <span class="o">-</span><span class="n">itd</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8080</span><span class="o">:</span><span class="mi">8080</span> <span class="o">--</span><span class="n">name</span> <span class="n">spark</span> <span class="o">--</span><span class="n">hostname</span> <span class="n">spark</span> <span class="n">ubuntu</span>
</pre></div>
</td></tr></table><br />
Nous avons lancé un nouveau contenaire intitulé <em>spark</em> à partir de la machine ubuntu, en exposant sur le localhost son port 8080, pour pouvoir accéder à sa WebURL.<br />
On pourra vérifier que la machine est bien démarrée en utilisant:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker ps
</pre></div>
</td></tr></table>

<p>On devrait obtenir un résultat semblable au suivant:<br />
<img alt="Contenaires Démarrés" src="../img/p3/started.png" /></p>
<p>Pour se connecter à la machine et la manipuler avec les lignes de commandes, utiliser:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="n">spark</span> <span class="n">bash</span>
</pre></div>
</td></tr></table>

<p>Le résultat sera comme suit:<br />
<img alt="Connexion à la machine" src="../img/p3/logged.png" /></p>
<div class="admonition warning">
<p class="admonition-title">Attention</p>
<p>Ces étapes sont faites une seule fois, à la première création de la machine. Si vous voulez relancer une machine déjà créée, suivre les étapes suivantes:</p>
<ul>
<li>Vérifier que la machine n'est pas déjà démarrée. Pour cela, taper la commande suivante:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">ps</span>
</pre></div>
</td></tr></table></li>
<li>
<p>Si vous retrouvez le contenaire dans la liste affichée, vous pouvez exécuter la commande <code class="codehilite"><span class="n">docker</span> <span class="n">exec</span><span class="p">...</span></code> présentée précédemment.</p>
</li>
<li>
<p>Sinon, vérifier que le contenaire existe bien, mais qu'il est juste stoppé, grâce à la commande:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">ps</span> <span class="o">-</span><span class="n">a</span>
</pre></div>
</td></tr></table></p>
</li>
<li>
<p>Une fois le contenaire retrouvé, le démarrer, simplement en tapant la commande suivante:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">docker</span> <span class="n">start</span> <span class="n">spark</span>
</pre></div>
</td></tr></table></p>
</li>
</ul>
<p>Le contenaire sera lancé.</p>
</div>
<h3 id="etape-2-installer-java">Étape 2 - Installer Java</h3>
<p>Afin d'installer Java sur la machine, commencer par mettre à jour les packages systèmes de Ubuntu:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">apt</span> <span class="n">update</span>
  <span class="n">apt</span> <span class="o">-</span><span class="n">y</span> <span class="n">upgrade</span>
</pre></div>
</td></tr></table>

<p>Installer ensuite la version par défaut de Java:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">apt</span> <span class="n">install</span> <span class="k">default</span><span class="o">-</span><span class="n">jdk</span>
</pre></div>
</td></tr></table>

<p>Vérifier la version de Java que vous venez d'installer:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">java</span> <span class="o">-</span><span class="n">version</span>
</pre></div>
</td></tr></table>

<h3 id="etape-3-installer-scala">Étape 3 - Installer Scala</h3>
<p>Installer Scala :</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  apt install scala
</pre></div>
</td></tr></table>

<h3 id="etape-4-telecharger-spark">Étape 4 - Télécharger Spark</h3>
<p>Pour installer Spark sur la machine docker, utiliser la commande suivante:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">apt</span> <span class="n">install</span> <span class="n">curl</span>
  <span class="n">curl</span> <span class="o">-</span><span class="n">O</span> <span class="n">https</span><span class="o">:</span><span class="c1">//archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz</span>
</pre></div>
</td></tr></table>

<p>La version stable actuelle est 2.4.5, mais vous pouvez télécharger la version de votre choix. Vous retrouverez les liens de téléchargement de toutes les versions <a href="https://archive.apache.org/dist/spark">ICI</a>.</p>
<p>Extraire ensuite le fichier tgz:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">tar</span> <span class="n">xvf</span> <span class="n">spark</span><span class="o">-</span><span class="mf">2.4.5</span><span class="o">-</span><span class="n">bin</span><span class="o">-</span><span class="n">hadoop2</span><span class="mf">.7</span><span class="p">.</span><span class="n">tgz</span>
</pre></div>
</td></tr></table>

<p>Déplacer le dossier obtenu vers le répertoire /opt comme suit:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="n">mv</span> <span class="n">spark</span><span class="o">-</span><span class="mf">2.4.5</span><span class="o">-</span><span class="n">bin</span><span class="o">-</span><span class="n">hadoop2</span><span class="mf">.7</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">spark</span>
  <span class="n">rm</span> <span class="n">spark</span><span class="o">-</span><span class="mf">2.4.5</span><span class="o">-</span><span class="n">bin</span><span class="o">-</span><span class="n">hadoop2</span><span class="mf">.7</span><span class="p">.</span><span class="n">tgz</span>
</pre></div>
</td></tr></table>

<h3 id="etape-5-mise-en-place-de-lenvironnement-spark">Étape 5 - Mise en place de l'environnement Spark</h3>
<p>Nous devons mettre en place certains paramètres d'environnement pour assurer une bonne exécution de Spark:</p>
<ol>
<li>Ouvrir le fichier de configuration bashrc (installer <a href="vim.org">vim</a> si nécessaire avec <code class="codehilite"><span class="n">apt</span> <span class="n">install</span> <span class="n">vim</span></code>)</li>
</ol>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  vim ~/.bashrc
</pre></div>
</td></tr></table><br />
  2. Ajouter les lignes suivantes à la fin du fichier (taper <code class="codehilite"><span class="n">G</span></code> pour aller à la fin du fichier, puis <code class="codehilite"><span class="n">o</span></code> pour insérer une nouvelle ligne et passer en mode édition)</p>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="nb">export </span><span class="nv">SPARK_HOME</span><span class="o">=</span>/opt/spark
  <span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SPARK_HOME</span>/bin:<span class="nv">$SPARK_HOME</span>/sbin
</pre></div>
</td></tr></table><br />
  Quitter l'éditeur en tapant <code class="codehilite"><span class="o">:</span><span class="n">wq</span></code><br />
  Activer les changements réalisés en tapant <code class="codehilite"><span class="err">`</span><span class="n">source</span> <span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span></code></p>
<h3 id="etape-6-demarrer-un-serveur-master-en-standalone">Étape 6 - Démarrer un serveur master en standalone</h3>
<p>Il est désormais possible de démarrer un serveur en standalone, en utilisant la commande suivante:</p>
<p><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  start-master.sh
</pre></div>
</td></tr></table><br />
Vous pourrez ensuite vérifier que votre serveur est bien démarré en tapant: <code class="codehilite"><span class="n">jps</span></code></p>
<p><img alt="Master démarré" src="../img/p3/master-started.png" /></p>
<p>Il suffit de plus, d'aller sur le navigateur de votre machine hôte, et d'ouvrir le lien: <code class="codehilite"><span class="nl">http:</span><span class="c1">//localhost:8080</span></code> (après avoir vérifié que rien d'autre ne tourne sur le même port). L'interface Web de Spark s'affichera, comme suit:</p>
<p><img alt="Interface Web Spark" src="../img/p3/spark-web.png" /></p>
<p>On remarque que la fenêtre indique que le spark master se trouve sur <code class="codehilite"><span class="nl">spark:</span><span class="c1">//spark:7077</span></code></p>
<h3 id="etape-7-demarrer-un-processus-worker">Étape 7 - Démarrer un processus Worker</h3>
<p>Pour lancer un processus Worker, utiliser la commande suivante:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  start-slave.sh spark://spark:7077
</pre></div>
</td></tr></table>

<p>Un nouveau processus sera lancé, qu'on pourra voir avec <code class="codehilite"><span class="n">jps</span></code></p>
<p><img alt="Worker démarré" src="../img/p3/worker-started.png" /></p>
<p>Vous pouvez maintenant lancer Spark Shell pour executer des Jobs Spark.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  spark-shell
</pre></div>
</td></tr></table>

<p><img alt="Spark Shell" src="../img/p3/spark-shell.png" /></p>
<h2 id="installation-de-spark-sur-un-cluster">Installation de Spark sur un cluster</h2>
<p>Nous allons maintenant procéder à l'installation de Spark sur un cluster, c'est à dire un ensemble de machines interconnectées, représentées dans notre cas par des contenaires Docker. L'objectif sera donc de créer un réseau de contenaires, installer Spark dessus, et lancer les processus sur les différents contenaires, de façon à obtenir le cluster suivant:</p>
<p><center><img src="../img/p3/cluster.png" width="400pts"></center></p>
<p>Pour réaliser cela, nous allons nous baser sur le contenaire créé précédemment, dans lequel nous avons installé Java et Spark.</p>
<h3 id="etape-1-installer-ssh">Étape 1 - Installer SSH</h3>
<ol>
<li>Installer OpenSSH sur la machine :<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  apt install openssh-server openssh-client
</pre></div>
</td></tr></table></li>
<li>Générer une paire de clefs (quand on vous le demande, valider le chemin par défaut proposé pour enregistrer la paire de clefs):<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  ssh-keygen -t rsa -P <span class="s2">&quot;&quot;</span>
</pre></div>
</td></tr></table></li>
<li>Définir la clef générée comme clef autorisée:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
</pre></div>
</td></tr></table></li>
<li>Programmer ssh pour qu'il soit lancé au démarrage du contenaire. Pour cela, ajouter les lignes suivantes à la fin du fichier <code class="codehilite"><span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span></code>:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  service ssh start
</pre></div>
</td></tr></table></li>
</ol>
<h3 id="etape-2-configurer-spark">Étape 2 - Configurer Spark</h3>
<p>Il faudrait éditer le fichier de configuration <code class="codehilite"><span class="n">spark</span><span class="o">-</span><span class="n">env</span><span class="p">.</span><span class="n">sh</span></code> (se trouvant dans le répertoire <code class="codehilite"><span class="err">$</span><span class="n">SPARK_HOME</span><span class="o">/</span><span class="n">conf</span></code>) pour ajouter les paramètres suivants:</p>
<ol>
<li>Créer une copie du template du fichier <code class="codehilite"><span class="n">spark</span><span class="o">-</span><span class="n">env</span><span class="p">.</span><span class="n">sh</span></code> et le renommer:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  cp <span class="nv">$SPARK_HOME</span>/conf/spark-env.sh.template <span class="nv">$SPARK_HOME</span>/conf/spark-env.sh
</pre></div>
</td></tr></table></li>
<li>Ajouter les deux lignes suivantes à la fin du fichier <code class="codehilite"><span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span></code> (n'oubliez pas de le recharger après modification avec <code class="codehilite"><span class="n">source</span> <span class="o">~/</span><span class="p">.</span><span class="n">bashrc</span></code>)<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="nb">export </span><span class="nv">SPARK_WORKER_CORES</span><span class="o">=</span>8
</pre></div>
</td></tr></table></li>
<li>Créer le fichier de configuration <code class="codehilite"><span class="n">slaves</span></code>dans le répertoire <code class="codehilite"><span class="err">$</span><span class="n">SPARK_HOME</span><span class="o">/</span><span class="n">conf</span></code>:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  vim <span class="nv">$SPARK_HOME</span>/conf/slaves
</pre></div>
</td></tr></table></li>
<li>Ajouter dans le fichier <code class="codehilite"><span class="n">slaves</span></code> les noms des contenaires workers (que nous allons créer tout à l'heure):<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  spark-slave1
  spark-slave2
</pre></div>
</td></tr></table></li>
</ol>
<p>Vous avez configuré Spark pour supporter deux esclaves (<em>workers</em> ou <em>slaves</em>) en plus du master.</p>
<h3 id="etape-3-creer-une-image-a-partir-du-contenaire">Étape 3 - Créer une image à partir du contenaire</h3>
<p>Une fois le contenaire créé et configuré tel que présenté précédemment, nous allons le dupliquer pour en créer un cluster. Mais d'abord, il faut créer une image du contenaire, de façon à l'utiliser pour créer les deux autre contenaires.</p>
<p>Commencer par quitter le noeud <em>spark</em> et retourner vers la machine hôte, en tapant <code class="codehilite"><span class="n">exit</span></code>.</p>
<ol>
<li>Taper la commande suivante pour créer une image à partir du contenaire spark:</li>
</ol>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker commit spark spark-image
</pre></div>
</td></tr></table>

<p><code class="codehilite"><span class="n">commit</span></code> permet de créer une nouvelle image <code class="codehilite"><span class="n">spark</span><span class="o">-</span><span class="n">image</span></code> à partir du contenaire <code class="codehilite"><span class="n">spark</span></code>.</p>
<p>Vérifier que <code class="codehilite"><span class="n">spark</span><span class="o">-</span><span class="n">image</span></code> existe bien en tapant: <code class="codehilite"><span class="n">docker</span> <span class="n">images</span></code>.</p>
<h3 id="etape-4-creer-le-cluster">Étape 4 - Créer le Cluster</h3>
<p>Pour créer le cluster à partir de l'image déjà générée, suivre les étapes suivantes:</p>
<ol>
<li>
<p>Supprimer le contenaire spark précédemment créé:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker stop spark
  docker rm spark
</pre></div>
</td></tr></table></p>
</li>
<li>
<p>Créer un réseau qui permettra de connecter les trois noeuds du cluster:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker network create --driver<span class="o">=</span>bridge spark-network
</pre></div>
</td></tr></table></p>
</li>
<li>Créer et lancer les trois contenaires (les instructions -p permettent de faire un mapping entre les ports de la machine hôte et ceux du contenaire):<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker run -itd --net<span class="o">=</span>spark-network -p 8080:8080 --expose 22 <span class="se">\</span>
        --name spark-master --hostname spark-master <span class="se">\</span>
        spark-image

  docker run -itd --net<span class="o">=</span>spark-network --expose 22 <span class="se">\</span>
        --name spark-slave1 --hostname spark-slave1 <span class="se">\</span>
        spark-image

  docker run -itd --net<span class="o">=</span>spark-network --expose 22 <span class="se">\</span>
        --name spark-slave2 --hostname spark-slave2 <span class="se">\</span>
        spark-image
</pre></div>
</td></tr></table></li>
<li>Vérifier que les trois contenaires sont bien créés:<br />
  <table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  docker ps
</pre></div>
</td></tr></table><br />
  Vous devriez retrouver la liste des trois contenaires:<br />
<img alt="Cluster Créé" src="../img/p3/cluster-created.png" /></li>
</ol>
<h3 id="etape-5-demarrer-les-services-spark">Étape 5 - Démarrer les services Spark</h3>
<p>Pour démarrer les services spark sur tous les noeuds, utiliser la commande suivante:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  start-all.sh
</pre></div>
</td></tr></table>

<p>Vous obtiendrez le résultat suivant:<br />
<img alt="Start All Spark" src="../img/p3/start-all.png" /></p>
<p>Pour vérifier que les services sont bien démarrés, aller sur le noeud Master et taper la commande <code class="codehilite"><span class="n">jps</span></code>, vous trouverez le résultat suivant:<br />
<img alt="Master démarré" src="../img/p3/master-started-cluster.png" /></p>
<p>Si on fait la même chose sur un des slaves, on obtiendra le résultat suivant:<br />
<img alt="Slave démarré" src="../img/p3/slave-started-cluster.png" /></p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../p2-spark/" title="P2 - Introduction à Apache Spark" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Précédent
                </span>
                P2 - Introduction à Apache Spark
              </span>
            </div>
          </a>
        
        
          <a href="../p4-batch/" title="P4 - RDD et Batch Processing avec Spark" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Suivant
                </span>
                P4 - RDD et Batch Processing avec Spark
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 - 2020 Lilia Sfaxi
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="http://liliasfaxi.wix.com/liliasfaxi" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/liliasfaxi" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/lillitou" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://www.linkedin.com/in/liliasfaxi/" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.808e90bb.js"></script>
      
        
        
          
          <script src="../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
              
                <script src="../assets/javascripts/lunr/lunr.fr.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      
    
  </body>
</html>