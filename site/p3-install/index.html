<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Lilia Sfaxi">
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p3-install/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>P3 - Installation de Spark - Atelier Apache Spark</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Atelier Apache Spark</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Atelier Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p1-big-data/" class="nav-link">P1 - Introduction au Big Data</a>
                            </li>
                            <li class="navitem">
                                <a href="../p2-spark/" class="nav-link">P2 - Introduction à Apache Spark</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">P3 - Installation de Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p4-batch/" class="nav-link">P4 - RDD et Batch Processing avec Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p5-sql/" class="nav-link">P5 - Spark SQL</a>
                            </li>
                            <li class="navitem">
                                <a href="../p6-stream/" class="nav-link">P6 - Spark Streaming</a>
                            </li>
                            <li class="navitem">
                                <a href="../p7-ml/" class="nav-link">P7 - Spark MLLib</a>
                            </li>
                            <li class="navitem">
                                <a href="../p8-graphx/" class="nav-link">P8 - Spark GraphX</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../p2-spark/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../p4-batch/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p3-install.md" class="nav-link">Edit on liliasfaxi/Atelier-Spark</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#partie-3-installation-de-spark" class="nav-link">Partie 3 - Installation de Spark</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#installation-de-spark-sur-un-seul-noeud" class="nav-link">Installation de Spark sur un seul Noeud</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#installation-de-spark-sur-un-cluster" class="nav-link">Installation de Spark sur un cluster</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="partie-3-installation-de-spark">Partie 3 - Installation de Spark</h1>
<p><center><img src="../img/p2/spark.jpeg" width="400pt"></center></p>
<h2 id="installation-de-spark-sur-un-seul-noeud">Installation de Spark sur un seul Noeud</h2>
<p>Pour installer Spark, nous allons utiliser des contenaires <a href="https://www.docker.com/">Docker</a>. Docker nous permettra de mettre en place un environnement complet, entièrement portable, sans rien installer sur la machine hôte, pour utiliser Spark de façon uniforme grâce aux lignes de commande.</p>
<p>Nous allons suivre les étapes suivantes pour installer l'environnement Spark sur une machine ubuntu.</p>
<h3 id="etape-1-telecharger-limage-de-base">Étape 1 - Télécharger l'image de base</h3>
<p>Avant de suivre les étapes suivantes, il faut commencer par installer Docker. Suivre les étapes se trouvant dans le lien suivant, suivant votre système d'exploitation:
<a href="https://docs.docker.com/install/">https://docs.docker.com/install/</a></p>
<p>Nous avons choisi Ubuntu comme environnement cible pour notre contenaire Docker. Nous commençons donc par télécharger l'image Ubuntu à partir de Docker Hub, avec la commande suivante:</p>
<pre><code class="language-Bash">  docker pull ubuntu
</code></pre>
<p>Nous allons ensuite créer un contenaire à partir de l'image téléchargée.</p>
<pre><code class="language-Bash">  docker run -itd -p 8080:8080 --name spark --hostname spark ubuntu
</code></pre>
<p>Nous avons lancé un nouveau contenaire intitulé <em>spark</em> à partir de la machine ubuntu, en exposant sur le localhost son port 8080, pour pouvoir accéder à sa WebURL.
On pourra vérifier que la machine est bien démarrée en utilisant:</p>
<pre><code class="language-bash">  docker ps
</code></pre>
<p>On devrait obtenir un résultat semblable au suivant:
<img alt="Contenaires Démarrés" src="../img/p3/started.png" /></p>
<p>Pour se connecter à la machine et la manipuler avec les lignes de commandes, utiliser:</p>
<pre><code class="language-Bash">  docker exec -it spark bash
</code></pre>
<p>Le résultat sera comme suit:
<img alt="Connexion à la machine" src="../img/p3/logged.png" /></p>
<p>!!! warning "Attention"
    Ces étapes sont faites une seule fois, à la première création de la machine. Si vous voulez relancer une machine déjà créée, suivre les étapes suivantes:</p>
<pre><code>  * Vérifier que la machine n'est pas déjà démarrée. Pour cela, taper la commande suivante:
  ```
    docker ps
  ```
  * Si vous retrouvez le contenaire dans la liste affichée, vous pouvez exécuter la commande ```docker exec...``` présentée précédemment.

  * Sinon, vérifier que le contenaire existe bien, mais qu'il est juste stoppé, grâce à la commande:
  ```
    docker ps -a
  ```

  * Une fois le contenaire retrouvé, le démarrer, simplement en tapant la commande suivante:
  ```
    docker start spark
  ```

  Le contenaire sera lancé.
</code></pre>
<h3 id="etape-2-installer-java">Étape 2 - Installer Java</h3>
<p>Afin d'installer Java sur la machine, commencer par mettre à jour les packages systèmes de Ubuntu:</p>
<pre><code class="language-Bash">  apt update
  apt -y upgrade
</code></pre>
<p>Installer ensuite la version par défaut de Java:</p>
<pre><code class="language-Bash">  apt install default-jdk
</code></pre>
<p>Vérifier la version de Java que vous venez d'installer:</p>
<pre><code class="language-Bash">  java -version
</code></pre>
<h3 id="etape-3-installer-scala">Étape 3 - Installer Scala</h3>
<p>Installer Scala :</p>
<pre><code class="language-bash">  apt install scala
</code></pre>
<h3 id="etape-4-telecharger-spark">Étape 4 - Télécharger Spark</h3>
<p>Pour installer Spark sur la machine docker, utiliser la commande suivante:</p>
<pre><code class="language-Bash">  apt install curl
  curl -O https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
</code></pre>
<p>La version stable actuelle est 2.4.5, mais vous pouvez télécharger la version de votre choix. Vous retrouverez les liens de téléchargement de toutes les versions <a href="https://archive.apache.org/dist/spark">ICI</a>.</p>
<p>Extraire ensuite le fichier tgz:</p>
<pre><code class="language-Bash">  tar xvf spark-2.4.5-bin-hadoop2.7.tgz
</code></pre>
<p>Déplacer le dossier obtenu vers le répertoire /opt comme suit:</p>
<pre><code class="language-Bash">  mv spark-2.4.5-bin-hadoop2.7 /opt/spark
  rm spark-2.4.5-bin-hadoop2.7.tgz
</code></pre>
<h3 id="etape-5-mise-en-place-de-lenvironnement-spark">Étape 5 - Mise en place de l'environnement Spark</h3>
<p>Nous devons mettre en place certains paramètres d'environnement pour assurer une bonne exécution de Spark:</p>
<ol>
<li>Ouvrir le fichier de configuration bashrc (installer <a href="https://www.vim.org/">vim</a> si nécessaire avec <code>apt install vim</code>)</li>
</ol>
<p><code>bash
    vim ~/.bashrc</code>
  2. Ajouter les lignes suivantes à la fin du fichier (taper <code>G</code> pour aller à la fin du fichier, puis <code>o</code> pour insérer une nouvelle ligne et passer en mode édition)</p>
<p><code>bash
    export SPARK_HOME=/opt/spark
    export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</code>
  Quitter l'éditeur en tapant <code>:wq</code>
  Activer les changements réalisés en tapant <code>`source ~/.bashrc</code></p>
<h3 id="etape-6-demarrer-un-serveur-master-en-standalone">Étape 6 - Démarrer un serveur master en standalone</h3>
<p>Il est désormais possible de démarrer un serveur en standalone, en utilisant la commande suivante:</p>
<pre><code class="language-bash">  start-master.sh
</code></pre>
<p>Vous pourrez ensuite vérifier que votre serveur est bien démarré en tapant: <code>jps</code></p>
<p><img alt="Master démarré" src="../img/p3/master-started.png" /></p>
<p>Il suffit de plus, d'aller sur le navigateur de votre machine hôte, et d'ouvrir le lien: <code>http://localhost:8080</code> (après avoir vérifié que rien d'autre ne tourne sur le même port). L'interface Web de Spark s'affichera, comme suit:</p>
<p><img alt="Interface Web Spark" src="../img/p3/spark-web.png" /></p>
<p>On remarque que la fenêtre indique que le spark master se trouve sur <code>spark://spark:7077</code></p>
<h3 id="etape-7-demarrer-un-processus-worker">Étape 7 - Démarrer un processus Worker</h3>
<p>Pour lancer un processus Worker, utiliser la commande suivante:</p>
<pre><code class="language-bash">  start-slave.sh spark://spark:7077
</code></pre>
<p>Un nouveau processus sera lancé, qu'on pourra voir avec <code>jps</code></p>
<p><img alt="Worker démarré" src="../img/p3/worker-started.png" /></p>
<p>Vous pouvez maintenant lancer Spark Shell pour executer des Jobs Spark.</p>
<pre><code class="language-bash">  spark-shell
</code></pre>
<p><img alt="Spark Shell" src="../img/p3/spark-shell.png" /></p>
<h2 id="installation-de-spark-sur-un-cluster">Installation de Spark sur un cluster</h2>
<p>Nous allons maintenant procéder à l'installation de Spark sur un cluster, c'est à dire un ensemble de machines interconnectées, représentées dans notre cas par des contenaires Docker. L'objectif sera donc de créer un réseau de contenaires, installer Spark dessus, et lancer les processus sur les différents contenaires, de façon à obtenir le cluster suivant:</p>
<p><center><img src="../img/p3/cluster.png" width="400pts"></center></p>
<p>Pour réaliser cela, nous allons nous baser sur le contenaire créé précédemment, dans lequel nous avons installé Java et Spark.</p>
<h3 id="etape-1-installer-ssh">Étape 1 - Installer SSH</h3>
<ol>
<li>Installer OpenSSH sur la machine :
  <code>bash
    apt install openssh-server openssh-client</code></li>
<li>Générer une paire de clefs (quand on vous le demande, valider le chemin par défaut proposé pour enregistrer la paire de clefs):
  <code>bash
    ssh-keygen -t rsa -P ""</code></li>
<li>Définir la clef générée comme clef autorisée:
  <code>bash
    cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys</code></li>
<li>Programmer ssh pour qu'il soit lancé au démarrage du contenaire. Pour cela, ajouter les lignes suivantes à la fin du fichier <code>~/.bashrc</code>:
  <code>bash
    service ssh start</code></li>
</ol>
<h3 id="etape-2-configurer-spark">Étape 2 - Configurer Spark</h3>
<p>Il faudrait éditer le fichier de configuration <code>spark-env.sh</code> (se trouvant dans le répertoire <code>$SPARK_HOME/conf</code>) pour ajouter les paramètres suivants:</p>
<ol>
<li>Créer une copie du template du fichier <code>spark-env.sh</code> et le renommer:
  <code>bash
    cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh</code></li>
<li>Ajouter les deux lignes suivantes à la fin du fichier <code>~/.bashrc</code> (n'oubliez pas de le recharger après modification avec <code>source ~/.bashrc</code>)
  <code>bash
    export SPARK_WORKER_CORES=8</code></li>
<li>Créer le fichier de configuration <code>slaves</code>dans le répertoire <code>$SPARK_HOME/conf</code>:
  <code>bash
    vim $SPARK_HOME/conf/slaves</code></li>
<li>Ajouter dans le fichier <code>slaves</code> les noms des contenaires workers (que nous allons créer tout à l'heure):
  <code>bash
    spark-slave1
    spark-slave2</code></li>
</ol>
<p>Vous avez configuré Spark pour supporter deux esclaves (<em>workers</em> ou <em>slaves</em>) en plus du master.</p>
<h3 id="etape-3-creer-une-image-a-partir-du-contenaire">Étape 3 - Créer une image à partir du contenaire</h3>
<p>Une fois le contenaire créé et configuré tel que présenté précédemment, nous allons le dupliquer pour en créer un cluster. Mais d'abord, il faut créer une image du contenaire, de façon à l'utiliser pour créer les deux autre contenaires.</p>
<p>Commencer par quitter le noeud <em>spark</em> et retourner vers la machine hôte, en tapant <code>exit</code>.</p>
<ol>
<li>Taper la commande suivante pour créer une image à partir du contenaire spark:</li>
</ol>
<p><code>bash
    docker commit spark spark-image</code></p>
<p><code>commit</code> permet de créer une nouvelle image <code>spark-image</code> à partir du contenaire <code>spark</code>.</p>
<p>Vérifier que <code>spark-image</code> existe bien en tapant: <code>docker images</code>.</p>
<h3 id="etape-4-creer-le-cluster">Étape 4 - Créer le Cluster</h3>
<p>Pour créer le cluster à partir de l'image déjà générée, suivre les étapes suivantes:</p>
<ol>
<li>
<p>Supprimer le contenaire spark précédemment créé:
  <code>bash
    docker stop spark
    docker rm spark</code></p>
</li>
<li>
<p>Créer un réseau qui permettra de connecter les trois noeuds du cluster:
  <code>bash
    docker network create --driver=bridge spark-network</code></p>
</li>
<li>
<p>Créer et lancer les trois contenaires (les instructions -p permettent de faire un mapping entre les ports de la machine hôte et ceux du contenaire):
  ```bash
    docker run -itd --net=spark-network -p 8080:8080 --expose 22 \
          --name spark-master --hostname spark-master \
          spark-image</p>
<p>docker run -itd --net=spark-network --expose 22 \
      --name spark-slave1 --hostname spark-slave1 \
      spark-image</p>
<p>docker run -itd --net=spark-network --expose 22 \
      --name spark-slave2 --hostname spark-slave2 \
      spark-image
  <code>4. Vérifier que les trois contenaires sont bien créés:</code>bash
docker ps
  ```
  Vous devriez retrouver la liste des trois contenaires:
  <img alt="Cluster Créé" src="../img/p3/cluster-created.png" /></p>
</li>
</ol>
<h3 id="etape-5-demarrer-les-services-spark">Étape 5 - Démarrer les services Spark</h3>
<p>Pour démarrer les services spark sur tous les noeuds, utiliser la commande suivante:</p>
<pre><code class="language-bash">  start-all.sh
</code></pre>
<p>Vous obtiendrez le résultat suivant:
<img alt="Start All Spark" src="../img/p3/start-all.png" /></p>
<p>Pour vérifier que les services sont bien démarrés, aller sur le noeud Master et taper la commande <code>jps</code>, vous trouverez le résultat suivant:
<img alt="Master démarré" src="../img/p3/master-started-cluster.png" /></p>
<p>Si on fait la même chose sur un des slaves, on obtiendra le résultat suivant:
<img alt="Slave démarré" src="../img/p3/slave-started-cluster.png" /></p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2019 - 2020 Lilia Sfaxi</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
