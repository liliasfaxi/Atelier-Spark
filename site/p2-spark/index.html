<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Lilia Sfaxi">
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p2-spark/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>P2 - Introduction à Apache Spark - Atelier Apache Spark</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Atelier Apache Spark</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Atelier Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p1-big-data/" class="nav-link">P1 - Introduction au Big Data</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">P2 - Introduction à Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p3-install/" class="nav-link">P3 - Installation de Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p4-batch/" class="nav-link">P4 - RDD et Batch Processing avec Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p5-sql/" class="nav-link">P5 - Spark SQL</a>
                            </li>
                            <li class="navitem">
                                <a href="../p6-stream/" class="nav-link">P6 - Spark Streaming</a>
                            </li>
                            <li class="navitem">
                                <a href="../p7-ml/" class="nav-link">P7 - Spark MLLib</a>
                            </li>
                            <li class="navitem">
                                <a href="../p8-graphx/" class="nav-link">P8 - Spark GraphX</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../p1-big-data/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../p3-install/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p2-spark.md" class="nav-link">Edit on liliasfaxi/Atelier-Spark</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#partie-2-introduction-a-apache-spark" class="nav-link">Partie 2 - Introduction à Apache Spark</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#apache-spark-presentation" class="nav-link">Apache Spark - Présentation</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#apache-spark-composants" class="nav-link">Apache Spark - Composants</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#architecture-de-spark" class="nav-link">Architecture de Spark</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#caracteristiques-de-spark" class="nav-link">Caractéristiques de Spark</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#limitations-de-spark" class="nav-link">Limitations de Spark</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#references" class="nav-link">Références</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="partie-2-introduction-a-apache-spark">Partie 2 - Introduction à Apache Spark</h1>
<p><center><img src="../img/p3/spark.jpeg" width="400pt"></center></p>
<h2 id="apache-spark-presentation">Apache Spark - Présentation</h2>
<p>Apache Spark est une plateforme de traitement sur cluster générique. C'est un moteur de traitement libre, assurant un traitement parallèle et distribué sur des données massives. Il fournit une API de développement pour permettre un traitement en streaming, l'apprentissage automatique ou la gestion de requêtes SQL et demandant des accès répétés sur un grand volume de données. [^DataFlair]</p>
<p>Apache Spark permet de réaliser des traitements par lot (<em>batch processing</em>) ou à la volée (<em>stream processing</em>) et est conçu de façon à pouvoir intégrer tous les outils et technologies Big Data. Par exemple, non seulement Spark peut-il accéder aux sources de données de Hadoop, il peut également tourner sur un cluster Hadoop. Étant donné que Spark n'offre pas de solution de stockage (pas encore en tout cas), il est logique qu'il puisse profiter de la puissance de HDFS (le système de fichiers de Hadoop), tout en offrant lui des performances inégalées pour le traitement en batch, ainsi que d'autres facilités (non offertes par Hadoop Map Reduce) telles que le traitement itératif, interactif et à la volée.</p>
<p>Spark offre des APIs de haut niveau en Java, Scala, Python et R. Il utilise le traitement en mémoire (<em>in-memory processing</em>), en exploitant les ressources combinées du cluster comme si c'était une machine unique.</p>
<p>Apache Spark a été créé en 2009 au laboratoire UC Berkeley R&amp;D Lab (appelé maintenant AMPLab), et est devenu open-source en 2010 avec une licence BSD. En 2013, il a intégré Apache Software Foundation, pour devenir, en 2014, un projet Apache de haut niveau.</p>
<h2 id="apache-spark-composants">Apache Spark - Composants</h2>
<p>Apache Spark utilise une architecture en couches, comportant plusieurs composants, dont l'objectif est de permettre de réaliser des traitements performants tout en promettant un  développement et une intégration facilitées. Il est né à la base pour pallier les problèmes posés par Hadoop Map Reduce, mais est devenu une entité à lui seul, offrant bien plus que le traitement par lot classique. [^DataFlair]</p>
<p>Voici les composants de Spark:</p>
<p><center><img src="../img/p2/spark.png" width="200pt"></center>
<center><img src="../img/p2/spark-layers.png" width="400pt"></center></p>
<ol>
<li>
<p><strong>Spark Core</strong>
Spark Core est le point central de Spark, qui fournit une plateforme d'exécution pour toutes les applications Spark. De plus, il supporte un large éventail d'applications.</p>
</li>
<li>
<p><strong>Spark SQL</strong>
Spark SQL se situe au dessus de Spark, pour permettre aux utilisateurs d'utiliser des requêtes SQL/HQL. Les données structurées et semi-structurées peuvent ainsi être traitées grâce à Spark SQL, avec une performance améliorée.</p>
</li>
<li>
<p><strong>Spark Streaming</strong>
Spark Streaming permet de créer des applications d'analyse de données interactives. Les flux de données sont transformés en micro-lots et traités par dessus Spark Core.</p>
</li>
<li>
<p><strong>Spark MLlib</strong>
La bibliothèque de machine learning MLlib fournit des algorithmes de haute qualité pour l'apprentissage automatique. Ce sont des libraries riches, très utiles pour les data scientists, autorisant de plus des traitements en mémoire améliorant de façon drastique la performance de ces algorithmes sur des données massives.</p>
</li>
<li>
<p><strong>Spark GraphX</strong>
Spark Graphx est le moteur d'exécution permettant un traitement scalable utilisant les graphes, se basant sur Spark Core.</p>
</li>
</ol>
<h2 id="architecture-de-spark">Architecture de Spark</h2>
<p>Les applications Spark s'exécutent comme un ensemble indépendant de processus sur un cluster, coordonnés par un objet <em>SparkContext</em> dans le programme principal, appelé <em>driver program</em>. [^Architecture]</p>
<p>Pour s'exécuter sur un cluster, <em>SparkContext</em> peut se connecter à plusieurs types de gestionnaires de clusters (<em>Cluster Managers</em>):</p>
<ul>
<li>Sur le <a href="https://spark.apache.org/docs/latest/spark-standalone.html">gestionnaire autonome de Spark</a>, qui est inclus dans Spark, et qui présente le moyen le plus rapide et simple de mettre en place un cluster.</li>
<li>Sur <a href="https://spark.apache.org/docs/latest/running-on-mesos.html">Apache Mesos</a>, un gestionnaire de cluster général qui peut aussi tourner sur Hadoop Map Reduce.</li>
<li>Sur <a href="https://spark.apache.org/docs/latest/running-on-yarn.html">Hadoop YARN</a>, le gestionnaire de ressources de Hadoop 2.</li>
<li>Sur <a href="https://spark.apache.org/docs/latest/running-on-kubernetes.html">Kubernetes</a>, un système open-source pour l'automatisation du déploiement et la gestion des applications conteneurisées.</li>
</ul>
<p>Ces gestionnaires permettent d'allouer les ressources nécessaires pour l'exécution de plusieurs applications Spark. Une fois connecté, Spark lance des <em>exécuteurs</em> sur les noeuds du cluster, qui sont des processus qui lancent des traitements et stockent des données pour les applications. Il envoie ensuite le code de l'application (dans un fichier JAR ou Python) aux <em>exécuteurs</em>. <em>Spark Context</em> envoie finalement les tâches à exécuter aux <em>exécuteurs</em>.</p>
<p><center><img src="../img/p2/archi.png" width="500pt"></center></p>
<p>Il est à noter que:</p>
<ul>
<li>Chaque application a son lot d'exécuteurs, qui restent actifs tout au long de l'exécution de l'application, et qui lancent des tâches sur plusieurs threads. Ainsi, les applications sont isolées les unes des autres, du point de vue de l'orchestration (chaque <em>driver</em> exécute ses propres tâches), et des exécuteurs (les tâches des différentes applications tournent sur des JVM différentes). Ceci implique également que les applications (ou Jobs) Sparks ne peuvent pas échanger des données, sans les enregistrer sur un support de stockage externe.</li>
<li>Spark est indépendant du gestionnaire de cluster sous-jacent. Il suffit de configurer Spark pour utiliser ce gestionnaire, il peut gérer ses ressources en même temps que d'autres applications, même non-Spark.</li>
<li>L'application principale (<em>driver</em>) doit être à l'écoute des connexions entrantes venant de ses exécuteurs.</li>
</ul>
<h2 id="caracteristiques-de-spark">Caractéristiques de Spark</h2>
<p>Spark est connu pour avoir plusieurs caractéristiques qui en font l'une des plateformes les plus utilisées dans le domaine des Big Data. Nous citons: [^DataFlair]</p>
<ul>
<li><strong>Performance de traitement</strong>: Il est possible de réaliser une vitesse de traitement très élevée avec Spark sur des fichiers volumineux qui peut être jusqu'à 100x meilleur que Hadoop Map Reduce, par exemple, et ceci grâce à des mécanismes tel que la réduction du nombre de lectures écritures sur le disque, la valorisation du traitement en mémoire et l'utilisation des mémoires cache et RAM pour les données intermédiaires.</li>
<li><strong>Dynamicité</strong>: Il est facile de développer des applications parallèles, grâce aux opérateurs haut niveau fournis par Spark (allant jusqu'à 80 opérateurs).</li>
<li><strong>Tolérance aux Fautes</strong>: Apache Spark fournit un mécanisme de tolérance aux fautes grâce aux RDD. Ces structures en mémoire sont conçues pour récupérer les données en cas de panne.</li>
<li><strong>Traitements à la volée</strong>: L'un des avantages de Spark par rapport à Hadoop Map Reduce, c'est qu'il permet de traiter les données à la volée, pas uniquement en batch.</li>
<li><strong>Évaluations Paresseuses (<em>Lazy Evaluations</em>)</strong>: Toutes les <em>transformations</em> faites sur Spark RDD sont paresseuses de nature, ce qui veut dire qu'elles ne donnent pas de résultat direct après leur exécution, mais génèrent un nouvel RDD à partir de l'ancien. On n'exécute effectivement les transformations qu'au moment de lancer une <em>action</em> sur les données. Nous allons détailler cet aspect plus tard dans le cours.</li>
<li><strong>Support de plusieurs langages</strong>: Plusieurs langages de programmation sont supportés par Spark, tel que Java, R, Scala et Python.</li>
<li><strong>Une communauté active et en expansion</strong>: Des développeurs de plus de 50 entreprises sont impliqués dans le développement et l'amélioration de Spark. Ce projet a été initié en 2009 et est encore en expansion.</li>
<li><strong>Support d'analyses sophistiquées</strong>: Spark est fourni avec un ensemble d'outils dédiés pour le streaming, les requêtes interactives, le machine learning, etc.</li>
<li><strong>Intégration avec Hadoop</strong>: Spark peut s'exécuter indépendamment ou sur Hadoop YARN, et profiter ainsi de la puissance du système de fichiers distribué Hadoop HDFS.</li>
</ul>
<h2 id="limitations-de-spark">Limitations de Spark</h2>
<p>Spark a plusieurs limitations, tel que : [^DataFlair]</p>
<ul>
<li><strong>Pas de support pour le traitement en temps réel</strong>: Spark permet le traitement en temps-presque-réel, car il utilise le traitement en micro-lot plutôt que le traitement en streaming.</li>
<li><strong>Problèmes avec les fichiers de petite taille</strong>: Spark partitionne le traitement sur plusieurs exécuteurs, et est optimisé principalement pour les grands volumes de données. L'utiliser pour des fichiers de petite taille va rajouter un coût supplémentaire, il est donc plus judicieux dans ce cas d'utiliser un traitement séquentiel classique sur une seule machine.</li>
<li><strong>Pas de système de gestion des fichiers</strong>: Spark est principalement un système de traitement, et ne fournit pas de solution pour le stockage des données. Il doit donc se baser sur d'autres systèmes de stockage tel que Hadoop HDFS ou Amazon S3.</li>
<li><strong>Coûteux</strong>: En tant que système de traitement en mémoire, le coût d'exécuter Spark sur un cluster peut être très élevé en terme de consommation mémoire.</li>
<li><strong>Nombre d'algorithmes limité</strong>: Malgré la disponibilité de la bibliothèque MLlib, elle reste limitée en termes de nombre d'algorithmes implémentés.</li>
<li><strong>Latence</strong>: La latence de Spark pour l'exécution de Jobs à la volée est plus élevée que d'autres solutions de traitement en streaming tel que <a href="https://flink.apache.org/">Flink</a>.</li>
</ul>
<h2 id="references">Références</h2>
<p>[^DataFlair]:
  Data Flair, <em>Spark Tutorial: Learn Spark Programming</em>, <a href="https://data-flair.training/blogs/spark-tutorial/">https://data-flair.training/blogs/spark-tutorial/</a>, consulté le 02/2020</p>
<p>[^Architecture]:
  Spark Documentation, <em>Cluster Mode Overview</em>, <a href="https://spark.apache.org/docs/latest/cluster-overview.html">https://spark.apache.org/docs/latest/cluster-overview.html</a>, consulté le 02/2020</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2019 - 2020 Lilia Sfaxi</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
