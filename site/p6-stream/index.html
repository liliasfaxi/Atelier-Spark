<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Lilia Sfaxi">
        <link rel="canonical" href="http://liliasfaxi.github.io/Atelier-Spark/p6-stream/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>P6 - Spark Streaming - Atelier Apache Spark</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Atelier Apache Spark</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Atelier Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p1-big-data/" class="nav-link">P1 - Introduction au Big Data</a>
                            </li>
                            <li class="navitem">
                                <a href="../p2-spark/" class="nav-link">P2 - Introduction à Apache Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p3-install/" class="nav-link">P3 - Installation de Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p4-batch/" class="nav-link">P4 - RDD et Batch Processing avec Spark</a>
                            </li>
                            <li class="navitem">
                                <a href="../p5-sql/" class="nav-link">P5 - Spark SQL</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">P6 - Spark Streaming</a>
                            </li>
                            <li class="navitem">
                                <a href="../p7-ml/" class="nav-link">P7 - Spark MLLib</a>
                            </li>
                            <li class="navitem">
                                <a href="../p8-graphx/" class="nav-link">P8 - Spark GraphX</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../p5-sql/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../p7-ml/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p6-stream.md" class="nav-link">Edit on liliasfaxi/Atelier-Spark</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#partie-6-spark-streaming" class="nav-link">Partie 6 - Spark Streaming</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#presentation-de-spark-streaming" class="nav-link">Présentation de Spark Streaming</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#les-dstreams" class="nav-link">Les DStreams</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#environnement-et-code" class="nav-link">Environnement et Code</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#references" class="nav-link">Références</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="partie-6-spark-streaming">Partie 6 - Spark Streaming</h1>
<p><center><img src="../img/p6/streaming.png" width="600pt"></center></p>
<h2 id="presentation-de-spark-streaming">Présentation de Spark Streaming</h2>
<p>Un flux de données (ou <em>data stream</em>) est une séquence non bornée de données qui arrive de manière continue. Le streaming divise le flux continu des données en unités discrètes pour les traiter. Le traitement de flux est un traitement à faible latence, et une analyse des données en streaming.</p>
<p><strong>Spark Streaming</strong> a été ajouté à Apache Spark en 2013, comme extension de l'API de base de Spark, qui fournit un traitement de flux scalable, à haut débit et tolérant aux fautes. L'ingestion de données peut être réalisée par plusieurs outils tels que <a href="https://kafka.apache.org/">Apache Kafka</a>, <a href="https://flume.apache.org/">Apache Flume</a> ou <a href="https://aws.amazon.com/kinesis/">Amazon Kinesis</a>, et le traitement peut être fait grâce à des algorithmes complexes, exprimés par des fonctions de haut niveau tel que <em>map</em>, <em>reduce</em>, <em>join</em>, etc. Finalement, les données traitées peuvent être envoyées vers des systèmes de fichiers, bases de données ou tableaux de bord en temps réels. Il est même possible de réaliser des algorithmes de machine learning et de traitement de graphes sur les flux de données.</p>
<p><center><img src="../img/p6/spark-streaming.png" width="400"></center></p>
<p>En interne, il fonctionne comme suit: Spark Streaming reçoit des données en streaming et les divise en micro-batches, qui sont ensuite calculés par le moteur de spark pour générer le flux final de résultats.</p>
<p><center><img src="../img/p6/micro-batch.png" width="500"></center></p>
<p>Au lieu de traiter les flux de données un élément à la fois, Spark Streaming les discrétise en micro-lots. En d'autres termes, les récepteurs de Spark Streaming acceptent les données en parallèle et les envoient sur la mémoire des noeuds Workers de Spark. Ensuite, le moteur optimisé de Spark exécuter de courtes tâches pour traiter les lots et envoyer les résultats à d'autre systèmes.</p>
<p>Contrairement au modèle d'opérateur continu, où le traitement est statiquement alloué à un noeud, les tâches de Spark sont affectées aux Workers de façon dynamique, sur la base de la localité des données et des ressources disponibles. Ceci permet une meilleure répartition des charges et une récupération plus rapide en cas de faute.</p>
<p>Chaque lot de données est un RDD dans Spark. Ceci permet aux données en streaming d'être traitées grâche à n'importe quel code ou bibliothèque Spark.</p>
<h2 id="les-dstreams">Les DStreams</h2>
<p>Spark Streaming divise le flux de données en lots appelés DStream (<em>Discretized Stream</em>), qui représentent fondamentalement une séquence de RDDs.</p>
<p><center><img src="../img/p6/dstream.jpg" width="600pt">[^data-flair]</center></p>
<p>Spark DStream est l'abstraction de base de Spark Streaming. C'est un flux continu de données, qui reçoit en entrée des données à partir de sources diverses. Il peut également être un flux de données généré à partir d'un flux en entrée. DStream est un flux continu de RDD. Chaque RDD contient des données sur un intervalle particulier.</p>
<p>Chaque opération sur un DStream s'applique à tous les RDD sous-jacents. DStream offre ainsi au développeur une API de haut niveau pour faciliter le travail sur les données en streaming.</p>
<p>Les opérations sur le DStreams peuvent être:</p>
<ul>
<li><strong>Transformations</strong>: qui peuvent être:<ul>
<li>Sans état (<em>Stateless</em>): ce sont des transformations où le traitement sur un lot n'a pas de dépendance avec les lots précédents. Les transformations sans état sont de simples transformations RDD. Elles s'appliquent sur chaque batch (et sur chaque RDD) du DStream. Ceci inclut des transformations classiques telles que <em>map</em>, <em>filter</em>, <em>reduceByKey</em>, etc.</li>
<li>Avec état (<em>Stateful</em>): ces transformations utilisent des données ou des résultats intermédiaires provenant des batches précédents. Les transformations avec état sont des opérations sur les DStreams qui suivent l'évolution des données à travers le temps. Les deux types de transformations avec état sont les <em>windowed operations</em>, qui opèrent sur une fenêtre glissante de périodes de temps, et la <em>updateStateByKey</em>, utilisée pour suivre l'état à travers les évènements de chaque clef.</li>
</ul>
</li>
<li><strong>Output Operations</strong>: elles sont réalisées pour renvoyer un résultat après les transformations. C'est l'équivalent des <em>actions</em> pour les RDDs. On peut citer: <em>print</em>, <em>save</em>, etc.</li>
</ul>
<h2 id="environnement-et-code">Environnement et Code</h2>
<p>Nous allons commencer par tester le streaming en local, comme d'habitude. Pour cela:</p>
<ol>
<li>Commencer par créer un nouveau projet Maven, avec le fichier pom suivant:
  ```xml
  <?xml version="1.0" encoding="UTF-8"?></li>
</ol>
<p><project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion></p>
<pre><code>&lt;groupId&gt;spark.streaming&lt;/groupId&gt;
&lt;artifactId&gt;stream&lt;/artifactId&gt;
&lt;version&gt;1&lt;/version&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.2.1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-streaming_2.11&lt;/artifactId&gt;
        &lt;version&gt;2.2.1&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.1&lt;/version&gt;
            &lt;configuration&gt;
                &lt;source&gt;1.8&lt;/source&gt;
                &lt;target&gt;1.8&lt;/target&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>
<p></project>
  ```
  2. Créer une classe <em>tn.spark.streaming.Stream</em> avec le code suivant:</p>
<p>```java
  package tn.spark.streaming;</p>
<p>import org.apache.spark.SparkConf;
  import org.apache.spark.streaming.Durations;
  import org.apache.spark.streaming.api.java.JavaDStream;
  import org.apache.spark.streaming.api.java.JavaPairDStream;
  import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
  import org.apache.spark.streaming.api.java.JavaStreamingContext;
  import scala.Tuple2;</p>
<p>import java.util.Arrays;</p>
<pre><code>public class Stream {
  public static void main(String[] args) throws InterruptedException {
      SparkConf conf = new SparkConf()
          .setAppName("NetworkWordCount")
          .setMaster("local[*]");
      JavaStreamingContext jssc =
          new JavaStreamingContext(conf, Durations.seconds(1));

      JavaReceiverInputDStream&lt;String&gt; lines =
          jssc.socketTextStream("localhost", 9999);

      JavaDStream&lt;String&gt; words =
          lines.flatMap(x -&gt; Arrays.asList(x.split(" ")).iterator());
      JavaPairDStream&lt;String, Integer&gt; pairs =
          words.mapToPair(s -&gt; new Tuple2&lt;&gt;(s, 1));
      JavaPairDStream&lt;String, Integer&gt; wordCounts =
          pairs.reduceByKey((i1, i2) -&gt; i1 + i2);

      wordCounts.print();
      jssc.start();
      jssc.awaitTermination();
  }
}
</code></pre>
<p>```</p>
<p>Ce code permet de calculer le nombre de mots dans un stream de données toutes les secondes.</p>
<h3 id="test-du-code-en-local">Test du code en Local</h3>
<p>Le stream ici sera diffusé par une petite commande utilitaire qui se trouve dans la majorité des systèmes Unix-like.</p>
<ul>
<li>Exécuter votre classe <em>Stream</em>. Vous verrez défiler sur votre console des lignes en continu: l'application est en écoute sur localhost:9999.</li>
<li>Ouvrir un terminal, et taper la commande suivante pour créer le stream:
    <code>Bash
      nc -lk 9999</code>
    Vous pourrez alors taper les entrées de votre choix.</li>
</ul>
<p>!!! note "Remarque"
    L'équivalent de nc -lk sur Windows est l'utilitaure <a href="https://nmap.org/ncat/">ncat</a></p>
<p>A chaque fois que vous entrez quelque chose sur le terminal, l'application l'intercepte, et l'affichage sur l'écran de la console change, comme suit:</p>
<p><img alt="Test Streaming" src="../img/p6/stream-intercepted.png" /></p>
<p>Ainsi, chaque seconde, le programme exécute un wordcount sur la chaine entrée dans la fenêtre du terminal.</p>
<h3 id="lancement-du-code-sur-le-cluster">Lancement du code sur le cluster</h3>
<p>Pour lancer le code précédent sur le cluster, il faudra d'abord faire des petites modifications:</p>
<pre><code class="language-java">    public class Stream {
    public static void main(String[] args) throws InterruptedException {
        SparkConf conf = new SparkConf().setAppName(&quot;NetworkWordCount&quot;);
        JavaStreamingContext jssc =
            new JavaStreamingContext(conf, Durations.seconds(1));

        JavaReceiverInputDStream&lt;String&gt; lines =
            jssc.socketTextStream(&quot;&lt;votre-ip&gt;&quot;, 9999);

        JavaDStream&lt;String&gt; words =
            lines.flatMap(x -&gt; Arrays.asList(x.split(&quot; &quot;)).iterator());
        JavaPairDStream&lt;String, Integer&gt; pairs =
            words.mapToPair(s -&gt; new Tuple2&lt;&gt;(s, 1));
        JavaPairDStream&lt;String, Integer&gt; wordCounts =
            pairs.reduceByKey((i1, i2) -&gt; i1 + i2);

        wordCounts.print();
        jssc.start();
        jssc.awaitTermination();
    }
  }
</code></pre>
<p>!!!warning "Attention"
      Veillez à mettre l'IP de votre machine locale (sur laquelle vous allez lancer le flux avec <em>nc</em>) à la place de &lt;votre-ip>. Vous pourrez trouver votre IP avec la commande ifconfig (pour les systèmes Linux/Mac) ou ipconfig (pour les systèmes Windows).</p>
<p>Les détails de la réalisation des étapes suivantes sont semblables à celles réalisées dans la Partie <a href="../p4-batch/index.html#lancement-du-code-sur-le-cluster">P4 - RDD et Batch Processing avec Spark</a></p>
<ul>
<li>Lancer un <code>mvn package install</code>pour créer le fichier jar.</li>
<li>Copier le fichier jar sur le contenaire maître du cluster spark.</li>
<li>Lancer la commande suivante:</li>
</ul>
<p><code>bash
      spark-submit --class tn.spark.streaming.Stream
                   --master local
                   stream-1.jar</code></p>
<p>En arrêtant l'exécution du flux (taper pour cela <code>Ctrl-C</code>), et en revenant en arrière dans le terminal, vous constaterez que le calcul du nombre de mots est fait de façon périodique:</p>
<p><img alt="Test Streaming" src="../img/p6/stream-result.png" /></p>
<h2 id="references">Références</h2>
<p>[^spark-official]:
  Spark Documentation, <em>Spark Streaming Programming Guide</em>, <a href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">https://spark.apache.org/docs/latest/streaming-programming-guide.html</a>, consulté le 04/2020</p>
<p>[^data-flair]:
  Data Flair, <em>Spark Tutorial: Learn Spark Programming</em>, <a href="https://data-flair.training/blogs/spark-tutorial/">https://data-flair.training/blogs/spark-tutorial/</a>, consulté le 03/2020</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2019 - 2020 Lilia Sfaxi</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
