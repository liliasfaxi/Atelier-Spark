<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Cours et Travaux Pratiques pour se familiariser avec Apache Spark"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/Atelier-Spark/p2-spark/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>P2 - Introduction à Apache Spark - Atelier Apache Spark</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#546d78><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=blue-grey data-md-color-accent=amber> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#partie-2-introduction-a-apache-spark class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Atelier Apache Spark" class="md-header__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Atelier Apache Spark </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> P2 - Introduction à Apache Spark </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Atelier Apache Spark" class="md-nav__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Atelier Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Atelier Apache Spark </a> </li> <li class=md-nav__item> <a href=../p1-big-data/ class=md-nav__link> P1 - Introduction au Big Data </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> P2 - Introduction à Apache Spark <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> P2 - Introduction à Apache Spark </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-2-introduction-a-apache-spark class=md-nav__link> Partie 2 - Introduction à Apache Spark </a> <nav class=md-nav aria-label="Partie 2 - Introduction à Apache Spark"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#apache-spark-presentation class=md-nav__link> Apache Spark - Présentation </a> </li> <li class=md-nav__item> <a href=#apache-spark-composants class=md-nav__link> Apache Spark - Composants </a> </li> <li class=md-nav__item> <a href=#architecture-de-spark class=md-nav__link> Architecture de Spark </a> </li> <li class=md-nav__item> <a href=#caracteristiques-de-spark class=md-nav__link> Caractéristiques de Spark </a> </li> <li class=md-nav__item> <a href=#limitations-de-spark class=md-nav__link> Limitations de Spark </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> Références </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../p3-install/ class=md-nav__link> P3 - Installation de Spark </a> </li> <li class=md-nav__item> <a href=../p4-batch/ class=md-nav__link> P4 - RDD et Batch Processing avec Spark </a> </li> <li class=md-nav__item> <a href=../p5-sql/ class=md-nav__link> P5 - Spark SQL </a> </li> <li class=md-nav__item> <a href=../p6-stream/ class=md-nav__link> P6 - Spark Streaming </a> </li> <li class=md-nav__item> <a href=../p7-ml/ class=md-nav__link> P7 - Spark MLLib </a> </li> <li class=md-nav__item> <a href=../p8-graphx/ class=md-nav__link> P8 - Spark GraphX </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-2-introduction-a-apache-spark class=md-nav__link> Partie 2 - Introduction à Apache Spark </a> <nav class=md-nav aria-label="Partie 2 - Introduction à Apache Spark"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#apache-spark-presentation class=md-nav__link> Apache Spark - Présentation </a> </li> <li class=md-nav__item> <a href=#apache-spark-composants class=md-nav__link> Apache Spark - Composants </a> </li> <li class=md-nav__item> <a href=#architecture-de-spark class=md-nav__link> Architecture de Spark </a> </li> <li class=md-nav__item> <a href=#caracteristiques-de-spark class=md-nav__link> Caractéristiques de Spark </a> </li> <li class=md-nav__item> <a href=#limitations-de-spark class=md-nav__link> Limitations de Spark </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> Références </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p2-spark.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>P2 - Introduction à Apache Spark</h1> <h2 id=partie-2-introduction-a-apache-spark>Partie 2 - Introduction à Apache Spark<a class=headerlink href=#partie-2-introduction-a-apache-spark title="Permanent link">&para;</a></h2> <p><center><img src=../img/p3/spark.jpeg width=400pt></center></p> <h3 id=apache-spark-presentation>Apache Spark - Présentation<a class=headerlink href=#apache-spark-presentation title="Permanent link">&para;</a></h3> <p>Apache Spark est une plateforme de traitement sur cluster générique. C'est un moteur de traitement libre, assurant un traitement parallèle et distribué sur des données massives. Il fournit une API de développement pour permettre un traitement en streaming, l'apprentissage automatique ou la gestion de requêtes SQL et demandant des accès répétés sur un grand volume de données. [^DataFlair]</p> <p>Apache Spark permet de réaliser des traitements par lot (<em>batch processing</em>) ou à la volée (<em>stream processing</em>) et est conçu de façon à pouvoir intégrer tous les outils et technologies Big Data. Par exemple, non seulement Spark peut-il accéder aux sources de données de Hadoop, il peut également tourner sur un cluster Hadoop. Étant donné que Spark n'offre pas de solution de stockage (pas encore en tout cas), il est logique qu'il puisse profiter de la puissance de HDFS (le système de fichiers de Hadoop), tout en offrant lui des performances inégalées pour le traitement en batch, ainsi que d'autres facilités (non offertes par Hadoop Map Reduce) telles que le traitement itératif, interactif et à la volée.</p> <p>Spark offre des APIs de haut niveau en Java, Scala, Python et R. Il utilise le traitement en mémoire (<em>in-memory processing</em>), en exploitant les ressources combinées du cluster comme si c'était une machine unique.</p> <p>Apache Spark a été créé en 2009 au laboratoire UC Berkeley R&amp;D Lab (appelé maintenant AMPLab), et est devenu open-source en 2010 avec une licence BSD. En 2013, il a intégré Apache Software Foundation, pour devenir, en 2014, un projet Apache de haut niveau.</p> <h3 id=apache-spark-composants>Apache Spark - Composants<a class=headerlink href=#apache-spark-composants title="Permanent link">&para;</a></h3> <p>Apache Spark utilise une architecture en couches, comportant plusieurs composants, dont l'objectif est de permettre de réaliser des traitements performants tout en promettant un développement et une intégration facilitées. Il est né à la base pour pallier les problèmes posés par Hadoop Map Reduce, mais est devenu une entité à lui seul, offrant bien plus que le traitement par lot classique. [^DataFlair]</p> <p>Voici les composants de Spark:</p> <p><center><img src=../img/p2/spark.png width=200pt></center> <center><img src=../img/p2/spark-layers.png width=400pt></center></p> <ol> <li> <p><strong>Spark Core</strong> Spark Core est le point central de Spark, qui fournit une plateforme d'exécution pour toutes les applications Spark. De plus, il supporte un large éventail d'applications.</p> </li> <li> <p><strong>Spark SQL</strong> Spark SQL se situe au dessus de Spark, pour permettre aux utilisateurs d'utiliser des requêtes SQL/HQL. Les données structurées et semi-structurées peuvent ainsi être traitées grâce à Spark SQL, avec une performance améliorée.</p> </li> <li> <p><strong>Spark Streaming</strong> Spark Streaming permet de créer des applications d'analyse de données interactives. Les flux de données sont transformés en micro-lots et traités par dessus Spark Core.</p> </li> <li> <p><strong>Spark MLlib</strong> La bibliothèque de machine learning MLlib fournit des algorithmes de haute qualité pour l'apprentissage automatique. Ce sont des libraries riches, très utiles pour les data scientists, autorisant de plus des traitements en mémoire améliorant de façon drastique la performance de ces algorithmes sur des données massives.</p> </li> <li> <p><strong>Spark GraphX</strong> Spark Graphx est le moteur d'exécution permettant un traitement scalable utilisant les graphes, se basant sur Spark Core.</p> </li> </ol> <h3 id=architecture-de-spark>Architecture de Spark<a class=headerlink href=#architecture-de-spark title="Permanent link">&para;</a></h3> <p>Les applications Spark s'exécutent comme un ensemble indépendant de processus sur un cluster, coordonnés par un objet <em>SparkContext</em> dans le programme principal, appelé <em>driver program</em>. [^Architecture]</p> <p>Pour s'exécuter sur un cluster, <em>SparkContext</em> peut se connecter à plusieurs types de gestionnaires de clusters (<em>Cluster Managers</em>):</p> <ul> <li>Sur le <a href=https://spark.apache.org/docs/latest/spark-standalone.html>gestionnaire autonome de Spark</a>, qui est inclus dans Spark, et qui présente le moyen le plus rapide et simple de mettre en place un cluster.</li> <li>Sur <a href=https://spark.apache.org/docs/latest/running-on-mesos.html>Apache Mesos</a>, un gestionnaire de cluster général qui peut aussi tourner sur Hadoop Map Reduce.</li> <li>Sur <a href=https://spark.apache.org/docs/latest/running-on-yarn.html>Hadoop YARN</a>, le gestionnaire de ressources de Hadoop 2.</li> <li>Sur <a href=https://spark.apache.org/docs/latest/running-on-kubernetes.html>Kubernetes</a>, un système open-source pour l'automatisation du déploiement et la gestion des applications conteneurisées.</li> </ul> <p>Ces gestionnaires permettent d'allouer les ressources nécessaires pour l'exécution de plusieurs applications Spark. Une fois connecté, Spark lance des <em>exécuteurs</em> sur les noeuds du cluster, qui sont des processus qui lancent des traitements et stockent des données pour les applications. Il envoie ensuite le code de l'application (dans un fichier JAR ou Python) aux <em>exécuteurs</em>. <em>Spark Context</em> envoie finalement les tâches à exécuter aux <em>exécuteurs</em>.</p> <p><center><img src=../img/p2/archi.png width=500pt></center></p> <p>Il est à noter que:</p> <ul> <li>Chaque application a son lot d'exécuteurs, qui restent actifs tout au long de l'exécution de l'application, et qui lancent des tâches sur plusieurs threads. Ainsi, les applications sont isolées les unes des autres, du point de vue de l'orchestration (chaque <em>driver</em> exécute ses propres tâches), et des exécuteurs (les tâches des différentes applications tournent sur des JVM différentes). Ceci implique également que les applications (ou Jobs) Sparks ne peuvent pas échanger des données, sans les enregistrer sur un support de stockage externe.</li> <li>Spark est indépendant du gestionnaire de cluster sous-jacent. Il suffit de configurer Spark pour utiliser ce gestionnaire, il peut gérer ses ressources en même temps que d'autres applications, même non-Spark.</li> <li>L'application principale (<em>driver</em>) doit être à l'écoute des connexions entrantes venant de ses exécuteurs.</li> </ul> <h3 id=caracteristiques-de-spark>Caractéristiques de Spark<a class=headerlink href=#caracteristiques-de-spark title="Permanent link">&para;</a></h3> <p>Spark est connu pour avoir plusieurs caractéristiques qui en font l'une des plateformes les plus utilisées dans le domaine des Big Data. Nous citons: [^DataFlair]</p> <ul> <li><strong>Performance de traitement</strong>: Il est possible de réaliser une vitesse de traitement très élevée avec Spark sur des fichiers volumineux qui peut être jusqu'à 100x meilleur que Hadoop Map Reduce, par exemple, et ceci grâce à des mécanismes tel que la réduction du nombre de lectures écritures sur le disque, la valorisation du traitement en mémoire et l'utilisation des mémoires cache et RAM pour les données intermédiaires.</li> <li><strong>Dynamicité</strong>: Il est facile de développer des applications parallèles, grâce aux opérateurs haut niveau fournis par Spark (allant jusqu'à 80 opérateurs).</li> <li><strong>Tolérance aux Fautes</strong>: Apache Spark fournit un mécanisme de tolérance aux fautes grâce aux RDD. Ces structures en mémoire sont conçues pour récupérer les données en cas de panne.</li> <li><strong>Traitements à la volée</strong>: L'un des avantages de Spark par rapport à Hadoop Map Reduce, c'est qu'il permet de traiter les données à la volée, pas uniquement en batch.</li> <li><strong>Évaluations Paresseuses (<em>Lazy Evaluations</em>)</strong>: Toutes les <em>transformations</em> faites sur Spark RDD sont paresseuses de nature, ce qui veut dire qu'elles ne donnent pas de résultat direct après leur exécution, mais génèrent un nouvel RDD à partir de l'ancien. On n'exécute effectivement les transformations qu'au moment de lancer une <em>action</em> sur les données. Nous allons détailler cet aspect plus tard dans le cours.</li> <li><strong>Support de plusieurs langages</strong>: Plusieurs langages de programmation sont supportés par Spark, tel que Java, R, Scala et Python.</li> <li><strong>Une communauté active et en expansion</strong>: Des développeurs de plus de 50 entreprises sont impliqués dans le développement et l'amélioration de Spark. Ce projet a été initié en 2009 et est encore en expansion.</li> <li><strong>Support d'analyses sophistiquées</strong>: Spark est fourni avec un ensemble d'outils dédiés pour le streaming, les requêtes interactives, le machine learning, etc.</li> <li><strong>Intégration avec Hadoop</strong>: Spark peut s'exécuter indépendamment ou sur Hadoop YARN, et profiter ainsi de la puissance du système de fichiers distribué Hadoop HDFS.</li> </ul> <h3 id=limitations-de-spark>Limitations de Spark<a class=headerlink href=#limitations-de-spark title="Permanent link">&para;</a></h3> <p>Spark a plusieurs limitations, tel que : [^DataFlair]</p> <ul> <li><strong>Pas de support pour le traitement en temps réel</strong>: Spark permet le traitement en temps-presque-réel, car il utilise le traitement en micro-lot plutôt que le traitement en streaming.</li> <li><strong>Problèmes avec les fichiers de petite taille</strong>: Spark partitionne le traitement sur plusieurs exécuteurs, et est optimisé principalement pour les grands volumes de données. L'utiliser pour des fichiers de petite taille va rajouter un coût supplémentaire, il est donc plus judicieux dans ce cas d'utiliser un traitement séquentiel classique sur une seule machine.</li> <li><strong>Pas de système de gestion des fichiers</strong>: Spark est principalement un système de traitement, et ne fournit pas de solution pour le stockage des données. Il doit donc se baser sur d'autres systèmes de stockage tel que Hadoop HDFS ou Amazon S3.</li> <li><strong>Coûteux</strong>: En tant que système de traitement en mémoire, le coût d'exécuter Spark sur un cluster peut être très élevé en terme de consommation mémoire.</li> <li><strong>Nombre d'algorithmes limité</strong>: Malgré la disponibilité de la bibliothèque MLlib, elle reste limitée en termes de nombre d'algorithmes implémentés.</li> <li><strong>Latence</strong>: La latence de Spark pour l'exécution de Jobs à la volée est plus élevée que d'autres solutions de traitement en streaming tel que <a href=https://flink.apache.org/ >Flink</a>.</li> </ul> <h3 id=references>Références<a class=headerlink href=#references title="Permanent link">&para;</a></h3> <p>[^DataFlair]: Data Flair, <em>Spark Tutorial: Learn Spark Programming</em>, <a href=https://data-flair.training/blogs/spark-tutorial/ >https://data-flair.training/blogs/spark-tutorial/</a>, consulté le 02/2020</p> <p>[^Architecture]: Spark Documentation, <em>Cluster Mode Overview</em>, <a href=https://spark.apache.org/docs/latest/cluster-overview.html>https://spark.apache.org/docs/latest/cluster-overview.html</a>, consulté le 02/2020</p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2020-03-23T17:27:58+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2020-03-23</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../p1-big-data/ class="md-footer__link md-footer__link--prev" aria-label="Previous: P1 - Introduction au Big Data" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> P1 - Introduction au Big Data </div> </div> </a> <a href=../p3-install/ class="md-footer__link md-footer__link--next" aria-label="Next: P3 - Installation de Spark" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> P3 - Installation de Spark </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2019 - 2020 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>