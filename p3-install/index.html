<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Cours et Travaux Pratiques pour se familiariser avec Apache Spark"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/Atelier-Spark/p3-install/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>P3 - Installation de Spark - Atelier Apache Spark</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#546d78><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=blue-grey data-md-color-accent=amber> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#partie-3-installation-de-spark class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Atelier Apache Spark" class="md-header__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Atelier Apache Spark </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> P3 - Installation de Spark </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Atelier Apache Spark" class="md-nav__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Atelier Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Atelier Apache Spark </a> </li> <li class=md-nav__item> <a href=../p1-big-data/ class=md-nav__link> P1 - Introduction au Big Data </a> </li> <li class=md-nav__item> <a href=../p2-spark/ class=md-nav__link> P2 - Introduction à Apache Spark </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> P3 - Installation de Spark <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> P3 - Installation de Spark </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-3-installation-de-spark class=md-nav__link> Partie 3 - Installation de Spark </a> <nav class=md-nav aria-label="Partie 3 - Installation de Spark"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#installation-de-spark-sur-un-seul-noeud class=md-nav__link> Installation de Spark sur un seul Noeud </a> <nav class=md-nav aria-label="Installation de Spark sur un seul Noeud"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#etape-1-telecharger-limage-de-base class=md-nav__link> Étape 1 - Télécharger l'image de base </a> </li> <li class=md-nav__item> <a href=#etape-2-installer-java class=md-nav__link> Étape 2 - Installer Java </a> </li> <li class=md-nav__item> <a href=#etape-3-installer-scala class=md-nav__link> Étape 3 - Installer Scala </a> </li> <li class=md-nav__item> <a href=#etape-4-telecharger-spark class=md-nav__link> Étape 4 - Télécharger Spark </a> </li> <li class=md-nav__item> <a href=#etape-5-mise-en-place-de-lenvironnement-spark class=md-nav__link> Étape 5 - Mise en place de l'environnement Spark </a> </li> <li class=md-nav__item> <a href=#etape-6-demarrer-un-serveur-master-en-standalone class=md-nav__link> Étape 6 - Démarrer un serveur master en standalone </a> </li> <li class=md-nav__item> <a href=#etape-7-demarrer-un-processus-worker class=md-nav__link> Étape 7 - Démarrer un processus Worker </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#installation-de-spark-sur-un-cluster class=md-nav__link> Installation de Spark sur un cluster </a> <nav class=md-nav aria-label="Installation de Spark sur un cluster"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#etape-1-installer-ssh class=md-nav__link> Étape 1 - Installer SSH </a> </li> <li class=md-nav__item> <a href=#etape-2-configurer-spark class=md-nav__link> Étape 2 - Configurer Spark </a> </li> <li class=md-nav__item> <a href=#etape-3-creer-une-image-a-partir-du-contenaire class=md-nav__link> Étape 3 - Créer une image à partir du contenaire </a> </li> <li class=md-nav__item> <a href=#etape-4-creer-le-cluster class=md-nav__link> Étape 4 - Créer le Cluster </a> </li> <li class=md-nav__item> <a href=#etape-5-demarrer-les-services-spark class=md-nav__link> Étape 5 - Démarrer les services Spark </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../p4-batch/ class=md-nav__link> P4 - RDD et Batch Processing avec Spark </a> </li> <li class=md-nav__item> <a href=../p5-sql/ class=md-nav__link> P5 - Spark SQL </a> </li> <li class=md-nav__item> <a href=../p6-stream/ class=md-nav__link> P6 - Spark Streaming </a> </li> <li class=md-nav__item> <a href=../p7-ml/ class=md-nav__link> P7 - Spark MLLib </a> </li> <li class=md-nav__item> <a href=../p8-graphx/ class=md-nav__link> P8 - Spark GraphX </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-3-installation-de-spark class=md-nav__link> Partie 3 - Installation de Spark </a> <nav class=md-nav aria-label="Partie 3 - Installation de Spark"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#installation-de-spark-sur-un-seul-noeud class=md-nav__link> Installation de Spark sur un seul Noeud </a> <nav class=md-nav aria-label="Installation de Spark sur un seul Noeud"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#etape-1-telecharger-limage-de-base class=md-nav__link> Étape 1 - Télécharger l'image de base </a> </li> <li class=md-nav__item> <a href=#etape-2-installer-java class=md-nav__link> Étape 2 - Installer Java </a> </li> <li class=md-nav__item> <a href=#etape-3-installer-scala class=md-nav__link> Étape 3 - Installer Scala </a> </li> <li class=md-nav__item> <a href=#etape-4-telecharger-spark class=md-nav__link> Étape 4 - Télécharger Spark </a> </li> <li class=md-nav__item> <a href=#etape-5-mise-en-place-de-lenvironnement-spark class=md-nav__link> Étape 5 - Mise en place de l'environnement Spark </a> </li> <li class=md-nav__item> <a href=#etape-6-demarrer-un-serveur-master-en-standalone class=md-nav__link> Étape 6 - Démarrer un serveur master en standalone </a> </li> <li class=md-nav__item> <a href=#etape-7-demarrer-un-processus-worker class=md-nav__link> Étape 7 - Démarrer un processus Worker </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#installation-de-spark-sur-un-cluster class=md-nav__link> Installation de Spark sur un cluster </a> <nav class=md-nav aria-label="Installation de Spark sur un cluster"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#etape-1-installer-ssh class=md-nav__link> Étape 1 - Installer SSH </a> </li> <li class=md-nav__item> <a href=#etape-2-configurer-spark class=md-nav__link> Étape 2 - Configurer Spark </a> </li> <li class=md-nav__item> <a href=#etape-3-creer-une-image-a-partir-du-contenaire class=md-nav__link> Étape 3 - Créer une image à partir du contenaire </a> </li> <li class=md-nav__item> <a href=#etape-4-creer-le-cluster class=md-nav__link> Étape 4 - Créer le Cluster </a> </li> <li class=md-nav__item> <a href=#etape-5-demarrer-les-services-spark class=md-nav__link> Étape 5 - Démarrer les services Spark </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p3-install.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>P3 - Installation de Spark</h1> <h2 id=partie-3-installation-de-spark>Partie 3 - Installation de Spark<a class=headerlink href=#partie-3-installation-de-spark title="Permanent link">&para;</a></h2> <p><center><img src=../img/p2/spark.jpeg width=400pt></center></p> <h3 id=installation-de-spark-sur-un-seul-noeud>Installation de Spark sur un seul Noeud<a class=headerlink href=#installation-de-spark-sur-un-seul-noeud title="Permanent link">&para;</a></h3> <p>Pour installer Spark, nous allons utiliser des contenaires <a href=https://www.docker.com/ >Docker</a>. Docker nous permettra de mettre en place un environnement complet, entièrement portable, sans rien installer sur la machine hôte, pour utiliser Spark de façon uniforme grâce aux lignes de commande.</p> <p>Nous allons suivre les étapes suivantes pour installer l'environnement Spark sur une machine ubuntu.</p> <h4 id=etape-1-telecharger-limage-de-base>Étape 1 - Télécharger l'image de base<a class=headerlink href=#etape-1-telecharger-limage-de-base title="Permanent link">&para;</a></h4> <p>Avant de suivre les étapes suivantes, il faut commencer par installer Docker. Suivre les étapes se trouvant dans le lien suivant, suivant votre système d'exploitation: <a href=https://docs.docker.com/install/ >https://docs.docker.com/install/</a></p> <p>Nous avons choisi Ubuntu comme environnement cible pour notre contenaire Docker. Nous commençons donc par télécharger l'image Ubuntu à partir de Docker Hub, avec la commande suivante:</p> <div class=highlight><pre><span></span><code>  docker pull ubuntu
</code></pre></div> <p>Nous allons ensuite créer un contenaire à partir de l'image téléchargée.</p> <p><div class=highlight><pre><span></span><code>  docker run -itd -p <span class=m>8080</span>:8080 --name spark --hostname spark ubuntu
</code></pre></div> Nous avons lancé un nouveau contenaire intitulé <em>spark</em> à partir de la machine ubuntu, en exposant sur le localhost son port 8080, pour pouvoir accéder à sa WebURL. On pourra vérifier que la machine est bien démarrée en utilisant:</p> <div class=highlight><pre><span></span><code>  docker ps
</code></pre></div> <p>On devrait obtenir un résultat semblable au suivant: <img alt="Contenaires Démarrés" src=../img/p3/started.png></p> <p>Pour se connecter à la machine et la manipuler avec les lignes de commandes, utiliser:</p> <div class=highlight><pre><span></span><code>  docker <span class=nb>exec</span> -it spark bash
</code></pre></div> <p>Le résultat sera comme suit: <img alt="Connexion à la machine" src=../img/p3/logged.png></p> <div class="admonition warning"> <p class=admonition-title>Attention</p> <p>Ces étapes sont faites une seule fois, à la première création de la machine. Si vous voulez relancer une machine déjà créée, suivre les étapes suivantes:</p> <ul> <li>Vérifier que la machine n'est pas déjà démarrée. Pour cela, taper la commande suivante: <div class=highlight><pre><span></span><code>  docker ps
</code></pre></div></li> <li> <p>Si vous retrouvez le contenaire dans la liste affichée, vous pouvez exécuter la commande <code>docker exec...</code> présentée précédemment.</p> </li> <li> <p>Sinon, vérifier que le contenaire existe bien, mais qu'il est juste stoppé, grâce à la commande: <div class=highlight><pre><span></span><code>  docker ps -a
</code></pre></div></p> </li> <li> <p>Une fois le contenaire retrouvé, le démarrer, simplement en tapant la commande suivante: <div class=highlight><pre><span></span><code>  docker start spark
</code></pre></div></p> </li> </ul> <p>Le contenaire sera lancé.</p> </div> <h4 id=etape-2-installer-java>Étape 2 - Installer Java<a class=headerlink href=#etape-2-installer-java title="Permanent link">&para;</a></h4> <p>Afin d'installer Java sur la machine, commencer par mettre à jour les packages systèmes de Ubuntu:</p> <div class=highlight><pre><span></span><code>  apt update
  apt -y upgrade
</code></pre></div> <p>Installer ensuite la version par défaut de Java:</p> <div class=highlight><pre><span></span><code>  apt install default-jdk
</code></pre></div> <p>Vérifier la version de Java que vous venez d'installer:</p> <div class=highlight><pre><span></span><code>  java -version
</code></pre></div> <h4 id=etape-3-installer-scala>Étape 3 - Installer Scala<a class=headerlink href=#etape-3-installer-scala title="Permanent link">&para;</a></h4> <p>Installer Scala :</p> <div class=highlight><pre><span></span><code>  apt install scala
</code></pre></div> <h4 id=etape-4-telecharger-spark>Étape 4 - Télécharger Spark<a class=headerlink href=#etape-4-telecharger-spark title="Permanent link">&para;</a></h4> <p>Pour installer Spark sur la machine docker, utiliser la commande suivante:</p> <div class=highlight><pre><span></span><code>  apt install curl
  curl -O https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
</code></pre></div> <p>La version stable actuelle est 2.4.5, mais vous pouvez télécharger la version de votre choix. Vous retrouverez les liens de téléchargement de toutes les versions <a href=https://archive.apache.org/dist/spark>ICI</a>.</p> <p>Extraire ensuite le fichier tgz:</p> <div class=highlight><pre><span></span><code>  tar xvf spark-2.4.5-bin-hadoop2.7.tgz
</code></pre></div> <p>Déplacer le dossier obtenu vers le répertoire /opt comme suit:</p> <div class=highlight><pre><span></span><code>  mv spark-2.4.5-bin-hadoop2.7 /opt/spark
  rm spark-2.4.5-bin-hadoop2.7.tgz
</code></pre></div> <h4 id=etape-5-mise-en-place-de-lenvironnement-spark>Étape 5 - Mise en place de l'environnement Spark<a class=headerlink href=#etape-5-mise-en-place-de-lenvironnement-spark title="Permanent link">&para;</a></h4> <p>Nous devons mettre en place certains paramètres d'environnement pour assurer une bonne exécution de Spark:</p> <ol> <li>Ouvrir le fichier de configuration bashrc (installer <a href=https://www.vim.org/ >vim</a> si nécessaire avec <code>apt install vim</code>)</li> </ol> <p><div class=highlight><pre><span></span><code>  vim ~/.bashrc
</code></pre></div> 2. Ajouter les lignes suivantes à la fin du fichier (taper <code>G</code> pour aller à la fin du fichier, puis <code>o</code> pour insérer une nouvelle ligne et passer en mode édition)</p> <p><div class=highlight><pre><span></span><code>  <span class=nb>export</span> <span class=nv>SPARK_HOME</span><span class=o>=</span>/opt/spark
  <span class=nb>export</span> <span class=nv>PATH</span><span class=o>=</span><span class=nv>$PATH</span>:<span class=nv>$SPARK_HOME</span>/bin:<span class=nv>$SPARK_HOME</span>/sbin
</code></pre></div> Quitter l'éditeur en tapant <code>:wq</code> Activer les changements réalisés en tapant <code>`source ~/.bashrc</code></p> <h4 id=etape-6-demarrer-un-serveur-master-en-standalone>Étape 6 - Démarrer un serveur master en standalone<a class=headerlink href=#etape-6-demarrer-un-serveur-master-en-standalone title="Permanent link">&para;</a></h4> <p>Il est désormais possible de démarrer un serveur en standalone, en utilisant la commande suivante:</p> <p><div class=highlight><pre><span></span><code>  start-master.sh
</code></pre></div> Vous pourrez ensuite vérifier que votre serveur est bien démarré en tapant: <code>jps</code></p> <p><img alt="Master démarré" src=../img/p3/master-started.png></p> <p>Il suffit de plus, d'aller sur le navigateur de votre machine hôte, et d'ouvrir le lien: <code>http://localhost:8080</code> (après avoir vérifié que rien d'autre ne tourne sur le même port). L'interface Web de Spark s'affichera, comme suit:</p> <p><img alt="Interface Web Spark" src=../img/p3/spark-web.png></p> <p>On remarque que la fenêtre indique que le spark master se trouve sur <code>spark://spark:7077</code></p> <h4 id=etape-7-demarrer-un-processus-worker>Étape 7 - Démarrer un processus Worker<a class=headerlink href=#etape-7-demarrer-un-processus-worker title="Permanent link">&para;</a></h4> <p>Pour lancer un processus Worker, utiliser la commande suivante:</p> <div class=highlight><pre><span></span><code>  start-slave.sh spark://spark:7077
</code></pre></div> <p>Un nouveau processus sera lancé, qu'on pourra voir avec <code>jps</code></p> <p><img alt="Worker démarré" src=../img/p3/worker-started.png></p> <p>Vous pouvez maintenant lancer Spark Shell pour executer des Jobs Spark.</p> <div class=highlight><pre><span></span><code>  spark-shell
</code></pre></div> <p><img alt="Spark Shell" src=../img/p3/spark-shell.png></p> <h3 id=installation-de-spark-sur-un-cluster>Installation de Spark sur un cluster<a class=headerlink href=#installation-de-spark-sur-un-cluster title="Permanent link">&para;</a></h3> <p>Nous allons maintenant procéder à l'installation de Spark sur un cluster, c'est à dire un ensemble de machines interconnectées, représentées dans notre cas par des contenaires Docker. L'objectif sera donc de créer un réseau de contenaires, installer Spark dessus, et lancer les processus sur les différents contenaires, de façon à obtenir le cluster suivant:</p> <p><center><img src=../img/p3/cluster.png width=400pts></center></p> <p>Pour réaliser cela, nous allons nous baser sur le contenaire créé précédemment, dans lequel nous avons installé Java et Spark.</p> <h4 id=etape-1-installer-ssh>Étape 1 - Installer SSH<a class=headerlink href=#etape-1-installer-ssh title="Permanent link">&para;</a></h4> <ol> <li>Installer OpenSSH sur la machine : <div class=highlight><pre><span></span><code>  apt install openssh-server openssh-client
</code></pre></div></li> <li>Générer une paire de clefs (quand on vous le demande, valider le chemin par défaut proposé pour enregistrer la paire de clefs): <div class=highlight><pre><span></span><code>  ssh-keygen -t rsa -P <span class=s2>&quot;&quot;</span>
</code></pre></div></li> <li>Définir la clef générée comme clef autorisée: <div class=highlight><pre><span></span><code>  cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
</code></pre></div></li> <li>Programmer ssh pour qu'il soit lancé au démarrage du contenaire. Pour cela, ajouter les lignes suivantes à la fin du fichier <code>~/.bashrc</code>: <div class=highlight><pre><span></span><code>  service ssh start
</code></pre></div></li> </ol> <h4 id=etape-2-configurer-spark>Étape 2 - Configurer Spark<a class=headerlink href=#etape-2-configurer-spark title="Permanent link">&para;</a></h4> <p>Il faudrait éditer le fichier de configuration <code>spark-env.sh</code> (se trouvant dans le répertoire <code>$SPARK_HOME/conf</code>) pour ajouter les paramètres suivants:</p> <ol> <li>Créer une copie du template du fichier <code>spark-env.sh</code> et le renommer: <div class=highlight><pre><span></span><code>  cp <span class=nv>$SPARK_HOME</span>/conf/spark-env.sh.template <span class=nv>$SPARK_HOME</span>/conf/spark-env.sh
</code></pre></div></li> <li>Ajouter les deux lignes suivantes à la fin du fichier <code>~/.bashrc</code> (n'oubliez pas de le recharger après modification avec <code>source ~/.bashrc</code>) <div class=highlight><pre><span></span><code>  <span class=nb>export</span> <span class=nv>SPARK_WORKER_CORES</span><span class=o>=</span><span class=m>8</span>
</code></pre></div></li> <li>Créer le fichier de configuration <code>slaves</code>dans le répertoire <code>$SPARK_HOME/conf</code>: <div class=highlight><pre><span></span><code>  vim <span class=nv>$SPARK_HOME</span>/conf/slaves
</code></pre></div></li> <li>Ajouter dans le fichier <code>slaves</code> les noms des contenaires workers (que nous allons créer tout à l'heure): <div class=highlight><pre><span></span><code>  spark-slave1
  spark-slave2
</code></pre></div></li> </ol> <p>Vous avez configuré Spark pour supporter deux esclaves (<em>workers</em> ou <em>slaves</em>) en plus du master.</p> <h4 id=etape-3-creer-une-image-a-partir-du-contenaire>Étape 3 - Créer une image à partir du contenaire<a class=headerlink href=#etape-3-creer-une-image-a-partir-du-contenaire title="Permanent link">&para;</a></h4> <p>Une fois le contenaire créé et configuré tel que présenté précédemment, nous allons le dupliquer pour en créer un cluster. Mais d'abord, il faut créer une image du contenaire, de façon à l'utiliser pour créer les deux autre contenaires.</p> <p>Commencer par quitter le noeud <em>spark</em> et retourner vers la machine hôte, en tapant <code>exit</code>.</p> <ol> <li>Taper la commande suivante pour créer une image à partir du contenaire spark:</li> </ol> <div class=highlight><pre><span></span><code>  docker commit spark spark-image
</code></pre></div> <p><code>commit</code> permet de créer une nouvelle image <code>spark-image</code> à partir du contenaire <code>spark</code>.</p> <p>Vérifier que <code>spark-image</code> existe bien en tapant: <code>docker images</code>.</p> <h4 id=etape-4-creer-le-cluster>Étape 4 - Créer le Cluster<a class=headerlink href=#etape-4-creer-le-cluster title="Permanent link">&para;</a></h4> <p>Pour créer le cluster à partir de l'image déjà générée, suivre les étapes suivantes:</p> <ol> <li> <p>Supprimer le contenaire spark précédemment créé: <div class=highlight><pre><span></span><code>  docker stop spark
  docker rm spark
</code></pre></div></p> </li> <li> <p>Créer un réseau qui permettra de connecter les trois noeuds du cluster: <div class=highlight><pre><span></span><code>  docker network create --driver<span class=o>=</span>bridge spark-network
</code></pre></div></p> </li> <li>Créer et lancer les trois contenaires (les instructions -p permettent de faire un mapping entre les ports de la machine hôte et ceux du contenaire): <div class=highlight><pre><span></span><code>  docker run -itd --net<span class=o>=</span>spark-network -p <span class=m>8080</span>:8080 --expose <span class=m>22</span> <span class=se>\</span>
        --name spark-master --hostname spark-master <span class=se>\</span>
        spark-image

  docker run -itd --net<span class=o>=</span>spark-network --expose <span class=m>22</span> <span class=se>\</span>
        --name spark-slave1 --hostname spark-slave1 <span class=se>\</span>
        spark-image

  docker run -itd --net<span class=o>=</span>spark-network --expose <span class=m>22</span> <span class=se>\</span>
        --name spark-slave2 --hostname spark-slave2 <span class=se>\</span>
        spark-image
</code></pre></div></li> <li>Vérifier que les trois contenaires sont bien créés: <div class=highlight><pre><span></span><code>  docker ps
</code></pre></div> Vous devriez retrouver la liste des trois contenaires: <img alt="Cluster Créé" src=../img/p3/cluster-created.png></li> </ol> <h4 id=etape-5-demarrer-les-services-spark>Étape 5 - Démarrer les services Spark<a class=headerlink href=#etape-5-demarrer-les-services-spark title="Permanent link">&para;</a></h4> <p>Pour démarrer les services spark sur tous les noeuds, commencez d'abord par vous connecter sur le contenaire principal.</p> <div class=highlight><pre><span></span><code>  docker <span class=nb>exec</span> -it spark-master bash
</code></pre></div> <p>Utilisez ensuite la commande suivante:</p> <div class=highlight><pre><span></span><code>  start-all.sh
</code></pre></div> <p>Vous obtiendrez le résultat suivant: <img alt="Start All Spark" src=../img/p3/start-all.png></p> <p>Pour vérifier que les services sont bien démarrés, aller sur le noeud Master et taper la commande <code>jps</code>, vous trouverez le résultat suivant: <img alt="Master démarré" src=../img/p3/master-started-cluster.png></p> <p>Si on fait la même chose sur un des slaves, on obtiendra le résultat suivant: <img alt="Slave démarré" src=../img/p3/slave-started-cluster.png></p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2022-02-07T15:56:41+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2022-02-07</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../p2-spark/ class="md-footer__link md-footer__link--prev" aria-label="Previous: P2 - Introduction à Apache Spark" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> P2 - Introduction à Apache Spark </div> </div> </a> <a href=../p4-batch/ class="md-footer__link md-footer__link--next" aria-label="Next: P4 - RDD et Batch Processing avec Spark" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> P4 - RDD et Batch Processing avec Spark </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2019 - 2020 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>