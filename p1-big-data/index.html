<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Cours et Travaux Pratiques pour se familiariser avec Apache Spark"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/Atelier-Spark/p1-big-data/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>P1 - Introduction au Big Data - Atelier Apache Spark</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#546d78><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=blue-grey data-md-color-accent=amber> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#partie-1-introduction-au-big-data class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Atelier Apache Spark" class="md-header__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Atelier Apache Spark </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> P1 - Introduction au Big Data </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Atelier Apache Spark" class="md-nav__button md-logo" aria-label="Atelier Apache Spark" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Atelier Apache Spark </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/Atelier-Spark/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/Atelier-Spark </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. class=md-nav__link> Atelier Apache Spark </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> P1 - Introduction au Big Data <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> P1 - Introduction au Big Data </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-1-introduction-au-big-data class=md-nav__link> Partie 1 - Introduction au Big Data </a> <nav class=md-nav aria-label="Partie 1 - Introduction au Big Data"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#les-big-data-pourquoi class=md-nav__link> Les "Big Data", Pourquoi? </a> </li> <li class=md-nav__item> <a href=#caracteristiques-des-donnees-massives class=md-nav__link> Caract√©ristiques des Donn√©es Massives </a> </li> <li class=md-nav__item> <a href=#infrastructure-big-data-besoins class=md-nav__link> Infrastructure Big Data : Besoins </a> </li> <li class=md-nav__item> <a href=#theoreme-cap class=md-nav__link> Th√©or√®me CAP </a> </li> <li class=md-nav__item> <a href=#principes-de-base-du-domaine-des-big-data class=md-nav__link> Principes de base du Domaine des Big Data </a> </li> <li class=md-nav__item> <a href=#technologies-et-paradigmes class=md-nav__link> Technologies et Paradigmes </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../p2-spark/ class=md-nav__link> P2 - Introduction √† Apache Spark </a> </li> <li class=md-nav__item> <a href=../p3-install/ class=md-nav__link> P3 - Installation de Spark </a> </li> <li class=md-nav__item> <a href=../p4-batch/ class=md-nav__link> P4 - RDD et Batch Processing avec Spark </a> </li> <li class=md-nav__item> <a href=../p5-sql/ class=md-nav__link> P5 - Spark SQL </a> </li> <li class=md-nav__item> <a href=../p6-stream/ class=md-nav__link> P6 - Spark Streaming </a> </li> <li class=md-nav__item> <a href=../p7-ml/ class=md-nav__link> P7 - Spark MLLib </a> </li> <li class=md-nav__item> <a href=../p8-graphx/ class=md-nav__link> P8 - Spark GraphX </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#partie-1-introduction-au-big-data class=md-nav__link> Partie 1 - Introduction au Big Data </a> <nav class=md-nav aria-label="Partie 1 - Introduction au Big Data"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#les-big-data-pourquoi class=md-nav__link> Les "Big Data", Pourquoi? </a> </li> <li class=md-nav__item> <a href=#caracteristiques-des-donnees-massives class=md-nav__link> Caract√©ristiques des Donn√©es Massives </a> </li> <li class=md-nav__item> <a href=#infrastructure-big-data-besoins class=md-nav__link> Infrastructure Big Data : Besoins </a> </li> <li class=md-nav__item> <a href=#theoreme-cap class=md-nav__link> Th√©or√®me CAP </a> </li> <li class=md-nav__item> <a href=#principes-de-base-du-domaine-des-big-data class=md-nav__link> Principes de base du Domaine des Big Data </a> </li> <li class=md-nav__item> <a href=#technologies-et-paradigmes class=md-nav__link> Technologies et Paradigmes </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/Atelier-Spark/edit/master/docs/p1-big-data.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>P1 - Introduction au Big Data</h1> <h2 id=partie-1-introduction-au-big-data>Partie 1 - Introduction au Big Data<a class=headerlink href=#partie-1-introduction-au-big-data title="Permanent link">&para;</a></h2> <p><img alt="Big Data" src=../img/p1/big-data.jpeg></p> <h3 id=les-big-data-pourquoi>Les "Big Data", Pourquoi?<a class=headerlink href=#les-big-data-pourquoi title="Permanent link">&para;</a></h3> <p>L'√™tre humain, √† travers l'humanit√©, a toujours cherch√© trois choses : Savoir (qu'est-ce qui s'est pass√©?), Comprendre (pourquoi cela s'est-il pass√©?) et Pr√©dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam√© l'omniscience en ayant recours √† des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal.</p> <p>Cela dit, ces moyens ne sont gu√®res satisfaisants √† l'esprit m√©ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle √† tout √©v√®nement, et une justification convainquante √† tout comportement. Le scientifique se base sur des faits. Il veut arriver √† faire de la magie gr√¢ce √† la technologie.</p> <p>Pour arriver √† ces fins, le scientifique a besoin de donn√©es. L'int√©r√™t de collecter des donn√©es et de les exploiter a longtemps √©t√© n√©glig√©, et a √©t√© limit√© au peu de donn√©es, jug√©es "utiles", qui semblaient suffisantes pour atteindre un objectif imm√©diat. Cependant, adopter le chemin √©vident et peu risqu√© n'aurait jamais permis de r√©aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen..</p> <p>Le terme Big Data est apparu peu de temps apr√®s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une √®re o√π l'ajout des donn√©es √©tait exclusivement r√©serv√© √† une √©lite experte, o√π le volume des donn√©es disponible √©tait petit mais o√π les donn√©es √©taient pr√©cieuses et pertinentes, vers une √®re o√π tout un chacun √©tait capable d'introduire des connaissances, v√©ridiques ou pas, qui seraient sauvegard√©es dans une m√©moire collective jusqu'√† la fin des temps. Ce changement de paradigme a entrain√© le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn√©es, mais √©galement d'en extraire de la valeur.</p> <p>Ces infrastructures auront la capacit√© de g√©rer toute la cha√Æne logistique des donn√©es, de la collecte vers l'affichage. Cela semble √©vident, me direz-vous, car les syst√®mes classiques sont capables de faire cela. Qui stocke mieux les donn√©es qu'une bonne vieille base de donn√©es relationnelle? Le probl√®me est que les donn√©es dites "Big Data" sont caract√©ris√©es par des propri√©t√©s telles que, les syst√®mes classiques de stockage et de traitement auraient du mal √† les exploiter √† leur juste valeur.</p> <h3 id=caracteristiques-des-donnees-massives>Caract√©ristiques des Donn√©es Massives<a class=headerlink href=#caracteristiques-des-donnees-massives title="Permanent link">&para;</a></h3> <p>Le terme "donn√©es massives", ou "Big Data", ne donne √† mon avis pas enti√®rement justice aux donn√©es de notre domaine. En effet, il repr√©sente une seule caract√©ristique parmis plusieurs, le Volume, qui, m√™me si elle semble √™tre la plus importante, est loin d'√™tre la plus critique.</p> <p>En effet, les donn√©es massives sont caract√©ris√©es par les fameux <strong>*V</strong>. Il en existe plusieurs (10 jusqu'√† ce jour si je ne m'abuse, <a href=https://www.kdnuggets.com/2017/04/42-vs-big-data-data-science.html>certains</a> en citent m√™me 42!!!), mais pourraient √† mon avis √™tre r√©sum√©s en trois caract√©ristiques primordiales, autours de la combinaison desquelles tournent toutes les d√©cisions prises dans ce domaine.</p> <ul> <li> <p><strong>Volume</strong> C'est √©videmment le V le plus manifeste, qui caract√©rise le fait que les donn√©es ont un volume √©norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'√† <span class=arithmatex><span class=MathJax_Preview>2^{80}</span><script type=math/tex>2^{80}</script></span> octets!). Mais ceci n'est pas tout. Un volume √©norme, s'il reste constant, est g√©rable : il suffit de trouver une machine suffisamment puissante pour le sauvegarder. Le probl√®me avec la propri√©t√© du volume, c'est qu'il augmente de fa√ßon continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann√©e, atteste que <em>"Over the last two years alone 90 percent of the data in the world was generated."</em> Il est donc primordial de trouver un moyen de g√©rer ce volume toujours croissant des donn√©es.</p> </li> <li> <p><strong>V√©locit√©</strong> Cette propri√©t√© est, √† mon avis, la plus probl√©matique des trois, car, coupl√©e avec le volume, elle rend les syst√®me actuels obsol√®tes. En effet, la v√©locit√© est, litt√©ralement, "La vitesse avec laquelle quelque chose se d√©place dans une direction particuli√®re". Dans notre cas, la v√©locit√© des donn√©es est la responsable directe du volume croissant des donn√©es dans le syst√®me. Elle est provoqu√©e par une arriv√©e des donn√©es dans le syst√®me sous la forme d'un flux constant qui demande √† √™tre stock√© et trait√© imm√©diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr√©sentation r√©cente et fid√®le de l'√©tat des donn√©es. D'ailleurs, cette propri√©t√© a engendr√© une autre pr√©occupation des analystes des donn√©es, qui est de fournir une introspection en temps r√©el sur les donn√©es, les qualifiant ainsi de "<em>Fast Data</em>".</p> </li> <li> <p><strong>Vari√©t√©</strong> Ce qui distingue vraiment les donn√©es massives des donn√©es g√©r√©es classiquement dans des bases de donn√©es op√©rationnelles, c'est le support des donn√©es semi- et non structur√©es. En effet, les donn√©es non structur√©es sont des donn√©es qu'on stocke dans un format qui n'est pas d√©fini √† la cr√©ation, telles que les donn√©es textuelles, images ou sons. Les donn√©es semi-structur√©es sont des donn√©es qui contiennent une structure, mais une structure qui n'est pas rigide, et dont on ne d√©finit pas les contraintes √† l'insertion de la donn√©e, contrairement aux donn√©es structur√©es (se trouvant typiquement dans des bases de donn√©es relationnelles) qui, si elles ne respectent pas la structure d√©finie, sont consid√©r√©es fausses et ne sont pas autoris√©es √† √™tre enregistr√©es. On estime que seules 15% des donn√©es dans une entreprise sont des donn√©es structur√©es, contre 85% qui ne le sont pas! Dans une optique centr√©e sur les donn√©es, dont le but est de gagner le maximum de vision √† partir des donn√©es, perdre autant de sources d'information est un vrai probl√®me. Il est donc important que les syst√®mes Big Data sachent interpr√©ter ces donn√©es et en extraire le maximum de valeur.</p> </li> </ul> <p>Toutes les d√©cisions, choix et propri√©t√©s prises au niveau des architectures et infrastructures Big Data sont r√©gies par ces trois caract√©ristiques, ce qui va compl√®tement changer la vision "relationnelle" que tout informaticien qui se respecte a acquis tout au long de ses ann√©es d'√©tude et de travail.</p> <p>Cela dit, ce ne sont pas les seules propri√©t√©s. D'autres V ont vu le jour, mais sans jamais avoir autant d'impact sur l'infrastructre, plut√¥t dans la fa√ßon de d√©finir les processus, la gouvernance et les approches m√©tier √† adopter. Nous citons par exemple :</p> <ul> <li><em>V√©racit√©</em> : c'est la confiance que nous devons avoir en nos donn√©es. Cette propri√©t√© est inversement proportionnelle au volume et √† la vari√©t√© : plus nos donn√©es sont fiables, moins elles sont diversifi√©es et volumineuses!</li> <li><em>Valeur</em> : c'est la capacit√© d'extraire de la valeur m√©tier √† partir des donn√©es.</li> <li><em>Variabilit√©</em> : une extension de la vari√©t√©, qui indique √† quel point nos donn√©es peuvent avoir des dimensions diff√©rentes √† partir des sources de donn√©es disparates.</li> <li><em>Visualisation</em> : c'est la capacit√© de nos donn√©es √† √™tre repr√©sent√©es par les outils de visualisation classiques.</li> <li>etc.</li> </ul> <h3 id=infrastructure-big-data-besoins>Infrastructure Big Data : Besoins<a class=headerlink href=#infrastructure-big-data-besoins title="Permanent link">&para;</a></h3> <p>Les caract√©ristiques des donn√©es Big Data cit√©es ci-dessus, entra√Ænent des besoins particuliers en termes d'infrastructure et d'architecture.</p> <p><strong>Volume</strong> La caract√©ristique de volume, qui implique que la taille des donn√©es augmente de fa√ßon r√©guli√®re, fait qu'on ne peut plus se contenter d'un syst√®me centralis√© classique. Car dans un syst√®me centralis√© (donc bas√© sur une seule machine), augmenter les ressources de stockage au besoin implique ce que nous appelons une <strong>scalabilit√© verticale</strong> ou un <em>scale up</em>, qui veut dire une augmentation des capacit√©s du serveur de stockage en rajoutant des processeurs, de la RAM ou des disques.</p> <p>Cependant, cette solution, bien qu'elle soit intuitive, rapide et ne requiert pas de changement architecturaux cons√©quents, implique en g√©n√©ral un temps d'arr√™t pendant l'installation, ainsi qu'une d√©pense assez cons√©quente pour faire l'acquisition d'un serveur puissant. De plus, une machine unique atteindra rapidement une limite mat√©rielle, car il vous est impossible d'augmenter ses ressources ind√©finiment.</p> <p>En contrepartie, il est possible de penser que, face √† un volume de donn√©es toujours en augmentation, il serait plus judicieux de rajouter des machines au besoin, cr√©ant ainsi un cluster de machines interconnect√©es, ou <em>syst√®me r√©parti</em>, dont la taille et la capacit√© sont virtuellement illimit√©es. Nous sommes donc face √† un autre type de scalabilit√© : la <strong>scalabilit√© horizontale</strong> ou le <em>scale out</em>.</p> <p><img alt="Scale UP vs. Scale OUT" src=../img/p1/scaling.png></p> <p>Donc Volume =&gt; <span class=highlight>Scalabilit√© Horizontale</span></p> <p><strong>V√©locit√©</strong> La v√©locit√© est une propri√©t√© qui, coupl√©e au volume, rend la gestion de l'infrastructure un vrai cauchemar. En effet, g√©rer des donn√©es en continuelle arriv√©e implique qu'il y'a un risque √©norme de perte de donn√©es, si elles ne sont pas manipul√©es √† temps. C'est pour cette raison qu'un syst√®me Big Data se doit d'√™tre continuellement disponible : toute requ√™te de lecture ou d'√©criture doit √™tre trait√©e en un temps raisonnable, et le syst√®me doit √™tre continuellement alerte pour saisir toutes les donn√©es, sans risquer de les perdre.</p> <p>Ainsi V√©locit√© =&gt; <span class=highlight>Disponibilit√©</span></p> <p><strong>Vari√©t√©</strong> La vari√©t√© de donn√©es implique non seulement que nous sommes en pr√©sence de donn√©es structur√©es, semi-structur√©es et non structur√©es, mais √©galement que ces donn√©es peuvent parvenir de sources diff√©rentes, avec des formats diff√©rents, et que m√™me √† partir d'une m√™me source, ce format peut changer d'un moment √† un autre. Dans les syst√®mes classiques, tout ce qui est variable doit passer par une couche d'homog√©n√©isation qui transformera chaque entr√©e ou enregistrement dans la forme souhait√©e, en remplissant par des valeurs NULL les donn√©es manquantes. Rajouter cette couche d'homog√©n√©isation aura un double impact n√©gatif sur notre syst√®me : (1) √† cause de la v√©locit√©, cette op√©ration risquera de ralentir la collecte et saisie des donn√©es entrantes, et (2) on pourra subir une perte de donn√©es suite √† ces transformations.</p> <p>C'est pour ces raisons qu'un syst√®me Big Data se doit de supporter des types de donn√©es changeants, sans pour autant requ√©rir √† des subterfuges qui alourdissent ou contournent le syst√®me de stockage.</p> <p>D'o√π Vari√©t√© =&gt; <span class=highlight>Flexibilit√©</span></p> <h3 id=theoreme-cap>Th√©or√®me CAP<a class=headerlink href=#theoreme-cap title="Permanent link">&para;</a></h3> <p>Les besoins de scalabilit√©, disponibilit√© et flexibilit√©, obligatoires pour avoir un syst√®me Big Data en bonne et due forme, se trouvent confront√©s √† une contrainte de taille... et qu'en est-il de la coh√©rence (commun√©ment appel√©e aussi consistence, par anglicisme)? La coh√©rence repr√©sente en effet un <em>must</em> pour les syst√®mes relationnels classiques, et une base sur laquelle sont prises toutes les d√©cisions conceptuelles et techniques. Elle repr√©sente le fait que les donn√©es stables doivent respecter toutes les contraintes d'int√©grit√© d√©finies √† la cr√©ation de la base de donn√©e. Par exemple, si un champ est d√©cr√©t√© "Not Null", il doit le rester quelque soit la situation, et √† aucun moment une requ√™te ne doit surprendre ce champs avec une valeur nulle, m√™me si c'est juste une valeur interm√©diaire. La coh√©rence est un principe tr√®s rigide dans les bases de donn√©es relationnelles, et repr√©sente le crit√®re de base pour la gestion des transactions : le <strong>C</strong> de <strong>ACID</strong>.</p> <p>Cela dit, dans les syst√®mes Big Data, nous nous trouvons confront√©s √† un probl√®me de taille : nous devons √™tre en pr√©sence d'une infrastructure r√©partie et hautement disponible. Or, il existe un th√©or√®me appel√© <strong>CAP</strong> pour <em>Consistency / Availability / Partition tolerance</em>, qui stipule que ces trois propri√©t√©s (notamment la coh√©rence, la disponibilit√© et la tol√©rance au partitionnement), ne peuvent jamais avoir lieu en m√™me temps. Seules deux d'entre elles peuvent √™tre respect√©es √† la fois.</p> <p><center><img src=../img/p1/CAP.png width=300pt></center></p> <p>Essayons d'expliquer pourquoi.</p> <p>Un syst√®me r√©parti est dit coh√©rent si tous ses noeuds voient les m√™mes donn√©es en m√™me temps. C'est √† dire que, si nous r√©alisons une op√©ration de lecture sur un syst√®me consistant, il devrait toujours retourner la valeur la plus r√©cente qui ait √©t√© √©crite, quel que soit l'endroit √† partir duquel la lecture est effectu√©e. Ainsi, si une donn√©e est modifi√©e sur un noeud particulier, pour conserver la coh√©rence demand√©e, aucune op√©ration de lecture ne doit √™tre permise avant d'avoir mis √† jour toutes les r√©pliques (copies) de cette donn√©es. Or, les diff√©rents noeuds d'un cluster sont en g√©n√©ral distants, parfois m√™me g√©ographiquement, il est donc n√©cessaire d'attendre que la propagation de la modification se fasse sur le r√©seau, pour effectuer n'importe quelle op√©ration, m√™me une lecture. Ceci va rendre nos donn√©es indisponibles √† la lecture pendant tout le temps que durera l'op√©ration de synchronisation, qui est un temps incertain puisque... r√©seau. Assurer donc une coh√©rence forte dans un syst√®me distribu√© est en contradiction avec le besoin de disponibilit√© du syst√®me et des donn√©es. D'ailleurs, c'est ce que font les bases de donn√©es relationnelles r√©parties, qui conservent les propri√©t√©s ACID tout en distribuant les donn√©es, mais qui souffrent d'un manque notoire de performance.</p> <p>Les syst√®mes Big Data, subissant les contraintes des V pr√©c√©demment cit√©s, doivent donc faire un choix. Or ce choix est loin d'√™tre facile : qui voudra acheter un syst√®me qui pr√¥ne haut et fort qu'il est incoh√©rent ? L'id√©e serait donc de partir sur le principe de <strong>coh√©rence √©ventuelle</strong> ou parfois de <strong>coh√©rence ajustable</strong>. Ainsi, un syst√®me Big Data est un syst√®me principalement disponible, fondamentalement r√©parti, et qui assure une coh√©rence √©ventuelle au bout d'un temps g√©n√©ralement n√©gligeable, avec la possibilit√© de configurer les niveau de coh√©rence parfois m√™me dynamiquement.</p> <p>Les experts les appellent donc les syst√®mes <strong>BASE</strong> (admirez le jeux de mot.. ACID, BASE üòé):</p> <ul> <li>**B**asically **A**vailable</li> <li>**S**oft-state</li> <li>**E**ventual consistency</li> </ul> <p>La propri√©t√© de <em>Soft State</em> ou d'√©tat "mou" veut dire que l'√©tat du syst√®me peut changer dans le temps, m√™me sans qu'il y ait une nouvelle entr√©e, √† cause du principe de coh√©rence √©ventuelle expliqu√© pr√©c√©demment.</p> <p>Maintenant que vous √™tes plus familiaris√©s avec les caract√©ristiques d'un syst√®me Big Data, listons quelques principes, appel√©s ici <em>MOTTOS</em>, qui vont r√©gir nos futures d√©cisions dans ce domaine.</p> <h3 id=principes-de-base-du-domaine-des-big-data>Principes de base du Domaine des Big Data<a class=headerlink href=#principes-de-base-du-domaine-des-big-data title="Permanent link">&para;</a></h3> <p>Il est important, avant d'entamer n'importe quel travail sur les syst√®mes Big Data, de consid√©rer certains principes, qui sont parfois en enti√®re contradiction avec les principes classiques de d√©veloppement d'application. Ce n'est pas si √©tonnant : le domaine des Big Data n'est pas cens√© prendre la place des domaines relationnel et d√©cisionnel, mais plut√¥t les enrichir et les agr√©menter.</p> <p><strong><em>MOTTO 1 :</em> Stocker d'abord, r√©fl√©chir ensuite</strong> √Ä cause de la v√©locit√©, il est important de consid√©rer qu'il nous sera parfois difficile, voire impossible, de nettoyer les donn√©es ou de faire un traitement quelconque dessus, avant de les stocker. Cela risque dans bien des cas de nous faire perdre des donn√©es, le cauchemar de tout scientifique des donn√©es!</p> <p>Nous devons donc envisager la possibilit√© de d√©finir des syst√®mes de stockage qui contiennent des donn√©es non nettoy√©es, en vrac (appel√©es <em>raw data</em>), pour ensuite lancer des traitements dessus.. l'horreur pour un gestionnaire de bases des donn√©es! üò±</p> <p>Bien entendu, ces "bases" ne sont pas con√ßues pour √™tre directement exploit√©es par des applications externes, mais plut√¥t pour conserver le plus longtemps possibles les donn√©es brutes, sans perte, qui pourraient eventuellement √™tre r√©utilis√©es pour d'autres fins.</p> <p><strong><em>MOTTO 2 :</em> Absolument TOUTES les donn√©es sont importantes!</strong> D'o√π l'int√©r√™t du <em>MOTTO 1</em>. Il nous est parfois difficile, au tout d√©but de la conception des syst√®mes Big Data, de cerner toutes les possibilit√©s offertes par ces syst√®mes et par les donn√©es que nous avons √† notre disposition. Nous sommes donc en g√©n√©ral tent√©s de supprimer les donn√©es dont nous n'avons pas besoin une fois extraite l'information imm√©diatement utile. Cela dit, gr√¢ce √† l'accessibilit√© des syst√®mes de stockage magn√©tiques et leur prix de plus en plus bas, nous consid√©rons qu'il est largement plus b√©n√©fique de stocker des donn√©es qu'on n'utilisera peut-√™tre jamais, plut√¥t que de gagner de la place et perdre un potentiel pouvoir concurrentiel.</p> <p><strong><em>MOTTO 3 :</em> Ce sont les donn√©es qui pilotent le traitement</strong> Dans un syst√®me op√©rationnel classique, ainsi que dans la plupart des syst√®mes d√©cisionnels, ce sont les besoins m√©tier qui pr√©valoient : le responsable m√©tier commence par d√©finir les besoins (ou les KPIs : <em>Key Performance Indicators</em> dans le cas d'un syst√®me d√©cisionnel), puis le responsable technique con√ßoit les structures de donn√©es pour r√©pondre √† ces besoins.</p> <p>Par essence, un syst√®me Big Data fonctionne diff√©remment : les donn√©es sont collect√©es tout d'abord √† partir de toutes les sources possibles; des traitements de fouille et d'exploration de ces donn√©es sont lanc√©s ensuite, pour extraire de la valeur √† partir de ces donn√©es. L'objectif est toujours le m√™me : chercher l'effet WOW!</p> <p>D'o√π l'int√©r√™t de ce MOTTO : d√©finir le traitement √† r√©aliser d√©pend des donn√©es que nous avons r√©ussi √† collecter, et pas le contraire. Cela implique donc l'utilisation d'autres types de syst√®mes de traitement et d'algorithmes d'analyse.</p> <p><strong><em>MOTTO 4 :</em> Co-localisation des donn√©es et du traitement</strong> Un syst√®me classique √† plusieurs couches, tel que le syst√®me trois tiers par exemple, se base sur le principe de s√©paration des donn√©es et du traitement. On trouve en g√©n√©ral des donn√©es sur un serveur de bases de donn√©es s√©par√©, et les traitement complexes sur un serveur d'application qui se charge de l'aggr√©gation et de l'affichage de ces donn√©es. Ceci est agr√©ment√© d'un langage de requ√™tage d√©claratif (typiquement SQL) pour r√©aliser des op√©rations de filtrage, parfois assez lourdes et complexes, au niveau de la base de donn√©es.</p> <p>Cela dit, dans un contexte Big Data, le volume des donn√©es peut s'av√©rer assez cons√©quent, trop m√™me pour envisager de le d√©placer √† chaque fois vers un autre syst√®me pour en extraire une vraie valeur. De plus, compter sur un langage comme SQL pour diminuer le volume ou faire de simples agr√©gations au niveau de la base de donn√©es pourra la rendre indisponible pendant un moment (car n'oublions pas que nous parlons d'un syst√®me r√©parti), ce qui va √† l'encontre du principe de v√©locit√©, qui exige une disponibilit√© √† toute √©preuve du syst√®me de stockage.</p> <p>C'est pour cette raison que, pour r√©aliser les traitements voulus en un temps raisonnable et sans avoir √† trimballer les donn√©es sur le r√©seau, il est question dans les syst√®mes Big Data de d√©placer le traitement vers les donn√©es massives, au lieu de d√©placer les donn√©es vers le traitement.</p> <p><strong><em>MOTTO 5 :</em> La redondance, c'est bien</strong> Dans les bases de donn√©es relationnelles, le plus grand ennemi √† combattre dans la conception de la structure de donn√©es est la redondance, et ce pour deux raisons. La premi√®re, √©vidente, est le gain d'espace : notre espace de stockage est pr√©cieux, et nous devons √©viter de le gaspiller sans raison pr√©cise. La deuxi√®me est un besoin de coh√©rence : si nous dupliquons une m√™me information √† plusieurs endroits dans la base, nous devrons par la suite faire attention, parfois par des m√©canismes compliqu√©s et co√ªteux, √† ce que cette information soit mise √† jour instantan√©ment sur la totalit√© de ses copies.</p> <p>Ce besoin d'√©viter la redondance a cr√©√© la n√©cessit√© d'utiliser plusieurs techniques, telles que les jointures et clefs √©trang√®res, et entra√Æne parfois la cr√©ation d'un tr√®s grand nombre de tables. Ceci rajoute une complexit√© pour le requ√™tage, et une lourdeur d'ex√©cution des t√¢ches sur la base.</p> <p>Un syst√®me Big Data qui, non seulement est caract√©ris√© par un gros volume de donn√©es, mais √©galement une grande v√©locit√©, et qui doit donc √™tre imm√©diatement disponible, ne peut pas se permettre de gaspiller ses ressources en requ√™tes inutiles. On tol√®re donc √† un certain point les risques dus √† la redondance, pour gagner en disponibilit√©, primordiale dans ce type de syst√®mes.</p> <p>D'autre part, un syst√®me Big Data est un syst√®me r√©parti par excellence, et dans un syst√®me r√©parti, il est primordial d'assurer une bonne tol√©rance aux fautes en cr√©ant des r√©pliques des donn√©es, diss√©min√©es partout sur le cluster. Ces r√©pliques assurent qu'aucune machine n'est compl√®tement indispensable, et diminue le risque d'indisponibilit√© des donn√©es. Un autre signe de redondance.</p> <p><strong><em>MOTTO 6 :</em> Vive le Polyglottisme!</strong> √ätre polyglotte, c'est √™tre capable de parler plusieurs langues. Et les syst√®mes Big Data encouragent le polyglottisme. En effet, ce sont des syst√®mes complexes qui impliquent en g√©n√©ral plusieurs traitements et plusieurs types de donn√©es diff√©rentes (donn√©es brutes, donn√©es nettoy√©es, donn√©es trait√©es), ce qui fait qu'il existe deux principes importants √† encourager :</p> <ul> <li><em>Polyglot Programming</em> : Une application peut comporter plusieurs langages et paradigmes de programmation, chacun assurant un besoin particulier, de fa√ßon √† profiter des avantages de chacun √† sa juste valeur.</li> <li><em>Polyglot Persistence</em> : Dans une m√™me application, il est possible d'utiliser plusieurs syst√®mes de stockage diff√©rents (relationnels, NOSQL, syst√®mes de fichiers, etc.).</li> </ul> <p>Gr√¢ce √† ces deux principes, on pourra cr√©er des applications complexes mais compl√®tes, qui permettent d'assurer tous les besoins en terme de stockage et de traitement.</p> <h3 id=technologies-et-paradigmes>Technologies et Paradigmes<a class=headerlink href=#technologies-et-paradigmes title="Permanent link">&para;</a></h3> <p>Les op√©rations √† r√©aliser sur les syst√®mes Big Data consistent principalement en :</p> <ul> <li> <p><strong>Ingestion des donn√©es</strong> : repr√©sente les phases de collecte et d'importation des donn√©es pour √™tre stock√©es ou trait√©es √† la vol√©e. Cela peut se faire en "temps r√©el", c'est √† dire que les donn√©es sont import√©es au moment o√π elles sont √©mises par leur source, ou bien "par lots", ce qui veut dire que les donn√©es sont import√©es par portions √† intervalles r√©gulier.</p> <blockquote> <p>Exemples de technologies <a href=http://kafka.apache.org>Apache Kafka</a>, <a href=https://aws.amazon.com/kinesis/ >Amazon Kinesis</a>, <a href=https://flume.apache.org/ >Apache Flume</a>, <a href=https://sqoop.apache.org>Sqoop</a>, etc.</p> </blockquote> </li> <li> <p><strong>Stockage des donn√©es</strong> : Les syst√®mes de stockage de donn√©es respectant les propri√©t√©s le Big Data se distinguent principalement en syst√®mes de fichiers distribu√©s, tel que <a href=https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html>Hadoop HDFS</a> ou <a href=https://research.google/pubs/pub51/ >Google GFS</a>, ou bases de donn√©es NOSQL, tel que <a href=https://www.mongodb.com/ >MongoDB</a>, <a href=http://cassandra.apache.org/ >Cassandra</a>, <a href=https://redis.io/ >Redis</a> ou <a href=https://neo4j.com/ >Neo4J</a>.</p> </li> <li> <p><strong>Traitement des donn√©es</strong> : Plusieurs types de traitement de donn√©es sont possibles, nous citons :</p> <ul> <li> <p><ins><em>Traitement par lot</em></ins> <em>(Batch Processing)</em> : c'est le traitement des <em>donn√©es au repos (data at rest)</em> qui se fait sur l'ensemble des donn√©es stock√©es, sans avoir besoin d'une interaction avec l'utilisateur. Le traitement par lot est adapt√© principalement aux op√©rations ayant lieu √† la fin d'un cycle, permettant d'avoir une vision globale sur la totalit√© des donn√©es, par exemple pour avoir un rapport global ou une analyse mensuelle. Les op√©rations de traitement par lots sont en g√©n√©ral lanc√©es √† des p√©riodes r√©guli√®res, car elles sont connues pour avoir une grande latence (temps total de traitement).</p> <blockquote> <p>Exemples de technologies <a href=https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html>Hadoop Map Reduce</a> et <a href=https://spark.apache.org/docs/latest/rdd-programming-guide.html>Spark Batch</a>.</p> </blockquote> </li> <li> <p><ins><em>Traitement en Streaming</em></ins> <em>(Stream Processing)</em> : c'est le traitement des donn√©es <em>en transit (data in motion)</em>, ou en d'autres termes, le traitement des donn√©es pendant qu'elles sont produites ou re√ßues. Les donn√©es √©tant en g√©n√©ral cr√©√©es en tant que flux continu (√©v√®nements de capteurs, activit√© des utilisateurs sur un site web, flux vid√©o, etc.), elles sont captur√©es comme une s√©rie d'√©v√®nements continus dans le temps. Avant la cr√©ation des traitements en streaming, ces donn√©es √©taient stock√©es dans une base de donn√©es, un syst√®me de fichier ou tout autre forme de stockage en masse. Les applications appelleront ensuite les donn√©es au besoin. Gr√¢ce √† ce nouveau paradigme, les donn√©es peuvent maintenant √™tre trait√©es √† la vol√©e, ce qui permet √† la couche applicative d'√™tre toujours sur √©coute et √† jour.</p> <blockquote> <p>Exemples de technologies <a href=https://flink.apache.org/ >Apache Flink</a> et <a href=https://storm.apache.org/ >Apache Storm</a>.</p> </blockquote> </li> <li> <p><ins><em>Traitement par Micro-Lot</em></ins> <em>(Micro-Batch Processing)</em> : c'est la pratique de collecter les donn√©es en petits groupes (appel√©s des <em>micro-lots</em> ou des <em>micro-batchs</em>) pour les traiter. Contrairement au traditionnel traitement par lot, cette variante fait en sorte que le traitement des donn√©es soit plus fr√©quent, et que les r√©sultats soient produits avec une latence beaucoup plus petite. Les donn√©es sont collect√©es par intervalles selon un seuil pr√©d√©fini, limit√© par un temps (par exemple toutes les secondes), ou par un nombre (tous les 20 √©l√©ments). Ce traitement est en g√©n√©ral une alternative au traitement en streaming, o√π les donn√©es sont trait√©es √† la vol√©e, mais risquent d'√™tre perdues si le temps de traitement est sup√©rieur √† la fr√©quence de g√©n√©ration des donn√©es. Le micro-batching permet, par contraste, de sauvegarder les donn√©es dans un buffer, ralentissant ainsi le flux g√©n√©r√©. D'autre part, les donn√©es √©tant trait√©es par micro-lots, il est possible d'avoir une visibilit√© sur ce petit lot de donn√©es, contrairement au traitement en streaming qui n'a de visibilit√© que sur la derni√®re donn√©e g√©n√©r√©e, √† moins de proc√©der √† des m√©canismes parfois co√ªteux. En contrepartie, le traitement en micro-batch donne des r√©sultats moins r√©cents que le "vrai" streaming, et s'ex√©cute sous forme de <em>bursts</em> r√©guliers, qui peuvent parfois √™tre g√™nants pour le syst√®me sous-jacent.</p> <blockquote> <p>Exemples de technologies <a href=https://spark.apache.org/docs/latest/streaming-programming-guide.html>Spark Streaming</a> et <a href=https://www.elastic.co/logstash>Logstash</a>.</p> </blockquote> </li> <li> <p><ins><em>Traitement Interactif</em></ins> <em>(Interactive Processing)</em> : Dans les syst√®mes Big Data, la notion de transaction n'est plus exactement la m√™me que pour les syst√®mes classiques: finies les sacro-saintes propri√©t√©s ACID dont le premier objectif est d'avoir des donn√©es correctes et coh√©rentes, et bonjour les propri√©t√©s BASE, qui favorisent un acc√®s moins rigide aux donn√©es. On parle donc rarement de <em>traitement transactionnel</em> en Big Data, mais de traitements plut√¥t <em>interactifs</em> : une requ√™te est envoy√©e par le client, trait√©e imm√©diatement par le syst√®me qui renverra un r√©sultat dans un temps raisonnable. On parle alors d'<em>interaction</em> entre l'utilisateur et le syst√®me. Les traitements en batch et en streaming ne sont pas cens√©s communiquer avec un utilisateur de l'autre c√¥t√©. En g√©n√©ral, les r√©sultats de ces traitements sont enregistr√©s dans un syst√®me de stockage, qui sera, lui, par la suite interrog√© par l'utilisateur. Le traitement interactif est donc le r√©sultat d'une requ√™te de l'utilisateur, faite en g√©n√©ral sur une base de donn√©es (relationnelle ou NOSQL).</p> <blockquote> <p>Exemples de technologies <a href=https://drill.apache.org/ >Apache Drill</a>, <a href=https://docs.cloudera.com/documentation/enterprise/5-3-x/topics/impala_intro.html>Cloudera Impala</a> ou <a href=https://zeppelin.apache.org/ >Apache Zeppelin</a>.</p> </blockquote> </li> </ul> </li> </ul> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2020-02-09T10:50:37+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2020-02-09</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=.. class="md-footer__link md-footer__link--prev" aria-label="Previous: Atelier Apache Spark" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Atelier Apache Spark </div> </div> </a> <a href=../p2-spark/ class="md-footer__link md-footer__link--next" aria-label="Next: P2 - Introduction √† Apache Spark" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> P2 - Introduction √† Apache Spark </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2019 - 2020 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>