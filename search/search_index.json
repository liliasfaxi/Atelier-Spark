{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Atelier Apache Spark Ce(tte) \u0153uvre est mise \u00e0 disposition selon les termes de la Licence Creative Commons Attribution - Pas d\u2019Utilisation Commerciale - Partage dans les M\u00eames Conditions 4.0 International . Overview L'objectif de ce cours est d'initier les apprenants aux concepts de base de Apache Spark, et de faire le tours des composants qui le constituent et des cas d'utilisation. Ce cours est renforc\u00e9 par des travaux pratiques.","title":"Atelier Apache Spark"},{"location":"#atelier-apache-spark","text":"Ce(tte) \u0153uvre est mise \u00e0 disposition selon les termes de la Licence Creative Commons Attribution - Pas d\u2019Utilisation Commerciale - Partage dans les M\u00eames Conditions 4.0 International .","title":"Atelier Apache Spark"},{"location":"#overview","text":"L'objectif de ce cours est d'initier les apprenants aux concepts de base de Apache Spark, et de faire le tours des composants qui le constituent et des cas d'utilisation. Ce cours est renforc\u00e9 par des travaux pratiques.","title":"Overview"},{"location":"p1-big-data/","text":"Partie 1 - Introduction au Big Data Les \"Big Data\", Pourquoi? L'\u00eatre humain, \u00e0 travers l'humanit\u00e9, a toujours cherch\u00e9 trois choses : Savoir (qu'est-ce qui s'est pass\u00e9?), Comprendre (pourquoi cela s'est-il pass\u00e9?) et Pr\u00e9dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam\u00e9 l'omniscience en ayant recours \u00e0 des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal. Cela dit, ces moyens ne sont gu\u00e8res satisfaisants \u00e0 l'esprit m\u00e9ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle \u00e0 tout \u00e9v\u00e8nement, et une justification convainquante \u00e0 tout comportement. Le scientifique se base sur des faits. Il veut arriver \u00e0 faire de la magie gr\u00e2ce \u00e0 la technologie. Pour arriver \u00e0 ces fins, le scientifique a besoin de donn\u00e9es. L'int\u00e9r\u00eat de collecter des donn\u00e9es et de les exploiter a longtemps \u00e9t\u00e9 n\u00e9glig\u00e9, et a \u00e9t\u00e9 limit\u00e9 au peu de donn\u00e9es, jug\u00e9es \"utiles\", qui semblaient suffisantes pour atteindre un objectif imm\u00e9diat. Cependant, adopter le chemin \u00e9vident et peu risqu\u00e9 n'aurait jamais permis de r\u00e9aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen.. Le terme Big Data est apparu peu de temps apr\u00e8s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une \u00e8re o\u00f9 l'ajout des donn\u00e9es \u00e9tait exclusivement r\u00e9serv\u00e9 \u00e0 une \u00e9lite experte, o\u00f9 le volume des donn\u00e9es disponible \u00e9tait petit mais o\u00f9 les donn\u00e9es \u00e9taient pr\u00e9cieuses et pertinentes, vers une \u00e8re o\u00f9 tout un chacun \u00e9tait capable d'introduire des connaissances, v\u00e9ridiques ou pas, qui seraient sauvegard\u00e9es dans une m\u00e9moire collective jusqu'\u00e0 la fin des temps. Ce changement de paradigme a entrain\u00e9 le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn\u00e9es, mais \u00e9galement d'en extraire de la valeur. Ces infrastructures auront la capacit\u00e9 de g\u00e9rer toute la cha\u00eene logistique des donn\u00e9es, de la collecte vers l'affichage. Cela semble \u00e9vident, me direz-vous, car les syst\u00e8mes classiques sont capables de faire cela. Qui stocke mieux les donn\u00e9es qu'une bonne vieille base de donn\u00e9es relationnelle? Le probl\u00e8me est que les donn\u00e9es dites \"Big Data\" sont caract\u00e9ris\u00e9es par des propri\u00e9t\u00e9s telles que, les syst\u00e8mes classiques de stockage et de traitement auraient du mal \u00e0 les exploiter \u00e0 leur juste valeur. Caract\u00e9ristiques des Donn\u00e9es Massives Le terme \"donn\u00e9es massives\", ou \"Big Data\", ne donne \u00e0 mon avis pas enti\u00e8rement justice aux donn\u00e9es de notre domaine. En effet, il repr\u00e9sente une seule caract\u00e9ristique parmis plusieurs, le Volume, qui, m\u00eame si elle semble \u00eatre la plus importante, est loin d'\u00eatre la plus critique. En effet, les donn\u00e9es massives sont caract\u00e9ris\u00e9es par les fameux *V . Il en existe plusieurs (10 jusqu'\u00e0 ce jour si je ne m'abuse, certains en citent m\u00eame 42!!!), mais pourraient \u00e0 mon avis \u00eatre r\u00e9sum\u00e9s en trois caract\u00e9ristiques primordiales, autours de la combinaison desquelles tournent toutes les d\u00e9cisions prises dans ce domaine. Volume C'est \u00e9videmment le V le plus manifeste, qui caract\u00e9rise le fait que les donn\u00e9es ont un volume \u00e9norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'\u00e0 2^{80} 2^{80} octets!). Mais ceci n'est pas tout. Un volume \u00e9norme, s'il reste constant, est g\u00e9rable : il suffit de trouver une machine suffisamment puissante pour le sauvegarder. Le probl\u00e8me avec la propri\u00e9t\u00e9 du volume, c'est qu'il augmente de fa\u00e7on continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann\u00e9e, atteste que \"Over the last two years alone 90 percent of the data in the world was generated.\" Il est donc primordial de trouver un moyen de g\u00e9rer ce volume toujours croissant des donn\u00e9es. V\u00e9locit\u00e9 Cette propri\u00e9t\u00e9 est, \u00e0 mon avis, la plus probl\u00e9matique des trois, car, coupl\u00e9e avec le volume, elle rend les syst\u00e8me actuels obsol\u00e8tes. En effet, la v\u00e9locit\u00e9 est, litt\u00e9ralement, \"La vitesse avec laquelle quelque chose se d\u00e9place dans une direction particuli\u00e8re\". Dans notre cas, la v\u00e9locit\u00e9 des donn\u00e9es est la responsable directe du volume croissant des donn\u00e9es dans le syst\u00e8me. Elle est provoqu\u00e9e par une arriv\u00e9e des donn\u00e9es dans le syst\u00e8me sous la forme d'un flux constant qui demande \u00e0 \u00eatre stock\u00e9 et trait\u00e9 imm\u00e9diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr\u00e9sentation r\u00e9cente et fid\u00e8le de l'\u00e9tat des donn\u00e9es. D'ailleurs, cette propri\u00e9t\u00e9 a engendr\u00e9 une autre pr\u00e9occupation des analystes des donn\u00e9es, qui est de fournir une introspection en temps r\u00e9el sur les donn\u00e9es, les qualifiant ainsi de \" Fast Data \". Vari\u00e9t\u00e9 Ce qui distingue vraiment les donn\u00e9es massives des donn\u00e9es g\u00e9r\u00e9es classiquement dans des bases de donn\u00e9es op\u00e9rationnelles, c'est le support des donn\u00e9es semi- et non structur\u00e9es. En effet, les donn\u00e9es non structur\u00e9es sont des donn\u00e9es qu'on stocke dans un format qui n'est pas d\u00e9fini \u00e0 la cr\u00e9ation, telles que les donn\u00e9es textuelles, images ou sons. Les donn\u00e9es semi-structur\u00e9es sont des donn\u00e9es qui contiennent une structure, mais une structure qui n'est pas rigide, et dont on ne d\u00e9finit pas les contraintes \u00e0 l'insertion de la donn\u00e9e, contrairement aux donn\u00e9es structur\u00e9es (se trouvant typiquement dans des bases de donn\u00e9es relationnelles) qui, si elles ne respectent pas la structure d\u00e9finie, sont consid\u00e9r\u00e9es fausses et ne sont pas autoris\u00e9es \u00e0 \u00eatre enregistr\u00e9es. On estime que seules 15% des donn\u00e9es dans une entreprise sont des donn\u00e9es structur\u00e9es, contre 85% qui ne le sont pas! Dans une optique centr\u00e9e sur les donn\u00e9es, dont le but est de gagner le maximum de vision \u00e0 partir des donn\u00e9es, perdre autant de sources d'information est un vrai probl\u00e8me. Il est donc important que les syst\u00e8mes Big Data sachent interpr\u00e9ter ces donn\u00e9es et en extraire le maximum de valeur. Toutes les d\u00e9cisions, choix et propri\u00e9t\u00e9s prises au niveau des architectures et infrastructures Big Data sont r\u00e9gies par ces trois caract\u00e9ristiques, ce qui va compl\u00e8tement changer la vision \"relationnelle\" que tout informaticien qui se respecte a acquis tout au long de ses ann\u00e9es d'\u00e9tude et de travail. Cela dit, ce ne sont pas les seules propri\u00e9t\u00e9s. D'autres V ont vu le jour, mais sans jamais avoir autant d'impact sur l'infrastructre, plut\u00f4t dans la fa\u00e7on de d\u00e9finir les processus, la gouvernance et les approches m\u00e9tier \u00e0 adopter. Nous citons par exemple : V\u00e9racit\u00e9 : c'est la confiance que nous devons avoir en nos donn\u00e9es. Cette propri\u00e9t\u00e9 est inversement proportionnelle au volume et \u00e0 la vari\u00e9t\u00e9 : plus nos donn\u00e9es sont fiables, moins elles sont diversifi\u00e9es et volumineuses! Valeur : c'est la capacit\u00e9 d'extraire de la valeur m\u00e9tier \u00e0 partir des donn\u00e9es. Variabilit\u00e9 : une extension de la vari\u00e9t\u00e9, qui indique \u00e0 quel point nos donn\u00e9es peuvent avoir des dimensions diff\u00e9rentes \u00e0 partir des sources de donn\u00e9es disparates. Visualisation : c'est la capacit\u00e9 de nos donn\u00e9es \u00e0 \u00eatre repr\u00e9sent\u00e9es par les outils de visualisation classiques. etc. Infrastructure Big Data : Besoins Les caract\u00e9ristiques des donn\u00e9es Big Data cit\u00e9es ci-dessus, entra\u00eenent des besoins particuliers en termes d'infrastructure et d'architecture. Volume La caract\u00e9ristique de volume, qui implique que la taille des donn\u00e9es augmente de fa\u00e7on r\u00e9guli\u00e8re, fait qu'on ne peut plus se contenter d'un syst\u00e8me centralis\u00e9 classique. Car dans un syst\u00e8me centralis\u00e9 (donc bas\u00e9 sur une seule machine), augmenter les ressources de stockage au besoin implique ce que nous appelons une scalabilit\u00e9 verticale ou un scale up , qui veut dire une augmentation des capacit\u00e9s du serveur de stockage en rajoutant des processeurs, de la RAM ou des disques. Cependant, cette solution, bien qu'elle soit intuitive, rapide et ne requiert pas de changement architecturaux cons\u00e9quents, implique en g\u00e9n\u00e9ral un temps d'arr\u00eat pendant l'installation, ainsi qu'une d\u00e9pense assez cons\u00e9quente pour faire l'acquisition d'un serveur puissant. De plus, une machine unique atteindra rapidement une limite mat\u00e9rielle, car il vous est impossible d'augmenter ses ressources ind\u00e9finiment. En contrepartie, il est possible de penser que, face \u00e0 un volume de donn\u00e9es toujours en augmentation, il serait plus judicieux de rajouter des machines au besoin, cr\u00e9ant ainsi un cluster de machines interconnect\u00e9es, ou syst\u00e8me r\u00e9parti , dont la taille et la capacit\u00e9 sont virtuellement illimit\u00e9es. Nous sommes donc face \u00e0 un autre type de scalabilit\u00e9 : la scalabilit\u00e9 horizontale ou le scale out . Donc Volume => Scalabilit\u00e9 Horizontale V\u00e9locit\u00e9 La v\u00e9locit\u00e9 est une propri\u00e9t\u00e9 qui, coupl\u00e9e au volume, rend la gestion de l'infrastructure un vrai cauchemar. En effet, g\u00e9rer des donn\u00e9es en continuelle arriv\u00e9e implique qu'il y'a un risque \u00e9norme de perte de donn\u00e9es, si elles ne sont pas manipul\u00e9es \u00e0 temps. C'est pour cette raison qu'un syst\u00e8me Big Data se doit d'\u00eatre continuellement disponible : toute requ\u00eate de lecture ou d'\u00e9criture doit \u00eatre trait\u00e9e en un temps raisonnable, et le syst\u00e8me doit \u00eatre continuellement alerte pour saisir toutes les donn\u00e9es, sans risquer de les perdre. Ainsi V\u00e9locit\u00e9 => Disponibilit\u00e9 Vari\u00e9t\u00e9 La vari\u00e9t\u00e9 de donn\u00e9es implique non seulement que nous sommes en pr\u00e9sence de donn\u00e9es structur\u00e9es, semi-structur\u00e9es et non structur\u00e9es, mais \u00e9galement que ces donn\u00e9es peuvent parvenir de sources diff\u00e9rentes, avec des formats diff\u00e9rents, et que m\u00eame \u00e0 partir d'une m\u00eame source, ce format peut changer d'un moment \u00e0 un autre. Dans les syst\u00e8mes classiques, tout ce qui est variable doit passer par une couche d'homog\u00e9n\u00e9isation qui transformera chaque entr\u00e9e ou enregistrement dans la forme souhait\u00e9e, en remplissant par des valeurs NULL les donn\u00e9es manquantes. Rajouter cette couche d'homog\u00e9n\u00e9isation aura un double impact n\u00e9gatif sur notre syst\u00e8me : (1) \u00e0 cause de la v\u00e9locit\u00e9, cette op\u00e9ration risquera de ralentir la collecte et saisie des donn\u00e9es entrantes, et (2) on pourra subir une perte de donn\u00e9es suite \u00e0 ces transformations. C'est pour ces raisons qu'un syst\u00e8me Big Data se doit de supporter des types de donn\u00e9es changeants, sans pour autant requ\u00e9rir \u00e0 des subterfuges qui alourdissent ou contournent le syst\u00e8me de stockage. D'o\u00f9 Vari\u00e9t\u00e9 => Flexibilit\u00e9 Th\u00e9or\u00e8me CAP Les besoins de scalabilit\u00e9, disponibilit\u00e9 et flexibilit\u00e9, obligatoires pour avoir un syst\u00e8me Big Data en bonne et due forme, se trouvent confront\u00e9s \u00e0 une contrainte de taille... et qu'en est-il de la coh\u00e9rence (commun\u00e9ment appel\u00e9e aussi consistence, par anglicisme)? La coh\u00e9rence repr\u00e9sente en effet un must pour les syst\u00e8mes relationnels classiques, et une base sur laquelle sont prises toutes les d\u00e9cisions conceptuelles et techniques. Elle repr\u00e9sente le fait que les donn\u00e9es stables doivent respecter toutes les contraintes d'int\u00e9grit\u00e9 d\u00e9finies \u00e0 la cr\u00e9ation de la base de donn\u00e9e. Par exemple, si un champ est d\u00e9cr\u00e9t\u00e9 \"Not Null\", il doit le rester quelque soit la situation, et \u00e0 aucun moment une requ\u00eate ne doit surprendre ce champs avec une valeur nulle, m\u00eame si c'est juste une valeur interm\u00e9diaire. La coh\u00e9rence est un principe tr\u00e8s rigide dans les bases de donn\u00e9es relationnelles, et repr\u00e9sente le crit\u00e8re de base pour la gestion des transactions : le C de ACID . Cela dit, dans les syst\u00e8mes Big Data, nous nous trouvons confront\u00e9s \u00e0 un probl\u00e8me de taille : nous devons \u00eatre en pr\u00e9sence d'une infrastructure r\u00e9partie et hautement disponible. Or, il existe un th\u00e9or\u00e8me appel\u00e9 CAP pour Consistency / Availability / Partition tolerance , qui stipule que ces trois propri\u00e9t\u00e9s (notamment la coh\u00e9rence, la disponibilit\u00e9 et la tol\u00e9rance au partitionnement), ne peuvent jamais avoir lieu en m\u00eame temps. Seules deux d'entre elles peuvent \u00eatre respect\u00e9es \u00e0 la fois. Essayons d'expliquer pourquoi. Un syst\u00e8me r\u00e9parti est dit coh\u00e9rent si tous ses noeuds voient les m\u00eames donn\u00e9es en m\u00eame temps. C'est \u00e0 dire que, si nous r\u00e9alisons une op\u00e9ration de lecture sur un syst\u00e8me consistant, il devrait toujours retourner la valeur la plus r\u00e9cente qui ait \u00e9t\u00e9 \u00e9crite, quel que soit l'endroit \u00e0 partir duquel la lecture est effectu\u00e9e. Ainsi, si une donn\u00e9e est modifi\u00e9e sur un noeud particulier, pour conserver la coh\u00e9rence demand\u00e9e, aucune op\u00e9ration de lecture ne doit \u00eatre permise avant d'avoir mis \u00e0 jour toutes les r\u00e9pliques (copies) de cette donn\u00e9es. Or, les diff\u00e9rents noeuds d'un cluster sont en g\u00e9n\u00e9ral distants, parfois m\u00eame g\u00e9ographiquement, il est donc n\u00e9cessaire d'attendre que la propagation de la modification se fasse sur le r\u00e9seau, pour effectuer n'importe quelle op\u00e9ration, m\u00eame une lecture. Ceci va rendre nos donn\u00e9es indisponibles \u00e0 la lecture pendant tout le temps que durera l'op\u00e9ration de synchronisation, qui est un temps incertain puisque... r\u00e9seau. Assurer donc une coh\u00e9rence forte dans un syst\u00e8me distribu\u00e9 est en contradiction avec le besoin de disponibilit\u00e9 du syst\u00e8me et des donn\u00e9es. D'ailleurs, c'est ce que font les bases de donn\u00e9es relationnelles r\u00e9parties, qui conservent les propri\u00e9t\u00e9s ACID tout en distribuant les donn\u00e9es, mais qui souffrent d'un manque notoire de performance. Les syst\u00e8mes Big Data, subissant les contraintes des V pr\u00e9c\u00e9demment cit\u00e9s, doivent donc faire un choix. Or ce choix est loin d'\u00eatre facile : qui voudra acheter un syst\u00e8me qui pr\u00f4ne haut et fort qu'il est incoh\u00e9rent ? L'id\u00e9e serait donc de partir sur le principe de coh\u00e9rence \u00e9ventuelle ou parfois de coh\u00e9rence ajustable . Ainsi, un syst\u00e8me Big Data est un syst\u00e8me principalement disponible, fondamentalement r\u00e9parti, et qui assure une coh\u00e9rence \u00e9ventuelle au bout d'un temps g\u00e9n\u00e9ralement n\u00e9gligeable, avec la possibilit\u00e9 de configurer les niveau de coh\u00e9rence parfois m\u00eame dynamiquement. Les experts les appellent donc les syst\u00e8mes BASE (admirez le jeux de mot.. ACID, BASE \ud83d\ude0e): B asically A vailable S oft-state E ventual consistency La propri\u00e9t\u00e9 de Soft State ou d'\u00e9tat \"mou\" veut dire que l'\u00e9tat du syst\u00e8me peut changer dans le temps, m\u00eame sans qu'il y ait une nouvelle entr\u00e9e, \u00e0 cause du principe de coh\u00e9rence \u00e9ventuelle expliqu\u00e9 pr\u00e9c\u00e9demment. Maintenant que vous \u00eates plus familiaris\u00e9s avec les caract\u00e9ristiques d'un syst\u00e8me Big Data, listons quelques principes, appel\u00e9s ici MOTTOS , qui vont r\u00e9gir nos futures d\u00e9cisions dans ce domaine. Principes de base du Domaine des Big Data Il est important, avant d'entamer n'importe quel travail sur les syst\u00e8mes Big Data, de consid\u00e9rer certains principes, qui sont parfois en enti\u00e8re contradiction avec les principes classiques de d\u00e9veloppement d'application. Ce n'est pas si \u00e9tonnant : le domaine des Big Data n'est pas cens\u00e9 prendre la place des domaines relationnel et d\u00e9cisionnel, mais plut\u00f4t les enrichir et les agr\u00e9menter. MOTTO 1 : Stocker d'abord, r\u00e9fl\u00e9chir ensuite \u00c0 cause de la v\u00e9locit\u00e9, il est important de consid\u00e9rer qu'il nous sera parfois difficile, voire impossible, de nettoyer les donn\u00e9es ou de faire un traitement quelconque dessus, avant de les stocker. Cela risque dans bien des cas de nous faire perdre des donn\u00e9es, le cauchemar de tout scientifique des donn\u00e9es! Nous devons donc envisager la possibilit\u00e9 de d\u00e9finir des syst\u00e8mes de stockage qui contiennent des donn\u00e9es non nettoy\u00e9es, en vrac (appel\u00e9es raw data ), pour ensuite lancer des traitements dessus.. l'horreur pour un gestionnaire de bases des donn\u00e9es! \ud83d\ude31 Bien entendu, ces \"bases\" ne sont pas con\u00e7ues pour \u00eatre directement exploit\u00e9es par des applications externes, mais plut\u00f4t pour conserver le plus longtemps possibles les donn\u00e9es brutes, sans perte, qui pourraient eventuellement \u00eatre r\u00e9utilis\u00e9es pour d'autres fins. MOTTO 2 : Absolument TOUTES les donn\u00e9es sont importantes! D'o\u00f9 l'int\u00e9r\u00eat du MOTTO 1 . Il nous est parfois difficile, au tout d\u00e9but de la conception des syst\u00e8mes Big Data, de cerner toutes les possibilit\u00e9s offertes par ces syst\u00e8mes et par les donn\u00e9es que nous avons \u00e0 notre disposition. Nous sommes donc en g\u00e9n\u00e9ral tent\u00e9s de supprimer les donn\u00e9es dont nous n'avons pas besoin une fois extraite l'information imm\u00e9diatement utile. Cela dit, gr\u00e2ce \u00e0 l'accessibilit\u00e9 des syst\u00e8mes de stockage magn\u00e9tiques et leur prix de plus en plus bas, nous consid\u00e9rons qu'il est largement plus b\u00e9n\u00e9fique de stocker des donn\u00e9es qu'on n'utilisera peut-\u00eatre jamais, plut\u00f4t que de gagner de la place et perdre un potentiel pouvoir concurrentiel. MOTTO 3 : Ce sont les donn\u00e9es qui pilotent le traitement Dans un syst\u00e8me op\u00e9rationnel classique, ainsi que dans la plupart des syst\u00e8mes d\u00e9cisionnels, ce sont les besoins m\u00e9tier qui pr\u00e9valoient : le responsable m\u00e9tier commence par d\u00e9finir les besoins (ou les KPIs : Key Performance Indicators dans le cas d'un syst\u00e8me d\u00e9cisionnel), puis le responsable technique con\u00e7oit les structures de donn\u00e9es pour r\u00e9pondre \u00e0 ces besoins. Par essence, un syst\u00e8me Big Data fonctionne diff\u00e9remment : les donn\u00e9es sont collect\u00e9es tout d'abord \u00e0 partir de toutes les sources possibles; des traitements de fouille et d'exploration de ces donn\u00e9es sont lanc\u00e9s ensuite, pour extraire de la valeur \u00e0 partir de ces donn\u00e9es. L'objectif est toujours le m\u00eame : chercher l'effet WOW! D'o\u00f9 l'int\u00e9r\u00eat de ce MOTTO : d\u00e9finir le traitement \u00e0 r\u00e9aliser d\u00e9pend des donn\u00e9es que nous avons r\u00e9ussi \u00e0 collecter, et pas le contraire. Cela implique donc l'utilisation d'autres types de syst\u00e8mes de traitement et d'algorithmes d'analyse. MOTTO 4 : Co-localisation des donn\u00e9es et du traitement Un syst\u00e8me classique \u00e0 plusieurs couches, tel que le syst\u00e8me trois tiers par exemple, se base sur le principe de s\u00e9paration des donn\u00e9es et du traitement. On trouve en g\u00e9n\u00e9ral des donn\u00e9es sur un serveur de bases de donn\u00e9es s\u00e9par\u00e9, et les traitement complexes sur un serveur d'application qui se charge de l'aggr\u00e9gation et de l'affichage de ces donn\u00e9es. Ceci est agr\u00e9ment\u00e9 d'un langage de requ\u00eatage d\u00e9claratif (typiquement SQL) pour r\u00e9aliser des op\u00e9rations de filtrage, parfois assez lourdes et complexes, au niveau de la base de donn\u00e9es. Cela dit, dans un contexte Big Data, le volume des donn\u00e9es peut s'av\u00e9rer assez cons\u00e9quent, trop m\u00eame pour envisager de le d\u00e9placer \u00e0 chaque fois vers un autre syst\u00e8me pour en extraire une vraie valeur. De plus, compter sur un langage comme SQL pour diminuer le volume ou faire de simples agr\u00e9gations au niveau de la base de donn\u00e9es pourra la rendre indisponible pendant un moment (car n'oublions pas que nous parlons d'un syst\u00e8me r\u00e9parti), ce qui va \u00e0 l'encontre du principe de v\u00e9locit\u00e9, qui exige une disponibilit\u00e9 \u00e0 toute \u00e9preuve du syst\u00e8me de stockage. C'est pour cette raison que, pour r\u00e9aliser les traitements voulus en un temps raisonnable et sans avoir \u00e0 trimballer les donn\u00e9es sur le r\u00e9seau, il est question dans les syst\u00e8mes Big Data de d\u00e9placer le traitement vers les donn\u00e9es massives, au lieu de d\u00e9placer les donn\u00e9es vers le traitement. MOTTO 5 : La redondance, c'est bien Dans les bases de donn\u00e9es relationnelles, le plus grand ennemi \u00e0 combattre dans la conception de la structure de donn\u00e9es est la redondance, et ce pour deux raisons. La premi\u00e8re, \u00e9vidente, est le gain d'espace : notre espace de stockage est pr\u00e9cieux, et nous devons \u00e9viter de le gaspiller sans raison pr\u00e9cise. La deuxi\u00e8me est un besoin de coh\u00e9rence : si nous dupliquons une m\u00eame information \u00e0 plusieurs endroits dans la base, nous devrons par la suite faire attention, parfois par des m\u00e9canismes compliqu\u00e9s et co\u00fbteux, \u00e0 ce que cette information soit mise \u00e0 jour instantan\u00e9ment sur la totalit\u00e9 de ses copies. Ce besoin d'\u00e9viter la redondance a cr\u00e9\u00e9 la n\u00e9cessit\u00e9 d'utiliser plusieurs techniques, telles que les jointures et clefs \u00e9trang\u00e8res, et entra\u00eene parfois la cr\u00e9ation d'un tr\u00e8s grand nombre de tables. Ceci rajoute une complexit\u00e9 pour le requ\u00eatage, et une lourdeur d'ex\u00e9cution des t\u00e2ches sur la base. Un syst\u00e8me Big Data qui, non seulement est caract\u00e9ris\u00e9 par un gros volume de donn\u00e9es, mais \u00e9galement une grande v\u00e9locit\u00e9, et qui doit donc \u00eatre imm\u00e9diatement disponible, ne peut pas se permettre de gaspiller ses ressources en requ\u00eates inutiles. On tol\u00e8re donc \u00e0 un certain point les risques dus \u00e0 la redondance, pour gagner en disponibilit\u00e9, primordiale dans ce type de syst\u00e8mes. D'autre part, un syst\u00e8me Big Data est un syst\u00e8me r\u00e9parti par excellence, et dans un syst\u00e8me r\u00e9parti, il est primordial d'assurer une bonne tol\u00e9rance aux fautes en cr\u00e9ant des r\u00e9pliques des donn\u00e9es, diss\u00e9min\u00e9es partout sur le cluster. Ces r\u00e9pliques assurent qu'aucune machine n'est compl\u00e8tement indispensable, et diminue le risque d'indisponibilit\u00e9 des donn\u00e9es. Un autre signe de redondance. MOTTO 6 : Vive le Polyglottisme! \u00catre polyglotte, c'est \u00eatre capable de parler plusieurs langues. Et les syst\u00e8mes Big Data encouragent le polyglottisme. En effet, ce sont des syst\u00e8mes complexes qui impliquent en g\u00e9n\u00e9ral plusieurs traitements et plusieurs types de donn\u00e9es diff\u00e9rentes (donn\u00e9es brutes, donn\u00e9es nettoy\u00e9es, donn\u00e9es trait\u00e9es), ce qui fait qu'il existe deux principes importants \u00e0 encourager : Polyglot Programming : Une application peut comporter plusieurs langages et paradigmes de programmation, chacun assurant un besoin particulier, de fa\u00e7on \u00e0 profiter des avantages de chacun \u00e0 sa juste valeur. Polyglot Persistence : Dans une m\u00eame application, il est possible d'utiliser plusieurs syst\u00e8mes de stockage diff\u00e9rents (relationnels, NOSQL, syst\u00e8mes de fichiers, etc.). Gr\u00e2ce \u00e0 ces deux principes, on pourra cr\u00e9er des applications complexes mais compl\u00e8tes, qui permettent d'assurer tous les besoins en terme de stockage et de traitement. Technologies et Paradigmes Les op\u00e9rations \u00e0 r\u00e9aliser sur les syst\u00e8mes Big Data consistent principalement en : Ingestion des donn\u00e9es : repr\u00e9sente les phases de collecte et d'importation des donn\u00e9es pour \u00eatre stock\u00e9es ou trait\u00e9es \u00e0 la vol\u00e9e. Cela peut se faire en \"temps r\u00e9el\", c'est \u00e0 dire que les donn\u00e9es sont import\u00e9es au moment o\u00f9 elles sont \u00e9mises par leur source, ou bien \"par lots\", ce qui veut dire que les donn\u00e9es sont import\u00e9es par portions \u00e0 intervalles r\u00e9gulier. Exemples de technologies Apache Kafka , Amazon Kinesis , Apache Flume , Sqoop , etc. Stockage des donn\u00e9es : Les syst\u00e8mes de stockage de donn\u00e9es respectant les propri\u00e9t\u00e9s le Big Data se distinguent principalement en syst\u00e8mes de fichiers distribu\u00e9s, tel que Hadoop HDFS ou Google GFS , ou bases de donn\u00e9es NOSQL, tel que MongoDB , Cassandra , Redis ou Neo4J . Traitement des donn\u00e9es : Plusieurs types de traitement de donn\u00e9es sont possibles, nous citons : Traitement par lot (Batch Processing) : c'est le traitement des donn\u00e9es au repos (data at rest) qui se fait sur l'ensemble des donn\u00e9es stock\u00e9es, sans avoir besoin d'une interaction avec l'utilisateur. Le traitement par lot est adapt\u00e9 principalement aux op\u00e9rations ayant lieu \u00e0 la fin d'un cycle, permettant d'avoir une vision globale sur la totalit\u00e9 des donn\u00e9es, par exemple pour avoir un rapport global ou une analyse mensuelle. Les op\u00e9rations de traitement par lots sont en g\u00e9n\u00e9ral lanc\u00e9es \u00e0 des p\u00e9riodes r\u00e9guli\u00e8res, car elles sont connues pour avoir une grande latence (temps total de traitement). Exemples de technologies Hadoop Map Reduce et Spark Batch . Traitement en Streaming (Stream Processing) : c'est le traitement des donn\u00e9es en transit (data in motion) , ou en d'autres termes, le traitement des donn\u00e9es pendant qu'elles sont produites ou re\u00e7ues. Les donn\u00e9es \u00e9tant en g\u00e9n\u00e9ral cr\u00e9\u00e9es en tant que flux continu (\u00e9v\u00e8nements de capteurs, activit\u00e9 des utilisateurs sur un site web, flux vid\u00e9o, etc.), elles sont captur\u00e9es comme une s\u00e9rie d'\u00e9v\u00e8nements continus dans le temps. Avant la cr\u00e9ation des traitements en streaming, ces donn\u00e9es \u00e9taient stock\u00e9es dans une base de donn\u00e9es, un syst\u00e8me de fichier ou tout autre forme de stockage en masse. Les applications appelleront ensuite les donn\u00e9es au besoin. Gr\u00e2ce \u00e0 ce nouveau paradigme, les donn\u00e9es peuvent maintenant \u00eatre trait\u00e9es \u00e0 la vol\u00e9e, ce qui permet \u00e0 la couche applicative d'\u00eatre toujours sur \u00e9coute et \u00e0 jour. Exemples de technologies Apache Flink et Apache Storm . Traitement par Micro-Lot (Micro-Batch Processing) : c'est la pratique de collecter les donn\u00e9es en petits groupes (appel\u00e9s des micro-lots ou des micro-batchs ) pour les traiter. Contrairement au traditionnel traitement par lot, cette variante fait en sorte que le traitement des donn\u00e9es soit plus fr\u00e9quent, et que les r\u00e9sultats soient produits avec une latence beaucoup plus petite. Les donn\u00e9es sont collect\u00e9es par intervalles selon un seuil pr\u00e9d\u00e9fini, limit\u00e9 par un temps (par exemple toutes les secondes), ou par un nombre (tous les 20 \u00e9l\u00e9ments). Ce traitement est en g\u00e9n\u00e9ral une alternative au traitement en streaming, o\u00f9 les donn\u00e9es sont trait\u00e9es \u00e0 la vol\u00e9e, mais risquent d'\u00eatre perdues si le temps de traitement est sup\u00e9rieur \u00e0 la fr\u00e9quence de g\u00e9n\u00e9ration des donn\u00e9es. Le micro-batching permet, par contraste, de sauvegarder les donn\u00e9es dans un buffer, ralentissant ainsi le flux g\u00e9n\u00e9r\u00e9. D'autre part, les donn\u00e9es \u00e9tant trait\u00e9es par micro-lots, il est possible d'avoir une visibilit\u00e9 sur ce petit lot de donn\u00e9es, contrairement au traitement en streaming qui n'a de visibilit\u00e9 que sur la derni\u00e8re donn\u00e9e g\u00e9n\u00e9r\u00e9e, \u00e0 moins de proc\u00e9der \u00e0 des m\u00e9canismes parfois co\u00fbteux. En contrepartie, le traitement en micro-batch donne des r\u00e9sultats moins r\u00e9cents que le \"vrai\" streaming, et s'ex\u00e9cute sous forme de bursts r\u00e9guliers, qui peuvent parfois \u00eatre g\u00eanants pour le syst\u00e8me sous-jacent. Exemples de technologies Spark Streaming et Logstash . Traitement Interactif (Interactive Processing) : Dans les syst\u00e8mes Big Data, la notion de transaction n'est plus exactement la m\u00eame que pour les syst\u00e8mes classiques: finies les sacro-saintes propri\u00e9t\u00e9s ACID dont le premier objectif est d'avoir des donn\u00e9es correctes et coh\u00e9rentes, et bonjour les propri\u00e9t\u00e9s BASE, qui favorisent un acc\u00e8s moins rigide aux donn\u00e9es. On parle donc rarement de traitement transactionnel en Big Data, mais de traitements plut\u00f4t interactifs : une requ\u00eate est envoy\u00e9e par le client, trait\u00e9e imm\u00e9diatement par le syst\u00e8me qui renverra un r\u00e9sultat dans un temps raisonnable. On parle alors d' interaction entre l'utilisateur et le syst\u00e8me. Les traitements en batch et en streaming ne sont pas cens\u00e9s communiquer avec un utilisateur de l'autre c\u00f4t\u00e9. En g\u00e9n\u00e9ral, les r\u00e9sultats de ces traitements sont enregistr\u00e9s dans un syst\u00e8me de stockage, qui sera, lui, par la suite interrog\u00e9 par l'utilisateur. Le traitement interactif est donc le r\u00e9sultat d'une requ\u00eate de l'utilisateur, faite en g\u00e9n\u00e9ral sur une base de donn\u00e9es (relationnelle ou NOSQL). Exemples de technologies Apache Drill , Cloudera Impala ou Apache Zeppelin .","title":"Partie 1 - Introduction au Big Data"},{"location":"p1-big-data/#partie-1-introduction-au-big-data","text":"","title":"Partie 1 - Introduction au Big Data"},{"location":"p1-big-data/#les-big-data-pourquoi","text":"L'\u00eatre humain, \u00e0 travers l'humanit\u00e9, a toujours cherch\u00e9 trois choses : Savoir (qu'est-ce qui s'est pass\u00e9?), Comprendre (pourquoi cela s'est-il pass\u00e9?) et Pr\u00e9dire (qu'est-ce que qui se passera?). Plusieurs cultures ont clam\u00e9 l'omniscience en ayant recours \u00e0 des subterfuges, tels que les oracles, l'astrologie, le tarot, ou les boules de cristal. Cela dit, ces moyens ne sont gu\u00e8res satisfaisants \u00e0 l'esprit m\u00e9ticuleux du scientifique, qui cherche toujours une explication logique et rationnelle \u00e0 tout \u00e9v\u00e8nement, et une justification convainquante \u00e0 tout comportement. Le scientifique se base sur des faits. Il veut arriver \u00e0 faire de la magie gr\u00e2ce \u00e0 la technologie. Pour arriver \u00e0 ces fins, le scientifique a besoin de donn\u00e9es. L'int\u00e9r\u00eat de collecter des donn\u00e9es et de les exploiter a longtemps \u00e9t\u00e9 n\u00e9glig\u00e9, et a \u00e9t\u00e9 limit\u00e9 au peu de donn\u00e9es, jug\u00e9es \"utiles\", qui semblaient suffisantes pour atteindre un objectif imm\u00e9diat. Cependant, adopter le chemin \u00e9vident et peu risqu\u00e9 n'aurait jamais permis de r\u00e9aliser les miracles auxquelles on s'attendait. Il fallait trouver un autre moyen.. Le terme Big Data est apparu peu de temps apr\u00e8s l'apparition du terme Web 2.0, qui montre la transition de l'internet d'une \u00e8re o\u00f9 l'ajout des donn\u00e9es \u00e9tait exclusivement r\u00e9serv\u00e9 \u00e0 une \u00e9lite experte, o\u00f9 le volume des donn\u00e9es disponible \u00e9tait petit mais o\u00f9 les donn\u00e9es \u00e9taient pr\u00e9cieuses et pertinentes, vers une \u00e8re o\u00f9 tout un chacun \u00e9tait capable d'introduire des connaissances, v\u00e9ridiques ou pas, qui seraient sauvegard\u00e9es dans une m\u00e9moire collective jusqu'\u00e0 la fin des temps. Ce changement de paradigme a entrain\u00e9 le besoin d'infrastructures nouvelles, qui seraient capables, non seulement de stocker ces donn\u00e9es, mais \u00e9galement d'en extraire de la valeur. Ces infrastructures auront la capacit\u00e9 de g\u00e9rer toute la cha\u00eene logistique des donn\u00e9es, de la collecte vers l'affichage. Cela semble \u00e9vident, me direz-vous, car les syst\u00e8mes classiques sont capables de faire cela. Qui stocke mieux les donn\u00e9es qu'une bonne vieille base de donn\u00e9es relationnelle? Le probl\u00e8me est que les donn\u00e9es dites \"Big Data\" sont caract\u00e9ris\u00e9es par des propri\u00e9t\u00e9s telles que, les syst\u00e8mes classiques de stockage et de traitement auraient du mal \u00e0 les exploiter \u00e0 leur juste valeur.","title":"Les \"Big Data\", Pourquoi?"},{"location":"p1-big-data/#caracteristiques-des-donnees-massives","text":"Le terme \"donn\u00e9es massives\", ou \"Big Data\", ne donne \u00e0 mon avis pas enti\u00e8rement justice aux donn\u00e9es de notre domaine. En effet, il repr\u00e9sente une seule caract\u00e9ristique parmis plusieurs, le Volume, qui, m\u00eame si elle semble \u00eatre la plus importante, est loin d'\u00eatre la plus critique. En effet, les donn\u00e9es massives sont caract\u00e9ris\u00e9es par les fameux *V . Il en existe plusieurs (10 jusqu'\u00e0 ce jour si je ne m'abuse, certains en citent m\u00eame 42!!!), mais pourraient \u00e0 mon avis \u00eatre r\u00e9sum\u00e9s en trois caract\u00e9ristiques primordiales, autours de la combinaison desquelles tournent toutes les d\u00e9cisions prises dans ce domaine. Volume C'est \u00e9videmment le V le plus manifeste, qui caract\u00e9rise le fait que les donn\u00e9es ont un volume \u00e9norme qui peut atteindre des valeurs de l'ordre de Exa-, Zetta- ou Yottaoctet (allant jusqu'\u00e0 2^{80} 2^{80} octets!). Mais ceci n'est pas tout. Un volume \u00e9norme, s'il reste constant, est g\u00e9rable : il suffit de trouver une machine suffisamment puissante pour le sauvegarder. Le probl\u00e8me avec la propri\u00e9t\u00e9 du volume, c'est qu'il augmente de fa\u00e7on continue, ce qui rend sa gestion beaucoup plus ardue. Une citation bien connue, et qui se re-confirme chaque ann\u00e9e, atteste que \"Over the last two years alone 90 percent of the data in the world was generated.\" Il est donc primordial de trouver un moyen de g\u00e9rer ce volume toujours croissant des donn\u00e9es. V\u00e9locit\u00e9 Cette propri\u00e9t\u00e9 est, \u00e0 mon avis, la plus probl\u00e9matique des trois, car, coupl\u00e9e avec le volume, elle rend les syst\u00e8me actuels obsol\u00e8tes. En effet, la v\u00e9locit\u00e9 est, litt\u00e9ralement, \"La vitesse avec laquelle quelque chose se d\u00e9place dans une direction particuli\u00e8re\". Dans notre cas, la v\u00e9locit\u00e9 des donn\u00e9es est la responsable directe du volume croissant des donn\u00e9es dans le syst\u00e8me. Elle est provoqu\u00e9e par une arriv\u00e9e des donn\u00e9es dans le syst\u00e8me sous la forme d'un flux constant qui demande \u00e0 \u00eatre stock\u00e9 et trait\u00e9 imm\u00e9diatement, ainsi que le besoin croissant des utilisateurs d'avoir une repr\u00e9sentation r\u00e9cente et fid\u00e8le de l'\u00e9tat des donn\u00e9es. D'ailleurs, cette propri\u00e9t\u00e9 a engendr\u00e9 une autre pr\u00e9occupation des analystes des donn\u00e9es, qui est de fournir une introspection en temps r\u00e9el sur les donn\u00e9es, les qualifiant ainsi de \" Fast Data \". Vari\u00e9t\u00e9 Ce qui distingue vraiment les donn\u00e9es massives des donn\u00e9es g\u00e9r\u00e9es classiquement dans des bases de donn\u00e9es op\u00e9rationnelles, c'est le support des donn\u00e9es semi- et non structur\u00e9es. En effet, les donn\u00e9es non structur\u00e9es sont des donn\u00e9es qu'on stocke dans un format qui n'est pas d\u00e9fini \u00e0 la cr\u00e9ation, telles que les donn\u00e9es textuelles, images ou sons. Les donn\u00e9es semi-structur\u00e9es sont des donn\u00e9es qui contiennent une structure, mais une structure qui n'est pas rigide, et dont on ne d\u00e9finit pas les contraintes \u00e0 l'insertion de la donn\u00e9e, contrairement aux donn\u00e9es structur\u00e9es (se trouvant typiquement dans des bases de donn\u00e9es relationnelles) qui, si elles ne respectent pas la structure d\u00e9finie, sont consid\u00e9r\u00e9es fausses et ne sont pas autoris\u00e9es \u00e0 \u00eatre enregistr\u00e9es. On estime que seules 15% des donn\u00e9es dans une entreprise sont des donn\u00e9es structur\u00e9es, contre 85% qui ne le sont pas! Dans une optique centr\u00e9e sur les donn\u00e9es, dont le but est de gagner le maximum de vision \u00e0 partir des donn\u00e9es, perdre autant de sources d'information est un vrai probl\u00e8me. Il est donc important que les syst\u00e8mes Big Data sachent interpr\u00e9ter ces donn\u00e9es et en extraire le maximum de valeur. Toutes les d\u00e9cisions, choix et propri\u00e9t\u00e9s prises au niveau des architectures et infrastructures Big Data sont r\u00e9gies par ces trois caract\u00e9ristiques, ce qui va compl\u00e8tement changer la vision \"relationnelle\" que tout informaticien qui se respecte a acquis tout au long de ses ann\u00e9es d'\u00e9tude et de travail. Cela dit, ce ne sont pas les seules propri\u00e9t\u00e9s. D'autres V ont vu le jour, mais sans jamais avoir autant d'impact sur l'infrastructre, plut\u00f4t dans la fa\u00e7on de d\u00e9finir les processus, la gouvernance et les approches m\u00e9tier \u00e0 adopter. Nous citons par exemple : V\u00e9racit\u00e9 : c'est la confiance que nous devons avoir en nos donn\u00e9es. Cette propri\u00e9t\u00e9 est inversement proportionnelle au volume et \u00e0 la vari\u00e9t\u00e9 : plus nos donn\u00e9es sont fiables, moins elles sont diversifi\u00e9es et volumineuses! Valeur : c'est la capacit\u00e9 d'extraire de la valeur m\u00e9tier \u00e0 partir des donn\u00e9es. Variabilit\u00e9 : une extension de la vari\u00e9t\u00e9, qui indique \u00e0 quel point nos donn\u00e9es peuvent avoir des dimensions diff\u00e9rentes \u00e0 partir des sources de donn\u00e9es disparates. Visualisation : c'est la capacit\u00e9 de nos donn\u00e9es \u00e0 \u00eatre repr\u00e9sent\u00e9es par les outils de visualisation classiques. etc.","title":"Caract\u00e9ristiques des Donn\u00e9es Massives"},{"location":"p1-big-data/#infrastructure-big-data-besoins","text":"Les caract\u00e9ristiques des donn\u00e9es Big Data cit\u00e9es ci-dessus, entra\u00eenent des besoins particuliers en termes d'infrastructure et d'architecture. Volume La caract\u00e9ristique de volume, qui implique que la taille des donn\u00e9es augmente de fa\u00e7on r\u00e9guli\u00e8re, fait qu'on ne peut plus se contenter d'un syst\u00e8me centralis\u00e9 classique. Car dans un syst\u00e8me centralis\u00e9 (donc bas\u00e9 sur une seule machine), augmenter les ressources de stockage au besoin implique ce que nous appelons une scalabilit\u00e9 verticale ou un scale up , qui veut dire une augmentation des capacit\u00e9s du serveur de stockage en rajoutant des processeurs, de la RAM ou des disques. Cependant, cette solution, bien qu'elle soit intuitive, rapide et ne requiert pas de changement architecturaux cons\u00e9quents, implique en g\u00e9n\u00e9ral un temps d'arr\u00eat pendant l'installation, ainsi qu'une d\u00e9pense assez cons\u00e9quente pour faire l'acquisition d'un serveur puissant. De plus, une machine unique atteindra rapidement une limite mat\u00e9rielle, car il vous est impossible d'augmenter ses ressources ind\u00e9finiment. En contrepartie, il est possible de penser que, face \u00e0 un volume de donn\u00e9es toujours en augmentation, il serait plus judicieux de rajouter des machines au besoin, cr\u00e9ant ainsi un cluster de machines interconnect\u00e9es, ou syst\u00e8me r\u00e9parti , dont la taille et la capacit\u00e9 sont virtuellement illimit\u00e9es. Nous sommes donc face \u00e0 un autre type de scalabilit\u00e9 : la scalabilit\u00e9 horizontale ou le scale out . Donc Volume => Scalabilit\u00e9 Horizontale V\u00e9locit\u00e9 La v\u00e9locit\u00e9 est une propri\u00e9t\u00e9 qui, coupl\u00e9e au volume, rend la gestion de l'infrastructure un vrai cauchemar. En effet, g\u00e9rer des donn\u00e9es en continuelle arriv\u00e9e implique qu'il y'a un risque \u00e9norme de perte de donn\u00e9es, si elles ne sont pas manipul\u00e9es \u00e0 temps. C'est pour cette raison qu'un syst\u00e8me Big Data se doit d'\u00eatre continuellement disponible : toute requ\u00eate de lecture ou d'\u00e9criture doit \u00eatre trait\u00e9e en un temps raisonnable, et le syst\u00e8me doit \u00eatre continuellement alerte pour saisir toutes les donn\u00e9es, sans risquer de les perdre. Ainsi V\u00e9locit\u00e9 => Disponibilit\u00e9 Vari\u00e9t\u00e9 La vari\u00e9t\u00e9 de donn\u00e9es implique non seulement que nous sommes en pr\u00e9sence de donn\u00e9es structur\u00e9es, semi-structur\u00e9es et non structur\u00e9es, mais \u00e9galement que ces donn\u00e9es peuvent parvenir de sources diff\u00e9rentes, avec des formats diff\u00e9rents, et que m\u00eame \u00e0 partir d'une m\u00eame source, ce format peut changer d'un moment \u00e0 un autre. Dans les syst\u00e8mes classiques, tout ce qui est variable doit passer par une couche d'homog\u00e9n\u00e9isation qui transformera chaque entr\u00e9e ou enregistrement dans la forme souhait\u00e9e, en remplissant par des valeurs NULL les donn\u00e9es manquantes. Rajouter cette couche d'homog\u00e9n\u00e9isation aura un double impact n\u00e9gatif sur notre syst\u00e8me : (1) \u00e0 cause de la v\u00e9locit\u00e9, cette op\u00e9ration risquera de ralentir la collecte et saisie des donn\u00e9es entrantes, et (2) on pourra subir une perte de donn\u00e9es suite \u00e0 ces transformations. C'est pour ces raisons qu'un syst\u00e8me Big Data se doit de supporter des types de donn\u00e9es changeants, sans pour autant requ\u00e9rir \u00e0 des subterfuges qui alourdissent ou contournent le syst\u00e8me de stockage. D'o\u00f9 Vari\u00e9t\u00e9 => Flexibilit\u00e9","title":"Infrastructure Big Data : Besoins"},{"location":"p1-big-data/#theoreme-cap","text":"Les besoins de scalabilit\u00e9, disponibilit\u00e9 et flexibilit\u00e9, obligatoires pour avoir un syst\u00e8me Big Data en bonne et due forme, se trouvent confront\u00e9s \u00e0 une contrainte de taille... et qu'en est-il de la coh\u00e9rence (commun\u00e9ment appel\u00e9e aussi consistence, par anglicisme)? La coh\u00e9rence repr\u00e9sente en effet un must pour les syst\u00e8mes relationnels classiques, et une base sur laquelle sont prises toutes les d\u00e9cisions conceptuelles et techniques. Elle repr\u00e9sente le fait que les donn\u00e9es stables doivent respecter toutes les contraintes d'int\u00e9grit\u00e9 d\u00e9finies \u00e0 la cr\u00e9ation de la base de donn\u00e9e. Par exemple, si un champ est d\u00e9cr\u00e9t\u00e9 \"Not Null\", il doit le rester quelque soit la situation, et \u00e0 aucun moment une requ\u00eate ne doit surprendre ce champs avec une valeur nulle, m\u00eame si c'est juste une valeur interm\u00e9diaire. La coh\u00e9rence est un principe tr\u00e8s rigide dans les bases de donn\u00e9es relationnelles, et repr\u00e9sente le crit\u00e8re de base pour la gestion des transactions : le C de ACID . Cela dit, dans les syst\u00e8mes Big Data, nous nous trouvons confront\u00e9s \u00e0 un probl\u00e8me de taille : nous devons \u00eatre en pr\u00e9sence d'une infrastructure r\u00e9partie et hautement disponible. Or, il existe un th\u00e9or\u00e8me appel\u00e9 CAP pour Consistency / Availability / Partition tolerance , qui stipule que ces trois propri\u00e9t\u00e9s (notamment la coh\u00e9rence, la disponibilit\u00e9 et la tol\u00e9rance au partitionnement), ne peuvent jamais avoir lieu en m\u00eame temps. Seules deux d'entre elles peuvent \u00eatre respect\u00e9es \u00e0 la fois. Essayons d'expliquer pourquoi. Un syst\u00e8me r\u00e9parti est dit coh\u00e9rent si tous ses noeuds voient les m\u00eames donn\u00e9es en m\u00eame temps. C'est \u00e0 dire que, si nous r\u00e9alisons une op\u00e9ration de lecture sur un syst\u00e8me consistant, il devrait toujours retourner la valeur la plus r\u00e9cente qui ait \u00e9t\u00e9 \u00e9crite, quel que soit l'endroit \u00e0 partir duquel la lecture est effectu\u00e9e. Ainsi, si une donn\u00e9e est modifi\u00e9e sur un noeud particulier, pour conserver la coh\u00e9rence demand\u00e9e, aucune op\u00e9ration de lecture ne doit \u00eatre permise avant d'avoir mis \u00e0 jour toutes les r\u00e9pliques (copies) de cette donn\u00e9es. Or, les diff\u00e9rents noeuds d'un cluster sont en g\u00e9n\u00e9ral distants, parfois m\u00eame g\u00e9ographiquement, il est donc n\u00e9cessaire d'attendre que la propagation de la modification se fasse sur le r\u00e9seau, pour effectuer n'importe quelle op\u00e9ration, m\u00eame une lecture. Ceci va rendre nos donn\u00e9es indisponibles \u00e0 la lecture pendant tout le temps que durera l'op\u00e9ration de synchronisation, qui est un temps incertain puisque... r\u00e9seau. Assurer donc une coh\u00e9rence forte dans un syst\u00e8me distribu\u00e9 est en contradiction avec le besoin de disponibilit\u00e9 du syst\u00e8me et des donn\u00e9es. D'ailleurs, c'est ce que font les bases de donn\u00e9es relationnelles r\u00e9parties, qui conservent les propri\u00e9t\u00e9s ACID tout en distribuant les donn\u00e9es, mais qui souffrent d'un manque notoire de performance. Les syst\u00e8mes Big Data, subissant les contraintes des V pr\u00e9c\u00e9demment cit\u00e9s, doivent donc faire un choix. Or ce choix est loin d'\u00eatre facile : qui voudra acheter un syst\u00e8me qui pr\u00f4ne haut et fort qu'il est incoh\u00e9rent ? L'id\u00e9e serait donc de partir sur le principe de coh\u00e9rence \u00e9ventuelle ou parfois de coh\u00e9rence ajustable . Ainsi, un syst\u00e8me Big Data est un syst\u00e8me principalement disponible, fondamentalement r\u00e9parti, et qui assure une coh\u00e9rence \u00e9ventuelle au bout d'un temps g\u00e9n\u00e9ralement n\u00e9gligeable, avec la possibilit\u00e9 de configurer les niveau de coh\u00e9rence parfois m\u00eame dynamiquement. Les experts les appellent donc les syst\u00e8mes BASE (admirez le jeux de mot.. ACID, BASE \ud83d\ude0e): B asically A vailable S oft-state E ventual consistency La propri\u00e9t\u00e9 de Soft State ou d'\u00e9tat \"mou\" veut dire que l'\u00e9tat du syst\u00e8me peut changer dans le temps, m\u00eame sans qu'il y ait une nouvelle entr\u00e9e, \u00e0 cause du principe de coh\u00e9rence \u00e9ventuelle expliqu\u00e9 pr\u00e9c\u00e9demment. Maintenant que vous \u00eates plus familiaris\u00e9s avec les caract\u00e9ristiques d'un syst\u00e8me Big Data, listons quelques principes, appel\u00e9s ici MOTTOS , qui vont r\u00e9gir nos futures d\u00e9cisions dans ce domaine.","title":"Th\u00e9or\u00e8me CAP"},{"location":"p1-big-data/#principes-de-base-du-domaine-des-big-data","text":"Il est important, avant d'entamer n'importe quel travail sur les syst\u00e8mes Big Data, de consid\u00e9rer certains principes, qui sont parfois en enti\u00e8re contradiction avec les principes classiques de d\u00e9veloppement d'application. Ce n'est pas si \u00e9tonnant : le domaine des Big Data n'est pas cens\u00e9 prendre la place des domaines relationnel et d\u00e9cisionnel, mais plut\u00f4t les enrichir et les agr\u00e9menter. MOTTO 1 : Stocker d'abord, r\u00e9fl\u00e9chir ensuite \u00c0 cause de la v\u00e9locit\u00e9, il est important de consid\u00e9rer qu'il nous sera parfois difficile, voire impossible, de nettoyer les donn\u00e9es ou de faire un traitement quelconque dessus, avant de les stocker. Cela risque dans bien des cas de nous faire perdre des donn\u00e9es, le cauchemar de tout scientifique des donn\u00e9es! Nous devons donc envisager la possibilit\u00e9 de d\u00e9finir des syst\u00e8mes de stockage qui contiennent des donn\u00e9es non nettoy\u00e9es, en vrac (appel\u00e9es raw data ), pour ensuite lancer des traitements dessus.. l'horreur pour un gestionnaire de bases des donn\u00e9es! \ud83d\ude31 Bien entendu, ces \"bases\" ne sont pas con\u00e7ues pour \u00eatre directement exploit\u00e9es par des applications externes, mais plut\u00f4t pour conserver le plus longtemps possibles les donn\u00e9es brutes, sans perte, qui pourraient eventuellement \u00eatre r\u00e9utilis\u00e9es pour d'autres fins. MOTTO 2 : Absolument TOUTES les donn\u00e9es sont importantes! D'o\u00f9 l'int\u00e9r\u00eat du MOTTO 1 . Il nous est parfois difficile, au tout d\u00e9but de la conception des syst\u00e8mes Big Data, de cerner toutes les possibilit\u00e9s offertes par ces syst\u00e8mes et par les donn\u00e9es que nous avons \u00e0 notre disposition. Nous sommes donc en g\u00e9n\u00e9ral tent\u00e9s de supprimer les donn\u00e9es dont nous n'avons pas besoin une fois extraite l'information imm\u00e9diatement utile. Cela dit, gr\u00e2ce \u00e0 l'accessibilit\u00e9 des syst\u00e8mes de stockage magn\u00e9tiques et leur prix de plus en plus bas, nous consid\u00e9rons qu'il est largement plus b\u00e9n\u00e9fique de stocker des donn\u00e9es qu'on n'utilisera peut-\u00eatre jamais, plut\u00f4t que de gagner de la place et perdre un potentiel pouvoir concurrentiel. MOTTO 3 : Ce sont les donn\u00e9es qui pilotent le traitement Dans un syst\u00e8me op\u00e9rationnel classique, ainsi que dans la plupart des syst\u00e8mes d\u00e9cisionnels, ce sont les besoins m\u00e9tier qui pr\u00e9valoient : le responsable m\u00e9tier commence par d\u00e9finir les besoins (ou les KPIs : Key Performance Indicators dans le cas d'un syst\u00e8me d\u00e9cisionnel), puis le responsable technique con\u00e7oit les structures de donn\u00e9es pour r\u00e9pondre \u00e0 ces besoins. Par essence, un syst\u00e8me Big Data fonctionne diff\u00e9remment : les donn\u00e9es sont collect\u00e9es tout d'abord \u00e0 partir de toutes les sources possibles; des traitements de fouille et d'exploration de ces donn\u00e9es sont lanc\u00e9s ensuite, pour extraire de la valeur \u00e0 partir de ces donn\u00e9es. L'objectif est toujours le m\u00eame : chercher l'effet WOW! D'o\u00f9 l'int\u00e9r\u00eat de ce MOTTO : d\u00e9finir le traitement \u00e0 r\u00e9aliser d\u00e9pend des donn\u00e9es que nous avons r\u00e9ussi \u00e0 collecter, et pas le contraire. Cela implique donc l'utilisation d'autres types de syst\u00e8mes de traitement et d'algorithmes d'analyse. MOTTO 4 : Co-localisation des donn\u00e9es et du traitement Un syst\u00e8me classique \u00e0 plusieurs couches, tel que le syst\u00e8me trois tiers par exemple, se base sur le principe de s\u00e9paration des donn\u00e9es et du traitement. On trouve en g\u00e9n\u00e9ral des donn\u00e9es sur un serveur de bases de donn\u00e9es s\u00e9par\u00e9, et les traitement complexes sur un serveur d'application qui se charge de l'aggr\u00e9gation et de l'affichage de ces donn\u00e9es. Ceci est agr\u00e9ment\u00e9 d'un langage de requ\u00eatage d\u00e9claratif (typiquement SQL) pour r\u00e9aliser des op\u00e9rations de filtrage, parfois assez lourdes et complexes, au niveau de la base de donn\u00e9es. Cela dit, dans un contexte Big Data, le volume des donn\u00e9es peut s'av\u00e9rer assez cons\u00e9quent, trop m\u00eame pour envisager de le d\u00e9placer \u00e0 chaque fois vers un autre syst\u00e8me pour en extraire une vraie valeur. De plus, compter sur un langage comme SQL pour diminuer le volume ou faire de simples agr\u00e9gations au niveau de la base de donn\u00e9es pourra la rendre indisponible pendant un moment (car n'oublions pas que nous parlons d'un syst\u00e8me r\u00e9parti), ce qui va \u00e0 l'encontre du principe de v\u00e9locit\u00e9, qui exige une disponibilit\u00e9 \u00e0 toute \u00e9preuve du syst\u00e8me de stockage. C'est pour cette raison que, pour r\u00e9aliser les traitements voulus en un temps raisonnable et sans avoir \u00e0 trimballer les donn\u00e9es sur le r\u00e9seau, il est question dans les syst\u00e8mes Big Data de d\u00e9placer le traitement vers les donn\u00e9es massives, au lieu de d\u00e9placer les donn\u00e9es vers le traitement. MOTTO 5 : La redondance, c'est bien Dans les bases de donn\u00e9es relationnelles, le plus grand ennemi \u00e0 combattre dans la conception de la structure de donn\u00e9es est la redondance, et ce pour deux raisons. La premi\u00e8re, \u00e9vidente, est le gain d'espace : notre espace de stockage est pr\u00e9cieux, et nous devons \u00e9viter de le gaspiller sans raison pr\u00e9cise. La deuxi\u00e8me est un besoin de coh\u00e9rence : si nous dupliquons une m\u00eame information \u00e0 plusieurs endroits dans la base, nous devrons par la suite faire attention, parfois par des m\u00e9canismes compliqu\u00e9s et co\u00fbteux, \u00e0 ce que cette information soit mise \u00e0 jour instantan\u00e9ment sur la totalit\u00e9 de ses copies. Ce besoin d'\u00e9viter la redondance a cr\u00e9\u00e9 la n\u00e9cessit\u00e9 d'utiliser plusieurs techniques, telles que les jointures et clefs \u00e9trang\u00e8res, et entra\u00eene parfois la cr\u00e9ation d'un tr\u00e8s grand nombre de tables. Ceci rajoute une complexit\u00e9 pour le requ\u00eatage, et une lourdeur d'ex\u00e9cution des t\u00e2ches sur la base. Un syst\u00e8me Big Data qui, non seulement est caract\u00e9ris\u00e9 par un gros volume de donn\u00e9es, mais \u00e9galement une grande v\u00e9locit\u00e9, et qui doit donc \u00eatre imm\u00e9diatement disponible, ne peut pas se permettre de gaspiller ses ressources en requ\u00eates inutiles. On tol\u00e8re donc \u00e0 un certain point les risques dus \u00e0 la redondance, pour gagner en disponibilit\u00e9, primordiale dans ce type de syst\u00e8mes. D'autre part, un syst\u00e8me Big Data est un syst\u00e8me r\u00e9parti par excellence, et dans un syst\u00e8me r\u00e9parti, il est primordial d'assurer une bonne tol\u00e9rance aux fautes en cr\u00e9ant des r\u00e9pliques des donn\u00e9es, diss\u00e9min\u00e9es partout sur le cluster. Ces r\u00e9pliques assurent qu'aucune machine n'est compl\u00e8tement indispensable, et diminue le risque d'indisponibilit\u00e9 des donn\u00e9es. Un autre signe de redondance. MOTTO 6 : Vive le Polyglottisme! \u00catre polyglotte, c'est \u00eatre capable de parler plusieurs langues. Et les syst\u00e8mes Big Data encouragent le polyglottisme. En effet, ce sont des syst\u00e8mes complexes qui impliquent en g\u00e9n\u00e9ral plusieurs traitements et plusieurs types de donn\u00e9es diff\u00e9rentes (donn\u00e9es brutes, donn\u00e9es nettoy\u00e9es, donn\u00e9es trait\u00e9es), ce qui fait qu'il existe deux principes importants \u00e0 encourager : Polyglot Programming : Une application peut comporter plusieurs langages et paradigmes de programmation, chacun assurant un besoin particulier, de fa\u00e7on \u00e0 profiter des avantages de chacun \u00e0 sa juste valeur. Polyglot Persistence : Dans une m\u00eame application, il est possible d'utiliser plusieurs syst\u00e8mes de stockage diff\u00e9rents (relationnels, NOSQL, syst\u00e8mes de fichiers, etc.). Gr\u00e2ce \u00e0 ces deux principes, on pourra cr\u00e9er des applications complexes mais compl\u00e8tes, qui permettent d'assurer tous les besoins en terme de stockage et de traitement.","title":"Principes de base du Domaine des Big Data"},{"location":"p1-big-data/#technologies-et-paradigmes","text":"Les op\u00e9rations \u00e0 r\u00e9aliser sur les syst\u00e8mes Big Data consistent principalement en : Ingestion des donn\u00e9es : repr\u00e9sente les phases de collecte et d'importation des donn\u00e9es pour \u00eatre stock\u00e9es ou trait\u00e9es \u00e0 la vol\u00e9e. Cela peut se faire en \"temps r\u00e9el\", c'est \u00e0 dire que les donn\u00e9es sont import\u00e9es au moment o\u00f9 elles sont \u00e9mises par leur source, ou bien \"par lots\", ce qui veut dire que les donn\u00e9es sont import\u00e9es par portions \u00e0 intervalles r\u00e9gulier. Exemples de technologies Apache Kafka , Amazon Kinesis , Apache Flume , Sqoop , etc. Stockage des donn\u00e9es : Les syst\u00e8mes de stockage de donn\u00e9es respectant les propri\u00e9t\u00e9s le Big Data se distinguent principalement en syst\u00e8mes de fichiers distribu\u00e9s, tel que Hadoop HDFS ou Google GFS , ou bases de donn\u00e9es NOSQL, tel que MongoDB , Cassandra , Redis ou Neo4J . Traitement des donn\u00e9es : Plusieurs types de traitement de donn\u00e9es sont possibles, nous citons : Traitement par lot (Batch Processing) : c'est le traitement des donn\u00e9es au repos (data at rest) qui se fait sur l'ensemble des donn\u00e9es stock\u00e9es, sans avoir besoin d'une interaction avec l'utilisateur. Le traitement par lot est adapt\u00e9 principalement aux op\u00e9rations ayant lieu \u00e0 la fin d'un cycle, permettant d'avoir une vision globale sur la totalit\u00e9 des donn\u00e9es, par exemple pour avoir un rapport global ou une analyse mensuelle. Les op\u00e9rations de traitement par lots sont en g\u00e9n\u00e9ral lanc\u00e9es \u00e0 des p\u00e9riodes r\u00e9guli\u00e8res, car elles sont connues pour avoir une grande latence (temps total de traitement). Exemples de technologies Hadoop Map Reduce et Spark Batch . Traitement en Streaming (Stream Processing) : c'est le traitement des donn\u00e9es en transit (data in motion) , ou en d'autres termes, le traitement des donn\u00e9es pendant qu'elles sont produites ou re\u00e7ues. Les donn\u00e9es \u00e9tant en g\u00e9n\u00e9ral cr\u00e9\u00e9es en tant que flux continu (\u00e9v\u00e8nements de capteurs, activit\u00e9 des utilisateurs sur un site web, flux vid\u00e9o, etc.), elles sont captur\u00e9es comme une s\u00e9rie d'\u00e9v\u00e8nements continus dans le temps. Avant la cr\u00e9ation des traitements en streaming, ces donn\u00e9es \u00e9taient stock\u00e9es dans une base de donn\u00e9es, un syst\u00e8me de fichier ou tout autre forme de stockage en masse. Les applications appelleront ensuite les donn\u00e9es au besoin. Gr\u00e2ce \u00e0 ce nouveau paradigme, les donn\u00e9es peuvent maintenant \u00eatre trait\u00e9es \u00e0 la vol\u00e9e, ce qui permet \u00e0 la couche applicative d'\u00eatre toujours sur \u00e9coute et \u00e0 jour. Exemples de technologies Apache Flink et Apache Storm . Traitement par Micro-Lot (Micro-Batch Processing) : c'est la pratique de collecter les donn\u00e9es en petits groupes (appel\u00e9s des micro-lots ou des micro-batchs ) pour les traiter. Contrairement au traditionnel traitement par lot, cette variante fait en sorte que le traitement des donn\u00e9es soit plus fr\u00e9quent, et que les r\u00e9sultats soient produits avec une latence beaucoup plus petite. Les donn\u00e9es sont collect\u00e9es par intervalles selon un seuil pr\u00e9d\u00e9fini, limit\u00e9 par un temps (par exemple toutes les secondes), ou par un nombre (tous les 20 \u00e9l\u00e9ments). Ce traitement est en g\u00e9n\u00e9ral une alternative au traitement en streaming, o\u00f9 les donn\u00e9es sont trait\u00e9es \u00e0 la vol\u00e9e, mais risquent d'\u00eatre perdues si le temps de traitement est sup\u00e9rieur \u00e0 la fr\u00e9quence de g\u00e9n\u00e9ration des donn\u00e9es. Le micro-batching permet, par contraste, de sauvegarder les donn\u00e9es dans un buffer, ralentissant ainsi le flux g\u00e9n\u00e9r\u00e9. D'autre part, les donn\u00e9es \u00e9tant trait\u00e9es par micro-lots, il est possible d'avoir une visibilit\u00e9 sur ce petit lot de donn\u00e9es, contrairement au traitement en streaming qui n'a de visibilit\u00e9 que sur la derni\u00e8re donn\u00e9e g\u00e9n\u00e9r\u00e9e, \u00e0 moins de proc\u00e9der \u00e0 des m\u00e9canismes parfois co\u00fbteux. En contrepartie, le traitement en micro-batch donne des r\u00e9sultats moins r\u00e9cents que le \"vrai\" streaming, et s'ex\u00e9cute sous forme de bursts r\u00e9guliers, qui peuvent parfois \u00eatre g\u00eanants pour le syst\u00e8me sous-jacent. Exemples de technologies Spark Streaming et Logstash . Traitement Interactif (Interactive Processing) : Dans les syst\u00e8mes Big Data, la notion de transaction n'est plus exactement la m\u00eame que pour les syst\u00e8mes classiques: finies les sacro-saintes propri\u00e9t\u00e9s ACID dont le premier objectif est d'avoir des donn\u00e9es correctes et coh\u00e9rentes, et bonjour les propri\u00e9t\u00e9s BASE, qui favorisent un acc\u00e8s moins rigide aux donn\u00e9es. On parle donc rarement de traitement transactionnel en Big Data, mais de traitements plut\u00f4t interactifs : une requ\u00eate est envoy\u00e9e par le client, trait\u00e9e imm\u00e9diatement par le syst\u00e8me qui renverra un r\u00e9sultat dans un temps raisonnable. On parle alors d' interaction entre l'utilisateur et le syst\u00e8me. Les traitements en batch et en streaming ne sont pas cens\u00e9s communiquer avec un utilisateur de l'autre c\u00f4t\u00e9. En g\u00e9n\u00e9ral, les r\u00e9sultats de ces traitements sont enregistr\u00e9s dans un syst\u00e8me de stockage, qui sera, lui, par la suite interrog\u00e9 par l'utilisateur. Le traitement interactif est donc le r\u00e9sultat d'une requ\u00eate de l'utilisateur, faite en g\u00e9n\u00e9ral sur une base de donn\u00e9es (relationnelle ou NOSQL). Exemples de technologies Apache Drill , Cloudera Impala ou Apache Zeppelin .","title":"Technologies et Paradigmes"},{"location":"tips/","text":"See mkdocs Cheat Sheet italique input gras 50070 image ou lien Apache Hadoop code git clone https : //github.com/liliasfaxi/hadoop-cluster-docker inline code hadoop fs - mkdir - p / user / root Attention blablabla Erreur blablabla Activit\u00e9 Modifier tables |Instruction|Fonctionnalit\u00e9| |---------|-------------------------------------------------------------| | hadoop fs \u2013 ls | Afficher le contenu du re\u0301pertoire racine | | hadoop fs \u2013 put file . txt | Upload un fichier dans hadoop (a\u0300 partir du re\u0301pertoire courant linux) | | hadoop fs \u2013 get file . txt | Download un fichier a\u0300 partir de hadoop sur votre disque local | | hadoop fs \u2013 tail file . txt | Lire les dernie\u0300res lignes du fichier | | hadoop fs \u2013 cat file . txt | Affiche tout le contenu du fichier | | hadoop fs \u2013 mv file . txt newfile . txt | Renommer le fichier | | hadoop fs \u2013 rm newfile . txt | Supprimer le fichier | | hadoop fs \u2013 mkdir myinput | Cre\u0301er un re\u0301pertoire | | hadoop fs \u2013 cat file . txt \\ | less | Lire le fichier page par page|","title":"Tips"}]}